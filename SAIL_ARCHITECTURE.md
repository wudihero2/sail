# Sail æ¶æ§‹æ·±åº¦è§£æï¼šå¾è«‹æ±‚åˆ°åŸ·è¡Œçš„å®Œæ•´æ—…ç¨‹

æœ¬æ–‡æ·±å…¥æ¢è¨ Sail å¦‚ä½•å•Ÿå‹•ã€æ¥å—è«‹æ±‚ã€è™•ç†æŸ¥è©¢ï¼Œä»¥åŠåœ¨ Local å’Œ Cluster æ¨¡å¼ä¸‹çš„é‹ä½œæ©Ÿåˆ¶ã€‚

## æ¶æ§‹ç¸½è¦½

Sail æ˜¯ä¸€å€‹é«˜æ€§èƒ½çš„ Spark ç›¸å®¹è¨ˆç®—å¼•æ“ï¼Œæ¡ç”¨ Rust å¯¦ä½œï¼Œæ”¯æ´å…©ç¨®åŸ·è¡Œæ¨¡å¼ï¼š

| æ¨¡å¼ | èªªæ˜ | é©ç”¨å ´æ™¯ |
|------|------|----------|
| **Local** | å–®ä¸€ç¨‹åºï¼Œå¤šåŸ·è¡Œç·’åŸ·è¡Œ | é–‹ç™¼ã€æ¸¬è©¦ã€å°è¦æ¨¡è³‡æ–™è™•ç† |
| **LocalCluster** | æœ¬åœ°å•Ÿå‹•å¤šå€‹ Worker ç¨‹åº | æ¸¬è©¦åˆ†æ•£å¼é‚è¼¯ |
| **KubernetesCluster** | åœ¨ K8s ä¸Šå•Ÿå‹• Worker Pod | ç”Ÿç”¢ç’°å¢ƒå¤§è¦æ¨¡è³‡æ–™è™•ç† |

ğŸ”¸ ä½ç½®ï¼š`crates/sail-common/src/config/application.rs:66-78`

```rust
#[derive(Debug, Clone, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ExecutionMode {
    Local,
    #[serde(alias = "local-cluster")]
    LocalCluster,
    #[serde(
        alias = "kubernetes-cluster",
        alias = "k8s-cluster",
        alias = "k8s_cluster",
        alias = "kube-cluster",
        alias = "kube_cluster"
    )]
    KubernetesCluster,
}
```

## æ•´é«”æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PySpark Client                           â”‚
â”‚  spark = SparkSession.builder.remote("sc://localhost:50051")    â”‚
â”‚  df = spark.sql("SELECT * FROM table WHERE id > 100")           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ gRPC (Spark Connect Protocol)
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Sail Spark Connect Server                    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          SparkConnectServer (gRPC Service)               â”‚   â”‚
â”‚  â”‚  - execute_plan()    - analyze_plan()                    â”‚   â”‚
â”‚  â”‚  - config()          - add_artifacts()                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         SessionManagerActor (Actor)                      â”‚   â”‚
â”‚  â”‚  - ç®¡ç† Session ç”Ÿå‘½é€±æœŸ                                   â”‚   â”‚
â”‚  â”‚  - å»ºç«‹ SessionContext                                    â”‚   â”‚
â”‚  â”‚  - é–’ç½® Session æ¸…ç†                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            SessionContext (DataFusion)                   â”‚   â”‚
â”‚  â”‚  - SparkSession Extension                                â”‚   â”‚
â”‚  â”‚  - JobRunner (Local æˆ– Cluster)                          â”‚   â”‚
â”‚  â”‚  - Catalog Provider                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
        â–¼ Local Mode              â–¼ Cluster Mode
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LocalJobRunner    â”‚     â”‚      ClusterJobRunner                â”‚
â”‚                   â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ DataFusion        â”‚     â”‚  â”‚   DriverActor (Actor)          â”‚  â”‚
â”‚ execute_stream()  â”‚     â”‚  â”‚  - ä»»å‹™èª¿åº¦                     â”‚  â”‚
â”‚                   â”‚     â”‚  â”‚  - Worker ç®¡ç†                 â”‚  â”‚
â”‚ å¤šåŸ·è¡Œç·’åŸ·è¡Œ        â”‚     â”‚  â”‚  - ç‹€æ…‹è¿½è¹¤                     â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â”‚           â”‚ gRPC (å…§éƒ¨å”è­°)           â”‚
                          â”‚           â†“                          â”‚
                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                          â”‚  â”‚   WorkerActor (Actor) Ã— N      â”‚  â”‚
                          â”‚  â”‚  - åŸ·è¡Œä»»å‹™                     â”‚  â”‚
                          â”‚  â”‚  - è³‡æ–™ Shuffle                â”‚  â”‚
                          â”‚  â”‚  - å›å ±ç‹€æ…‹                     â”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ç¬¬ä¸€éƒ¨åˆ†ï¼šæœå‹™å™¨å•Ÿå‹•æµç¨‹

### å•Ÿå‹•å‘½ä»¤

```bash
sail spark server --port 50051
```

### å•Ÿå‹•èª¿ç”¨éˆ

```
main.rs::main()
  â”‚
  â”œâ”€> Python::initialize()              # åˆå§‹åŒ–åµŒå…¥å¼ Python
  â”‚
  â””â”€> runner::main(args)
        â”‚
        â””â”€> run_spark_connect_server(ip, port)
              â”‚
              â”œâ”€> init_telemetry()      # åˆå§‹åŒ–æ—¥èªŒå’Œè¿½è¹¤
              â”‚
              â”œâ”€> AppConfig::load()     # è¼‰å…¥è¨­å®šï¼ˆå« ExecutionModeï¼‰
              â”‚
              â”œâ”€> RuntimeManager::try_new()  # å»ºç«‹ Tokio åŸ·è¡Œæ™‚
              â”‚
              â””â”€> runtime.block_on(async {
                    â”‚
                    â”œâ”€> TcpListener::bind((ip, port))  # ç¶å®š TCP åŸ 
                    â”‚
                    â””â”€> serve(listener, shutdown(), options)
                          â”‚
                          â”œâ”€> SessionManager::new(options)
                          â”‚     â”‚
                          â”‚     â””â”€> ActorSystem::spawn::<SessionManagerActor>()
                          â”‚
                          â”œâ”€> SparkConnectServer::new(session_manager)
                          â”‚
                          â”œâ”€> SparkConnectServiceServer::new(server)
                          â”‚
                          â””â”€> ServerBuilder::new(...).serve(...)
                                â””â”€> å•Ÿå‹• gRPC ä¼ºæœå™¨ï¼Œç­‰å¾…è«‹æ±‚
                  })
```

### é—œéµé…ç½®ï¼šExecutionMode

ğŸ”¸ ä½ç½®ï¼š`crates/sail-common/src/config/application.yaml`ï¼ˆå…§åµŒï¼‰

```yaml
mode: local  # æˆ– local-clusterã€kubernetes-cluster

cluster:
  enable_tls: false
  driver_listen_host: "0.0.0.0"
  driver_listen_port: 50052
  driver_external_host: "localhost"
  driver_external_port: 50052
  worker_initial_count: 2
  worker_max_count: 10
  worker_task_slots: 4
  # ... æ›´å¤šè¨­å®š
```

å¯é€éç’°å¢ƒè®Šæ•¸è¦†è“‹ï¼š
```bash
export SAIL_MODE=local-cluster
export SAIL_CLUSTER__WORKER_INITIAL_COUNT=4
sail spark server --port 50051
```

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ¥æ”¶èˆ‡è™•ç†è«‹æ±‚

### PySpark å®¢æˆ¶ç«¯ç™¼é€æŸ¥è©¢

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.remote("sc://localhost:50051").getOrCreate()
df = spark.sql("SELECT id, name FROM users WHERE age > 18")
df.show()
```

### gRPC è«‹æ±‚æµç¨‹

```
PySpark Client
  â”‚ 1. å»ºç«‹ Spark Connect gRPC é€£ç·š
  â”‚
  â”œâ”€> ExecutePlanRequest {
  â”‚     session_id: "abc-123"
  â”‚     user_context: { user_id: "user1" }
  â”‚     plan: {
  â”‚       op_type: Root {
  â”‚         relation: Sql {
  â”‚           query: "SELECT id, name FROM users WHERE age > 18"
  â”‚         }
  â”‚       }
  â”‚     }
  â”‚   }
  â”‚
  â†“ gRPC: /spark.connect.SparkConnectService/ExecutePlan

SparkConnectServer::execute_plan()
```

### æœå‹™å™¨è™•ç†è«‹æ±‚

ğŸ”¸ ä½ç½®ï¼š`crates/sail-spark-connect/src/server.rs:54-161`

```rust
async fn execute_plan(
    &self,
    request: Request<ExecutePlanRequest>,
) -> Result<Response<Self::ExecutePlanStream>, Status> {
    let request = request.into_inner();

    // 1. æå– Session è³‡è¨Š
    let session_key = SessionKey {
        user_id: request.user_context.map(|u| u.user_id).unwrap_or_default(),
        session_id: request.session_id,
    };

    // 2. å–å¾—æˆ–å»ºç«‹ Session
    let ctx = self
        .session_manager
        .get_or_create_session_context(session_key)
        .await?;

    // 3. è§£æè¨ˆåŠƒ
    let Plan { op_type: op } = request.plan.required("plan")?;
    let op = op.required("plan op")?;

    // 4. åˆ†ç™¼è™•ç†
    let stream = match op {
        plan::OpType::Root(relation) => {
            service::handle_execute_relation(&ctx, relation, metadata).await?
        }
        plan::OpType::Command(Command { command_type }) => {
            // è™•ç†å„ç¨®å‘½ä»¤ï¼ˆWriteOperationã€RegisterFunction ç­‰ï¼‰
        }
    };

    Ok(Response::new(stream))
}
```

### Session å»ºç«‹æµç¨‹

```
SessionManager::get_or_create_session_context(session_key)
  â”‚
  â”œâ”€> ç™¼é€è¨Šæ¯åˆ° SessionManagerActor
  â”‚     SessionManagerEvent::GetOrCreateSession {
  â”‚       key: session_key,
  â”‚       result: oneshot::channel(),
  â”‚     }
  â”‚
  â†“ Actor è™•ç†è¨Šæ¯

SessionManagerActor::handle_get_or_create_session()
  â”‚
  â”œâ”€> æª¢æŸ¥ self.sessions.get(&key)
  â”‚     â”œâ”€ å­˜åœ¨: å›å‚³æ—¢æœ‰ Session
  â”‚     â””â”€ ä¸å­˜åœ¨: å»ºç«‹æ–° Session
  â”‚
  â””â”€> create_session_context(system, key)
        â”‚
        â”œâ”€> å»ºç«‹ JobRunnerï¼ˆæ ¹æ“š ExecutionModeï¼‰
        â”‚     â”œâ”€ Local: LocalJobRunner::new()
        â”‚     â””â”€ Cluster: ClusterJobRunner::new(system, options)
        â”‚           â””â”€> ActorSystem::spawn::<DriverActor>(options)
        â”‚
        â”œâ”€> SessionConfig::new()
        â”‚     â”œâ”€> è¨»å†Š CatalogManager Extension
        â”‚     â””â”€> è¨»å†Š SparkSession Extension (å« JobRunner)
        â”‚
        â”œâ”€> SessionStateBuilder
        â”‚     â”œâ”€> è¨­å®š ObjectStore Registry
        â”‚     â”œâ”€> è¨­å®š Optimizer Rules
        â”‚     â””â”€> è¨­å®š Query Planner
        â”‚
        â””â”€> SessionContext::new_with_state(state)
```

### æŸ¥è©¢åŸ·è¡Œæµç¨‹

ğŸ”¸ ä½ç½®ï¼š`crates/sail-spark-connect/src/service/plan_executor.rs:147-154`

```rust
pub(crate) async fn handle_execute_relation(
    ctx: &SessionContext,
    relation: Relation,
    metadata: ExecutorMetadata,
) -> SparkResult<ExecutePlanResponseStream> {
    let plan = relation.try_into()?;  // Spark Plan -> Sail Plan
    handle_execute_plan(ctx, plan, metadata, ExecutePlanMode::Lazy).await
}
```

å®Œæ•´è™•ç†æµç¨‹ï¼š

```
handle_execute_relation(ctx, relation, metadata)
  â”‚
  â”œâ”€> 1. Spark Plan è½‰æ›ç‚º Sail Spec Plan
  â”‚      Relation (protobuf) -> spec::Plan (å…§éƒ¨è¡¨ç¤º)
  â”‚
  â””â”€> handle_execute_plan(ctx, plan, metadata, mode)
        â”‚
        â”œâ”€> 2. è§£æèˆ‡å„ªåŒ–è¨ˆåŠƒ
        â”‚      resolve_and_execute_plan(ctx, plan_config, plan)
        â”‚        â”‚
        â”‚        â”œâ”€> Resolver::resolve(plan)
        â”‚        â”‚     - è§£æ SQL èªæ³•
        â”‚        â”‚     - è§£æ Table å¼•ç”¨
        â”‚        â”‚     - è§£æ UDF èª¿ç”¨
        â”‚        â”‚
        â”‚        â”œâ”€> DataFusion LogicalPlan
        â”‚        â”‚
        â”‚        â”œâ”€> Optimizer::optimize()
        â”‚        â”‚     - è¬‚è©ä¸‹æ¨
        â”‚        â”‚     - æŠ•å½±ä¸‹æ¨
        â”‚        â”‚     - å¸¸æ•¸æŠ˜ç–Š
        â”‚        â”‚     - Join é‡æ’åº
        â”‚        â”‚
        â”‚        â””â”€> DataFusion PhysicalPlan
        â”‚
        â””â”€> 3. åŸ·è¡Œè¨ˆåŠƒï¼ˆæ ¹æ“š JobRunner å‹åˆ¥ï¼‰
              spark.job_runner().execute(ctx, physical_plan)
                â”‚
                â”œâ”€ LocalJobRunner:
                â”‚    â””â”€> datafusion::execute_stream(plan, task_ctx)
                â”‚          - å¤šåŸ·è¡Œç·’åŸ·è¡Œ
                â”‚          - å›å‚³ SendableRecordBatchStream
                â”‚
                â””â”€ ClusterJobRunner:
                     â””â”€> driver.send(DriverEvent::ExecuteJob { plan })
                           â”‚
                           â””â”€> DriverActor è™•ç†ï¼ˆè©³è¦‹ä¸‹ç¯€ï¼‰
```

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šLocal Mode åŸ·è¡Œ

### Local Mode æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Sail Server (å–®ä¸€ç¨‹åº)                â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         SparkConnectServer (gRPC)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚        SessionManagerActor                       â”‚ â”‚
â”‚  â”‚  sessions: HashMap<SessionKey, SessionContext>   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         SessionContext                           â”‚ â”‚
â”‚  â”‚  - SparkSession Extension                        â”‚ â”‚
â”‚  â”‚    - job_runner: LocalJobRunner                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         LocalJobRunner                           â”‚ â”‚
â”‚  â”‚  execute(ctx, plan) {                            â”‚ â”‚
â”‚  â”‚    datafusion::execute_stream(plan, task_ctx)    â”‚ â”‚
â”‚  â”‚  }                                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚       DataFusion Execution (å¤šåŸ·è¡Œç·’)           â”‚ â”‚
â”‚  â”‚                                                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚ â”‚
â”‚  â”‚  â”‚Thread 1â”‚  â”‚Thread 2â”‚  â”‚Thread 3â”‚  ...       â”‚ â”‚
â”‚  â”‚  â”‚Partitionâ”‚  â”‚Partitionâ”‚  â”‚Partitionâ”‚           â”‚ â”‚
â”‚  â”‚  â”‚   0    â”‚  â”‚   1    â”‚  â”‚   2    â”‚            â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â”‚
â”‚  â”‚       â”‚           â”‚           â”‚                 â”‚ â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚ â”‚
â”‚  â”‚                   â”‚                             â”‚ â”‚
â”‚  â”‚         SendableRecordBatchStream               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LocalJobRunner å¯¦ä½œ

ğŸ”¸ ä½ç½®ï¼š`crates/sail-execution/src/job/runner.rs:24-60`

```rust
pub struct LocalJobRunner {
    stopped: AtomicBool,
}

#[tonic::async_trait]
impl JobRunner for LocalJobRunner {
    async fn execute(
        &self,
        ctx: &SessionContext,
        plan: Arc<dyn ExecutionPlan>,
    ) -> ExecutionResult<SendableRecordBatchStream> {
        if self.stopped.load(Ordering::Relaxed) {
            return Err(ExecutionError::InternalError(
                "job runner is stopped".to_string(),
            ));
        }
        // DataFusion åŸ·è¡Œï¼Œä½¿ç”¨å¤šåŸ·è¡Œç·’è™•ç†åˆ†å€
        Ok(execute_stream(plan, ctx.task_ctx())?)
    }

    async fn stop(&self) {
        self.stopped.store(true, Ordering::Relaxed);
    }
}
```

### Local Mode æŸ¥è©¢åŸ·è¡Œç¯„ä¾‹

å‡è¨­æŸ¥è©¢ï¼š`SELECT id, name FROM users WHERE age > 18`

```
1. è§£æ SQL ç‚º Logical Plan
   â””â”€> Projection [id, name]
         â””â”€> Filter (age > 18)
               â””â”€> TableScan (users)

2. å„ªåŒ– Logical Plan
   â””â”€> Projection [id, name]
         â””â”€> TableScan (users)
               - è¬‚è©ä¸‹æ¨: Filter (age > 18) æ¨åˆ°æƒæå±¤
               - æŠ•å½±ä¸‹æ¨: åªè®€å– [id, name, age] æ¬„ä½

3. è½‰æ›ç‚º Physical Plan
   â””â”€> ProjectionExec [id, name]
         â””â”€> CoalesceBatchesExec
               â””â”€> FilterExec (age > 18)
                     â””â”€> ParquetExec
                           - æª”æ¡ˆ: s3://bucket/users/*.parquet
                           - åˆ†å€: 4 å€‹ (æ ¹æ“š CPU æ ¸å¿ƒæ•¸)

4. DataFusion åŸ·è¡Œ
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Thread 1   â”‚  Thread 2   â”‚  Thread 3   â”‚  Thread 4   â”‚
   â”‚ Partition 0 â”‚ Partition 1 â”‚ Partition 2 â”‚ Partition 3 â”‚
   â”‚             â”‚             â”‚             â”‚             â”‚
   â”‚ ParquetExec â”‚ ParquetExec â”‚ ParquetExec â”‚ ParquetExec â”‚
   â”‚ - file_0.pq â”‚ - file_1.pq â”‚ - file_2.pq â”‚ - file_3.pq â”‚
   â”‚             â”‚             â”‚             â”‚             â”‚
   â”‚ FilterExec  â”‚ FilterExec  â”‚ FilterExec  â”‚ FilterExec  â”‚
   â”‚ age > 18    â”‚ age > 18    â”‚ age > 18    â”‚ age > 18    â”‚
   â”‚             â”‚             â”‚             â”‚             â”‚
   â”‚ ProjectExec â”‚ ProjectExec â”‚ ProjectExec â”‚ ProjectExec â”‚
   â”‚ [id, name]  â”‚ [id, name]  â”‚ [id, name]  â”‚ [id, name]  â”‚
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  RecordBatch Stream
                           â”‚
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ gRPC Response Stream    â”‚
              â”‚ (Arrow IPC Format)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    PySpark Client
                    df.show()
```

### Local Mode ç‰¹æ€§

âœ… **å„ªé»**
- å•Ÿå‹•å¿«é€Ÿï¼Œä¸éœ€é¡å¤–ç¨‹åº
- è¨˜æ†¶é«”æ•ˆç‡é«˜ï¼Œè³‡æ–™ä¸éœ€è·¨ç¨‹åºå‚³è¼¸
- é™¤éŒ¯ç°¡å–®ï¼Œå–®ä¸€ç¨‹åº
- é©åˆå°è¦æ¨¡è³‡æ–™ï¼ˆGB ç´šåˆ¥ï¼‰

âŒ **é™åˆ¶**
- å—é™æ–¼å–®æ©Ÿè³‡æº
- ç„¡æ³•æ°´å¹³æ“´å±•
- å¤§è¦æ¨¡è³‡æ–™ï¼ˆTB ç´šåˆ¥ï¼‰è™•ç†å›°é›£

## ç¬¬å››éƒ¨åˆ†ï¼šCluster Mode åŸ·è¡Œ

### Cluster Mode æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Sail Server (Driver)                      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         SparkConnectServer (gRPC)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        SessionManagerActor                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         SessionContext                                 â”‚  â”‚
â”‚  â”‚  - job_runner: ClusterJobRunner                        â”‚  â”‚
â”‚  â”‚    - driver: ActorHandle<DriverActor>                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         DriverActor (Actor)                            â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  state:                                                â”‚  â”‚
â”‚  â”‚  - workers: HashMap<WorkerId, WorkerInfo>              â”‚  â”‚
â”‚  â”‚  - jobs: HashMap<JobId, JobState>                      â”‚  â”‚
â”‚  â”‚  - task_queue: VecDeque<TaskId>                        â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  worker_manager:                                       â”‚  â”‚
â”‚  â”‚  - LocalWorkerManager (LocalCluster æ¨¡å¼)              â”‚  â”‚
â”‚  â”‚  - KubernetesWorkerManager (K8s æ¨¡å¼)                  â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  worker_clients: HashMap<WorkerId, WorkerClient>       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                    â”‚                        â”‚
â”‚   gRPC (å…§éƒ¨å”è­°)                gRPC (å…§éƒ¨å”è­°)              â”‚
â”‚                 â”‚                    â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   Worker 1         â”‚   â”‚   Worker 2       â”‚  ...
      â”‚                    â”‚   â”‚                  â”‚
      â”‚  WorkerActor       â”‚   â”‚  WorkerActor     â”‚
      â”‚  - åŸ·è¡Œä»»å‹™        â”‚   â”‚  - åŸ·è¡Œä»»å‹™      â”‚
      â”‚  - è³‡æ–™ Shuffle    â”‚   â”‚  - è³‡æ–™ Shuffle  â”‚
      â”‚  - å›å ±ç‹€æ…‹        â”‚   â”‚  - å›å ±ç‹€æ…‹      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ClusterJobRunner å¯¦ä½œ

ğŸ”¸ ä½ç½®ï¼š`crates/sail-execution/src/job/runner.rs:62-93`

```rust
pub struct ClusterJobRunner {
    driver: ActorHandle<DriverActor>,
}

impl ClusterJobRunner {
    pub fn new(system: &mut ActorSystem, options: DriverOptions) -> Self {
        // åœ¨ Actor ç³»çµ±ä¸­ç”Ÿæˆ DriverActor
        let driver = system.spawn(options);
        Self { driver }
    }
}

#[tonic::async_trait]
impl JobRunner for ClusterJobRunner {
    async fn execute(
        &self,
        _ctx: &SessionContext,
        plan: Arc<dyn ExecutionPlan>,
    ) -> ExecutionResult<SendableRecordBatchStream> {
        // ç™¼é€è¨Šæ¯çµ¦ DriverActorï¼Œç­‰å¾…çµæœ
        let (tx, rx) = oneshot::channel();
        self.driver
            .send(DriverEvent::ExecuteJob { plan, result: tx })
            .await?;
        rx.await.map_err(|e| {
            ExecutionError::InternalError(format!("failed to create job stream: {e}"))
        })?
    }

    async fn stop(&self) {
        let _ = self.driver.send(DriverEvent::Shutdown).await;
    }
}
```

### DriverActor çš„è·è²¬

ğŸ”¸ ä½ç½®ï¼š`crates/sail-execution/src/driver/actor/core.rs:19-99`

```rust
pub struct DriverActor {
    options: DriverOptions,
    state: DriverState,
    server: ServerMonitor,  // gRPC ä¼ºæœå™¨
    worker_manager: Arc<dyn WorkerManager>,  // Worker ç”Ÿå‘½é€±æœŸç®¡ç†
    worker_clients: HashMap<WorkerId, WorkerClient>,  // gRPC å®¢æˆ¶ç«¯
    physical_plan_codec: Box<dyn PhysicalExtensionCodec>,
    task_queue: VecDeque<TaskId>,
    task_sequences: HashMap<TaskId, u64>,
    job_outputs: HashMap<JobId, JobOutput>,
}
```

**ä¸»è¦è¨Šæ¯è™•ç†**ï¼š

1. **ExecuteJob**ï¼šåŸ·è¡Œåˆ†æ•£å¼æŸ¥è©¢
2. **RegisterWorker**ï¼šWorker è¨»å†Š
3. **WorkerHeartbeat**ï¼šWorker å¿ƒè·³
4. **UpdateTask**ï¼šä»»å‹™ç‹€æ…‹æ›´æ–°
5. **ProbeIdleWorker**ï¼šæª¢æ¸¬é–’ç½® Worker

### WorkerActor çš„è·è²¬

ğŸ”¸ ä½ç½®ï¼š`crates/sail-execution/src/worker/actor/core.rs:24-99`

```rust
pub struct WorkerActor {
    options: WorkerOptions,
    server: ServerMonitor,  // gRPC ä¼ºæœå™¨
    driver_client: DriverClient,  // èˆ‡ Driver é€šè¨Š
    worker_clients: HashMap<WorkerId, WorkerClient>,  // èˆ‡å…¶ä»– Worker é€šè¨Š
    task_signals: HashMap<TaskAttempt, oneshot::Sender<()>>,  // ä»»å‹™å–æ¶ˆä¿¡è™Ÿ
    local_streams: HashMap<ChannelName, Box<dyn LocalStream>>,  // æœ¬åœ°è³‡æ–™æµ
    session_context: Option<Arc<SessionContext>>,
    physical_plan_codec: Box<dyn PhysicalExtensionCodec>,
    sequence: u64,
}
```

**ä¸»è¦è¨Šæ¯è™•ç†**ï¼š

1. **RunTask**ï¼šåŸ·è¡Œä»»å‹™
2. **StopTask**ï¼šåœæ­¢ä»»å‹™
3. **CreateLocalStream**ï¼šå»ºç«‹æœ¬åœ°è³‡æ–™æµï¼ˆç”¨æ–¼ Shuffleï¼‰
4. **CreateRemoteStream**ï¼šå»ºç«‹é ç«¯è³‡æ–™æµ
5. **ReportTaskStatus**ï¼šå‘ Driver å›å ±ç‹€æ…‹

## ç¬¬äº”éƒ¨åˆ†ï¼šDriver-Worker gRPC é€šè¨Šå”è­°

### æ§åˆ¶å¹³é¢å”è­°

ğŸ”¸ Driver Service å”è­°ï¼ˆä½ç½®ï¼š`crates/sail-execution/proto/sail/driver/service.proto`ï¼‰

```protobuf
service DriverService {
  rpc RegisterWorker(RegisterWorkerRequest) returns (RegisterWorkerResponse) {}
  rpc ReportWorkerHeartbeat(ReportWorkerHeartbeatRequest) returns (ReportWorkerHeartbeatResponse) {}
  rpc ReportTaskStatus(ReportTaskStatusRequest) returns (ReportTaskStatusResponse) {}
}

enum TaskStatus {
  TASK_STATUS_RUNNING = 0;
  TASK_STATUS_SUCCEEDED = 1;
  TASK_STATUS_FAILED = 2;
  TASK_STATUS_CANCELED = 3;
}
```

ğŸ”¸ Worker Service å”è­°ï¼ˆä½ç½®ï¼š`crates/sail-execution/proto/sail/worker/service.proto`ï¼‰

```protobuf
service WorkerService {
  rpc RunTask(RunTaskRequest) returns (RunTaskResponse) {}
  rpc StopTask(StopTaskRequest) returns (StopTaskResponse) {}
  rpc RemoveStream(RemoveStreamRequest) returns (RemoveStreamResponse) {}
  rpc StopWorker(StopWorkerRequest) returns (StopWorkerResponse) {}
}

message RunTaskRequest {
  uint64 task_id = 1;
  uint64 attempt = 2;
  bytes plan = 3;           // åºåˆ—åŒ–çš„ PhysicalPlan
  uint64 partition = 4;
  optional string channel = 5;  // Shuffle è¼¸å‡ºé€šé“
}
```

### è³‡æ–™å¹³é¢å”è­°

ä½¿ç”¨ **Arrow Flight**ï¼ˆåŸºæ–¼ gRPCï¼‰åœ¨ Worker ä¹‹é–“äº¤æ›è³‡æ–™ï¼š

```
Worker 1 (Map Side)                   Worker 2 (Reduce Side)
     â”‚                                        â”‚
     â”‚ 1. åŸ·è¡Œ Map ä»»å‹™                       â”‚
     â”‚    ç”¢ç”Ÿä¸­é–“çµæœ                        â”‚
     â”‚                                        â”‚
     â”‚ 2. å¯«å…¥ LocalStream                    â”‚
     â”‚    channel: "job_1_stage_0_part_0"     â”‚
     â”‚                                        â”‚
     â”‚ <â”€â”€â”€â”€ Arrow Flight do_get() â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ 3. Reduce ä»»å‹™éœ€è¦è³‡æ–™
     â”‚                                        â”‚
     â”‚ â”€â”€â”€â”€ FlightData Stream â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚ 4. ä¸²æµå‚³è¼¸ RecordBatch
     â”‚      (Arrow IPC Format)                â”‚
     â”‚                                        â”‚
     â”‚ 5. RemoveStream RPC                    â”‚
     â”‚    æ¸…ç†å·²æ¶ˆè²»çš„è³‡æ–™                    â”‚
```

### DriverClient å¯¦ä½œ

ğŸ”¸ ä½ç½®ï¼š`crates/sail-execution/src/driver/client.rs:16-85`

```rust
pub struct DriverClient {
    inner: ClientHandle<DriverServiceClient<Channel>>,
}

impl DriverClient {
    // Worker å‘ Driver è¨»å†Š
    pub async fn register_worker(
        &self,
        worker_id: WorkerId,
        host: String,
        port: u16,
    ) -> ExecutionResult<()> {
        let request = RegisterWorkerRequest {
            worker_id: worker_id.into(),
            host,
            port: port as u32,
        };
        self.inner.get().await?.register_worker(request).await?;
        Ok(())
    }

    // Worker ç™¼é€å¿ƒè·³
    pub async fn report_worker_heartbeat(&self, worker_id: WorkerId) -> ExecutionResult<()> {
        let request = ReportWorkerHeartbeatRequest {
            worker_id: worker_id.into(),
        };
        self.inner.get().await?.report_worker_heartbeat(request).await?;
        Ok(())
    }

    // Worker å›å ±ä»»å‹™ç‹€æ…‹
    pub async fn report_task_status(
        &self,
        task_id: TaskId,
        attempt: usize,
        status: TaskStatus,
        message: Option<String>,
        cause: Option<CommonErrorCause>,
        sequence: u64,
    ) -> ExecutionResult<()> {
        let request = ReportTaskStatusRequest {
            task_id: task_id.into(),
            attempt: attempt as u64,
            status: TaskStatus::from(status) as i32,
            message,
            cause: cause.map(|x| serde_json::to_string(&x)?).transpose()?,
            sequence,
        };
        self.inner.get().await?.report_task_status(request).await?;
        Ok(())
    }
}
```

### WorkerClient å¯¦ä½œ

ğŸ”¸ ä½ç½®ï¼š`crates/sail-execution/src/worker/client.rs:20-103`

```rust
pub struct WorkerClient {
    client: ClientHandle<WorkerServiceClient<Channel>>,  // æ§åˆ¶å¹³é¢
    flight_client: ClientHandle<FlightServiceClient<Channel>>,  // è³‡æ–™å¹³é¢
}

impl WorkerClient {
    // Driver ç™¼é€ä»»å‹™çµ¦ Worker
    pub async fn run_task(
        &self,
        task_id: TaskId,
        attempt: usize,
        plan: Vec<u8>,
        partition: usize,
        channel: Option<ChannelName>,
    ) -> ExecutionResult<()> {
        let request = RunTaskRequest {
            task_id: task_id.into(),
            attempt: attempt as u64,
            plan,  // åºåˆ—åŒ–çš„ PhysicalPlan
            partition: partition as u64,
            channel: channel.map(|x| x.into()),
        };
        self.client.get().await?.run_task(request).await?;
        Ok(())
    }

    // Worker å¾å¦ä¸€å€‹ Worker ç²å– Shuffle è³‡æ–™
    pub async fn fetch_task_stream(
        &self,
        channel: ChannelName,
        _schema: SchemaRef,
    ) -> ExecutionResult<TaskStreamSource> {
        let ticket = TaskStreamTicket {
            channel: channel.into(),
        };
        let ticket = {
            let mut buf = Vec::with_capacity(ticket.encoded_len());
            ticket.encode(&mut buf)?;
            buf
        };
        let request = arrow_flight::Ticket {
            ticket: ticket.into(),
        };
        // Arrow Flight do_get
        let response = self.flight_client.get().await?.do_get(request).await?;
        let stream = response.into_inner().map_err(|e| e.into());
        let stream = FlightRecordBatchStream::new_from_flight_data(stream)
            .map_err(|e| e.into());
        Ok(Box::pin(stream))
    }
}
```

## ç¬¬å…­éƒ¨åˆ†ï¼šå®Œæ•´æŸ¥è©¢åŸ·è¡Œæµç¨‹ï¼ˆCluster Modeï¼‰

å‡è¨­æŸ¥è©¢ï¼š
```sql
SELECT department, COUNT(*) as cnt, AVG(salary) as avg_sal
FROM employees
WHERE age > 25
GROUP BY department
```

### éšæ®µ 1ï¼šDriver æ”¶åˆ°æŸ¥è©¢

```
PySpark Client
  â”‚
  â””â”€> ExecutePlanRequest (SQL)
        â”‚
        â–¼
SparkConnectServer::execute_plan()
  â”‚
  â””â”€> SessionContext (å« ClusterJobRunner)
        â”‚
        â””â”€> ClusterJobRunner::execute(plan)
              â”‚
              â””â”€> DriverActor æ”¶åˆ° ExecuteJob è¨Šæ¯
```

### éšæ®µ 2ï¼šDriver è¦åŠƒåˆ†æ•£å¼åŸ·è¡Œ

```
DriverActor::handle_execute_job()
  â”‚
  â”œâ”€> 1. åˆ†æ PhysicalPlanï¼Œè­˜åˆ¥ Shuffle é‚Šç•Œ
  â”‚
  â”‚      Stage 0 (Map):
  â”‚        ParquetExec (employees)
  â”‚          -> FilterExec (age > 25)
  â”‚          -> PartialAggregateExec (GROUP BY department)
  â”‚          -> ShuffleWriterExec (æŒ‰ department hash åˆ†å€)
  â”‚
  â”‚      Stage 1 (Reduce):
  â”‚        ShuffleReaderExec
  â”‚          -> FinalAggregateExec (COUNT, AVG)
  â”‚          -> ProjectionExec
  â”‚
  â”œâ”€> 2. ç‚ºæ¯å€‹ Stage å»ºç«‹ Tasks
  â”‚      Stage 0: 4 å€‹ Task (å°æ‡‰ 4 å€‹ Parquet æª”æ¡ˆ)
  â”‚        - Task 0: partition 0
  â”‚        - Task 1: partition 1
  â”‚        - Task 2: partition 2
  â”‚        - Task 3: partition 3
  â”‚
  â”‚      Stage 1: 2 å€‹ Task (æ ¹æ“š shuffle åˆ†å€æ•¸)
  â”‚        - Task 4: partition 0
  â”‚        - Task 5: partition 1
  â”‚
  â””â”€> 3. ç¢ºä¿æœ‰è¶³å¤ çš„ Worker
        worker_manager.ensure_workers(required_count)
          â”œâ”€ LocalWorkerManager: å•Ÿå‹•æœ¬åœ°ç¨‹åº
          â””â”€ KubernetesWorkerManager: å»ºç«‹ K8s Pod
```

### éšæ®µ 3ï¼šWorker è¨»å†Š

```
Worker ç¨‹åºå•Ÿå‹•
  â”‚
  â”œâ”€> WorkerActor::start()
  â”‚     â””â”€> å•Ÿå‹• gRPC ä¼ºæœå™¨ (WorkerService)
  â”‚
  â””â”€> WorkerActor æ”¶åˆ° ServerReady è¨Šæ¯
        â”‚
        â””â”€> DriverClient::register_worker(worker_id, host, port)
              â”‚
              â–¼
        DriverActor æ”¶åˆ° RegisterWorker è«‹æ±‚
          â”‚
          â”œâ”€> è¨˜éŒ„ Worker è³‡è¨Š
          â”‚     state.workers.insert(worker_id, WorkerInfo { ... })
          â”‚
          â”œâ”€> å»ºç«‹ WorkerClient
          â”‚     worker_clients.insert(worker_id, WorkerClient::new(...))
          â”‚
          â””â”€> é–‹å§‹èª¿åº¦ä»»å‹™
                schedule_tasks()
```

### éšæ®µ 4ï¼šDriver èª¿åº¦ä»»å‹™ï¼ˆStage 0ï¼‰

```
DriverActor::schedule_tasks()
  â”‚
  â”œâ”€> å¾ task_queue å–å‡ºä»»å‹™
  â”‚     task = task_queue.pop_front()  // Task 0
  â”‚
  â”œâ”€> é¸æ“‡ Worker
  â”‚     worker = select_worker()  // Worker 1
  â”‚
  â”œâ”€> åºåˆ—åŒ– PhysicalPlan
  â”‚     let plan_bytes = physical_plan_codec.encode(&plan)?;
  â”‚
  â””â”€> WorkerClient::run_task(task_id, attempt, plan_bytes, partition, channel)
        â”‚
        â–¼
  Worker 1 æ”¶åˆ° RunTask RPC
    â”‚
    â””â”€> WorkerActor æ”¶åˆ° RunTask è¨Šæ¯
```

### éšæ®µ 5ï¼šWorker åŸ·è¡Œä»»å‹™ï¼ˆStage 0ï¼‰

```
WorkerActor::handle_run_task(task_id, plan_bytes, partition, channel)
  â”‚
  â”œâ”€> 1. ååºåˆ—åŒ– PhysicalPlan
  â”‚      let plan = physical_plan_codec.decode(&plan_bytes)?;
  â”‚
  â”œâ”€> 2. åœ¨èƒŒæ™¯åŸ·è¡Œä»»å‹™
  â”‚      ctx.spawn(async move {
  â”‚        let result = execute_task(plan, partition).await;
  â”‚        ...
  â”‚      })
  â”‚
  â””â”€> 3. execute_task() åŸ·è¡Œ
        â”‚
        â”œâ”€> ParquetExec::execute(partition)
        â”‚     - è®€å– file_0.parquet
        â”‚     - å›å‚³ RecordBatch Stream
        â”‚
        â”œâ”€> FilterExec::execute()
        â”‚     - éæ¿¾ age > 25
        â”‚
        â”œâ”€> PartialAggregateExec::execute()
        â”‚     - éƒ¨åˆ†èšåˆï¼š{ dept: "IT", count: 50, sum: 500000 }
        â”‚
        â””â”€> ShuffleWriterExec::execute()
              - è¨ˆç®— hash(department) % 2
              - å¯«å…¥ LocalStream
                  channel: "job_1_stage_0_part_0"
                  channel: "job_1_stage_0_part_1"

              - å›å ±å®Œæˆç‹€æ…‹
                DriverClient::report_task_status(
                  task_id,
                  TaskStatus::Succeeded
                )
```

### éšæ®µ 6ï¼šDriver æ”¶åˆ°ä»»å‹™å®Œæˆï¼Œèª¿åº¦ Stage 1

```
DriverActor æ”¶åˆ° ReportTaskStatus (Task 0 å®Œæˆ)
  â”‚
  â”œâ”€> æ›´æ–°ä»»å‹™ç‹€æ…‹
  â”‚     state.tasks[task_0].status = Succeeded
  â”‚
  â”œâ”€> æª¢æŸ¥ Stage 0 æ˜¯å¦å…¨éƒ¨å®Œæˆ
  â”‚     æ‰€æœ‰ Task (0, 1, 2, 3) éƒ½å®Œæˆ
  â”‚
  â””â”€> èª¿åº¦ Stage 1 çš„ä»»å‹™
        â”‚
        â””â”€> WorkerClient::run_task(task_4, plan_stage1, partition=0, ...)
              â”‚
              â–¼
        Worker 2 æ”¶åˆ° RunTask (Stage 1, Task 4)
```

### éšæ®µ 7ï¼šWorker åŸ·è¡Œ Shuffle Readï¼ˆStage 1ï¼‰

```
WorkerActor::handle_run_task(task_4, plan_stage1, partition=0)
  â”‚
  â””â”€> execute_task(plan_stage1, partition=0)
        â”‚
        â”œâ”€> ShuffleReaderExec::execute()
        â”‚     â”‚
        â”‚     â”œâ”€> 1. è¨ˆç®—éœ€è¦è®€å–çš„ channels
        â”‚     â”‚      éœ€è¦è®€å–æ‰€æœ‰ Stage 0 Worker çš„ partition=0 è³‡æ–™
        â”‚     â”‚      - Worker 1: "job_1_stage_0_part_0"
        â”‚     â”‚      - Worker 1: "job_1_stage_0_part_0" (ä¾†è‡ªä¸åŒ Task)
        â”‚     â”‚      - Worker 2: "job_1_stage_0_part_0"
        â”‚     â”‚      - Worker 3: "job_1_stage_0_part_0"
        â”‚     â”‚
        â”‚     â”œâ”€> 2. å¾å„å€‹ Worker ç²å–è³‡æ–™
        â”‚     â”‚      for channel in channels {
        â”‚     â”‚        let worker_client = get_worker_client(channel.worker_id);
        â”‚     â”‚        let stream = worker_client.fetch_task_stream(channel, schema).await?;
        â”‚     â”‚        streams.push(stream);
        â”‚     â”‚      }
        â”‚     â”‚
        â”‚     â””â”€> 3. åˆä½µæ‰€æœ‰ streams
        â”‚           stream::select_all(streams)
        â”‚
        â”œâ”€> FinalAggregateExec::execute()
        â”‚     - æœ€çµ‚èšåˆï¼šåˆä½µæ‰€æœ‰ department çš„ count å’Œ sum
        â”‚     - è¨ˆç®— AVG = sum / count
        â”‚
        â””â”€> ProjectionExec::execute()
              - æŠ•å½±ï¼š[department, cnt, avg_sal]

              - å›å ±å®Œæˆ
                DriverClient::report_task_status(task_4, Succeeded)
```

### éšæ®µ 8ï¼šDriver æ”¶é›†çµæœï¼Œå›å‚³å®¢æˆ¶ç«¯

```
DriverActor::handle_update_task(task_4, Succeeded)
  â”‚
  â”œâ”€> æª¢æŸ¥æ‰€æœ‰ Stage 1 ä»»å‹™å®Œæˆ
  â”‚
  â”œâ”€> å¾ Worker 2 æ”¶é›†æœ€çµ‚çµæœ
  â”‚     let result_stream = worker_client.fetch_task_stream(output_channel, schema).await?;
  â”‚
  â””â”€> é€é oneshot::channel å›å‚³çµ¦ ClusterJobRunner
        result_sender.send(result_stream)
          â”‚
          â–¼
ClusterJobRunner::execute() å›å‚³
  â”‚
  â””â”€> handle_execute_plan() å›å‚³
        â”‚
        â””â”€> SparkConnectServer ä¸²æµå‚³é€çµ¦ PySpark Client
              â”‚
              â–¼
          PySpark Client
          df.show()

          +----------+---+-------+
          |department|cnt|avg_sal|
          +----------+---+-------+
          |IT        |150| 75000 |
          |HR        | 80| 55000 |
          |Sales     |120| 60000 |
          +----------+---+-------+
```

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šCluster Mode é€šè¨Šæ™‚åºåœ–

```
PySpark     Spark       Session      Cluster      Driver      Worker      Worker
Client      Connect     Manager      JobRunner    Actor       Manager     Actor 1
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚â”€â”€SQLâ”€â”€â”€â”€â”€>â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚â”€â”€GetSessionâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€SessionContextâ”€â”¤           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚â”€â”€Executeâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚     ExecuteJob        â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚      EnsureWorkersâ”€â”€â”€>â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚       StartWorkerâ”€â”€â”€â”€>â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Registerâ”€â”¤
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚      RunTaskâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚     ExecuteTask
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚<â”€Heartbeatâ”€â”¤
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚<â”€â”€â”€â”€â”€â”€TaskStatusâ”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚           â”‚            â”‚             â”‚           â”‚   (Succeeded)          â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚      FetchResultâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RecordBatchâ”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€RecordBatchâ”€â”€â”€â”€â”€â”€â”¤           â”‚           â”‚
  â”‚           â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
  â”‚  df.show()â”‚            â”‚             â”‚           â”‚           â”‚           â”‚
```

## ç¬¬å…«éƒ¨åˆ†ï¼šæ ¸å¿ƒå·®ç•°å°æ¯”

| ç‰¹æ€§ | Local Mode | LocalCluster Mode | KubernetesCluster Mode |
|------|------------|-------------------|------------------------|
| **ç¨‹åºæ•¸é‡** | 1 å€‹ | 1 å€‹ Server + N å€‹ Worker | 1 å€‹ Server + K8s Pods |
| **é€šè¨Šæ–¹å¼** | åŸ·è¡Œç·’é–“è¨˜æ†¶é«”å…±äº« | æœ¬åœ° gRPC (localhost) | ç¶²è·¯ gRPC |
| **ä»»å‹™åŸ·è¡Œ** | DataFusion å¤šåŸ·è¡Œç·’ | DriverActor â†’ WorkerActor | DriverActor â†’ WorkerActor |
| **è³‡æ–™ Shuffle** | è¨˜æ†¶é«”å…§ | Arrow Flight (localhost) | Arrow Flight (ç¶²è·¯) |
| **æ“´å±•æ€§** | å—é™æ–¼ CPU æ ¸å¿ƒæ•¸ | å—é™æ–¼æ©Ÿå™¨è³‡æº | æ°´å¹³æ“´å±•ï¼ˆK8sï¼‰ |
| **å•Ÿå‹•é€Ÿåº¦** | å¿« | ä¸­ | æ…¢ï¼ˆéœ€å»ºç«‹ Podï¼‰ |
| **é©ç”¨å ´æ™¯** | é–‹ç™¼ã€æ¸¬è©¦ã€å°è³‡æ–™ | æ¸¬è©¦åˆ†æ•£å¼é‚è¼¯ | ç”Ÿç”¢ç’°å¢ƒã€å¤§è³‡æ–™ |
| **è¨˜æ†¶é«”ä½¿ç”¨** | ä½ | ä¸­ | é«˜ï¼ˆå¤š Podï¼‰ |
| **å®¹éŒ¯èƒ½åŠ›** | ç„¡ | ä½ï¼ˆæœ¬åœ°ç¨‹åºï¼‰ | é«˜ï¼ˆK8s è‡ªå‹•é‡å•Ÿï¼‰ |

## ç¬¬ä¹éƒ¨åˆ†ï¼šé—œéµè¨­è¨ˆæ±ºç­–

### ç‚ºä»€éº¼ä½¿ç”¨ Actor æ¨¡å‹ï¼Ÿ

âœ… **å„ªé»**
- é¿å…æ‰‹å‹•ç®¡ç†é–ï¼Œæ¸›å°‘æ­»é–é¢¨éšª
- è¨Šæ¯é©…å‹•ï¼Œè‡ªç„¶é©åˆåˆ†æ•£å¼ç³»çµ±
- ç‹€æ…‹å°è£ï¼Œé™ä½è¤‡é›œåº¦
- éŒ¯èª¤éš”é›¢ï¼Œä¸€å€‹ Actor å´©æ½°ä¸å½±éŸ¿å…¶ä»–

âŒ **é™åˆ¶**
- é †åºè™•ç†è¨Šæ¯ï¼Œå¯èƒ½æˆç‚ºç“¶é ¸
- éœ€è¦è¨­è¨ˆè‰¯å¥½çš„è¨Šæ¯å”è­°
- é™¤éŒ¯ç›¸å°å›°é›£ï¼ˆè¨Šæ¯éåŒæ­¥ï¼‰

### ç‚ºä»€éº¼å€åˆ†æ§åˆ¶å¹³é¢å’Œè³‡æ–™å¹³é¢ï¼Ÿ

**æ§åˆ¶å¹³é¢**ï¼ˆå…§éƒ¨ Sail gRPCï¼‰
- ä»»å‹™èª¿åº¦ã€ç‹€æ…‹å›å ±ã€å¿ƒè·³æª¢æ¸¬
- è¨Šæ¯å°ã€é »ç‡é«˜
- éœ€è¦å¯é æ€§å’Œé †åºä¿è­‰

**è³‡æ–™å¹³é¢**ï¼ˆArrow Flightï¼‰
- Shuffle è³‡æ–™å‚³è¼¸ã€çµæœå›å‚³
- è³‡æ–™é‡å¤§ã€éœ€è¦é«˜ååé‡
- ä½¿ç”¨ Arrow IPC æ ¼å¼é›¶æ‹·è²

### ç‚ºä»€éº¼ Local Mode ä¸ä½¿ç”¨ Actorï¼Ÿ

Local Mode ä½¿ç”¨ `LocalJobRunner`ï¼Œç›´æ¥å‘¼å« DataFusion çš„ `execute_stream`ï¼š

```rust
// Local Mode: ç°¡å–®ç›´æ¥
Ok(execute_stream(plan, ctx.task_ctx())?)
```

åŸå› ï¼š
- **ç°¡å–®**ï¼šä¸éœ€è¦é¡å¤–çš„ç¨‹åºå’Œé€šè¨Š
- **é«˜æ•ˆ**ï¼šé¿å…è¨Šæ¯åºåˆ—åŒ–/ååºåˆ—åŒ–é–‹éŠ·
- **è¨˜æ†¶é«”æ•ˆç‡**ï¼šè³‡æ–™åœ¨åŸ·è¡Œç·’é–“å…±äº«ï¼Œä¸éœ€è·¨ç¨‹åº

Cluster Mode å¿…é ˆä½¿ç”¨ Actorï¼Œå› ç‚ºï¼š
- éœ€è¦ç®¡ç†å¤šå€‹ Worker ç¨‹åº
- éœ€è¦è¿½è¹¤åˆ†æ•£å¼ä»»å‹™ç‹€æ…‹
- éœ€è¦å”èª¿ Shuffle è³‡æ–™å‚³è¼¸

## ç¸½çµ

Sail çš„æ¶æ§‹è¨­è¨ˆé«”ç¾äº†å¹¾å€‹é—œéµåŸå‰‡ï¼š

ğŸ”¸ **æ¼¸é€²å¼è¤‡é›œåº¦**
- Local Mode ç°¡å–®é«˜æ•ˆ
- Cluster Mode æ”¯æ´å¤§è¦æ¨¡è™•ç†
- ä½¿ç”¨è€…å¯æ ¹æ“šéœ€æ±‚é¸æ“‡

ğŸ”¸ **æ¸…æ™°çš„è²¬ä»»åˆ†é›¢**
- SessionManagerï¼šSession ç”Ÿå‘½é€±æœŸ
- JobRunnerï¼šåŸ·è¡Œæ¨¡å¼æŠ½è±¡
- DriverActorï¼šä»»å‹™èª¿åº¦
- WorkerActorï¼šä»»å‹™åŸ·è¡Œ

ğŸ”¸ **é«˜æ•ˆçš„è³‡æ–™è™•ç†**
- åŸºæ–¼ DataFusion å’Œ Arrow
- é›¶æ‹·è²è³‡æ–™å‚³è¼¸ï¼ˆArrow Flightï¼‰
- å¤šåŸ·è¡Œç·’ä¸¦è¡Œï¼ˆLocalï¼‰
- åˆ†æ•£å¼ä¸¦è¡Œï¼ˆClusterï¼‰

ğŸ”¸ **å¯é çš„åˆ†æ•£å¼å”èª¿**
- Actor æ¨¡å‹ç®¡ç†ç‹€æ…‹
- gRPC æä¾›å¯é é€šè¨Š
- å¿ƒè·³æª¢æ¸¬å’Œè¶…æ™‚æ©Ÿåˆ¶
- ä»»å‹™é‡è©¦å’Œå®¹éŒ¯

é€éé€™æ¨£çš„è¨­è¨ˆï¼ŒSail åœ¨ä¿æŒç°¡å–®æ˜“ç”¨çš„åŒæ™‚ï¼Œæä¾›äº†å¾æœ¬åœ°é–‹ç™¼åˆ°ç”Ÿç”¢ç’°å¢ƒçš„å®Œæ•´è§£æ±ºæ–¹æ¡ˆã€‚
