# pyproject.toml è©³ç´°è§£èªª

é€™ä»½æ–‡ä»¶è§£é‡‹ Sail å°ˆæ¡ˆçš„ Python å¥—ä»¶é…ç½®ã€‚pysail æ˜¯ Sail çš„ Python ä»‹é¢ï¼Œä½¿ç”¨ Maturin å°‡ Rust ç·¨è­¯ç‚º Python extensionã€‚

## Project åŸºæœ¬è³‡è¨Š

```toml
[project]
name = "pysail"
version = "0.4.2"
description = "Sail Python library"
authors = [
    { name = "LakeSail", email = "hello@lakesail.com" },
]
readme = "README.md"
license = { file = "LICENSE" }
requires-python = ">=3.9,<3.14"
dependencies = []
```

ðŸ”¸ name = "pysail": PyPI ä¸Šçš„å¥—ä»¶åç¨±
ðŸ”¸ requires-python: æ”¯æ´ Python 3.9 åˆ° 3.13
ðŸ”¸ dependencies = []: æ ¸å¿ƒå¥—ä»¶ç„¡é¡å¤–ä¾è³´ï¼ŒRust extension æ˜¯è‡ªåŒ…å«çš„

## Classifiers (PyPI åˆ†é¡žæ¨™ç±¤)

```toml
classifiers = [
    "Development Status :: 4 - Beta",
    "Programming Language :: Python :: 3.9",
    ...
    "Programming Language :: Rust",
    "Topic :: Scientific/Engineering",
]
```

é€™äº›æ¨™ç±¤ç”¨æ–¼ PyPI æœå°‹å’Œåˆ†é¡žï¼Œè¡¨æ˜Žé€™æ˜¯ Beta éšŽæ®µã€æ”¯æ´å¤š Python ç‰ˆæœ¬ã€åŒ…å« Rust ç¨‹å¼ç¢¼

## Optional Dependencies (å¯é¸ä¾è³´)

```toml
[project.optional-dependencies]
test = [
    "pyspark-client>=4.0,<5",
    "duckdb>=1.0,<2",
    "pytest>=8.4,<9",
    "pytest-bdd>=8.1,<9",
    "jinja2>=3.1,<4",
    "pillow>=10.3.0",
    "pyiceberg[sql-sqlite,pyiceberg-core]==0.10.0",
    "pydantic>=2.11,<2.12",
]
mcp = [
    "mcp>=1.0.0,<2",
]
```

ðŸ”¸ test: æ¸¬è©¦ç”¨ä¾è³´ï¼Œå®‰è£æ–¹å¼: `pip install pysail[test]`
ðŸ”¸ mcp: Model Context Protocol æ”¯æ´ï¼Œç”¨æ–¼ AI æ‡‰ç”¨æ•´åˆ

## CLI å…¥å£é»ž

```toml
[project.scripts]
sail = "pysail.cli:main"
```

å®‰è£å¾Œå¯åŸ·è¡Œ `sail` å‘½ä»¤ï¼Œå°æ‡‰ `python/pysail/cli.py` çš„ main å‡½æ•¸

## Build System (Maturin)

```toml
[build-system]
requires = ["maturin>=1.0,<2.0"]
build-backend = "maturin"
```

ðŸ”¸ Maturin æ˜¯ Rust+Python æ··åˆå°ˆæ¡ˆçš„å»ºæ§‹å·¥å…·
ðŸ”¸ è² è²¬ç·¨è­¯ Rust ç¨‹å¼ç¢¼ä¸¦æ‰“åŒ…æˆ Python wheel

```toml
[tool.maturin]
python-source = "python"
module-name = "pysail._native"
manifest-path = "crates/sail-python/Cargo.toml"
features = [
    "pyo3/extension-module",
    "pyo3/abi3-py38",
    "pyo3/generate-import-lib",
]
```

ðŸ”¸ python-source: Python åŽŸå§‹ç¢¼ç›®éŒ„
ðŸ”¸ module-name: ç·¨è­¯å¾Œçš„ native module åç¨± (`pysail._native`)
ðŸ”¸ manifest-path: Rust crate çš„ Cargo.toml è·¯å¾‘
ðŸ”¸ features:
- extension-module: ç·¨è­¯ç‚º Python extension
- abi3-py38: ä½¿ç”¨ç©©å®š ABIï¼Œä¸€å€‹ wheel æ”¯æ´å¤š Python ç‰ˆæœ¬
- generate-import-lib: Windows ç›¸å®¹æ€§

## Hatch ç’°å¢ƒç®¡ç†

Hatch æ˜¯ç¾ä»£ Python å°ˆæ¡ˆç®¡ç†å·¥å…·ï¼Œé€™è£¡å®šç¾©å¤šå€‹è™›æ“¬ç’°å¢ƒ:

### ðŸ”¸ Default ç’°å¢ƒ (é–‹ç™¼ç”¨)

```toml
[tool.hatch.envs.default]
python = "3.11"
installer = "pip"
skip-install = true
dependencies = [
    "pyspark[connect]==4.0.0",
    "ibis-framework>=11,<12",
    "pytest>=8.4,<9",
    ...
]
path = ".venvs/default"
```

ðŸ”¸ skip-install = true: ä¸è‡ªå‹•å®‰è£å°ˆæ¡ˆï¼Œå› ç‚ºéœ€è¦å…ˆç”¨ maturin ç·¨è­¯
ðŸ”¸ path: è™›æ“¬ç’°å¢ƒå­˜æ”¾è·¯å¾‘

```toml
[tool.hatch.envs.default.overrides]
env.CI.installer = "uv"
```

CI ç’°å¢ƒä½¿ç”¨ uv (æ›´å¿«çš„å¥—ä»¶å®‰è£å™¨)ï¼Œæœ¬åœ°ç”¨ pip

```toml
[tool.hatch.envs.default.scripts]
install-pysail = "\"{env:HATCH_UV}\" pip install pysail --no-index -f target/wheels --force-reinstall"
```

è‡ªè¨‚è…³æœ¬: å¾žæœ¬åœ° wheels å®‰è£ç·¨è­¯å¥½çš„ pysail

### ðŸ”¸ Coverage ç’°å¢ƒ

```toml
[tool.hatch.envs.coverage]
template = "default"
env-vars = {
    RUSTC_WORKSPACE_WRAPPER = ".github/scripts/rustc-workspace-wrapper.sh",
    LLVM_PROFILE_FILE = "target/coverage/sail-%p-%m.profraw"
}
```

ç¹¼æ‰¿ default ç’°å¢ƒï¼Œè¨­å®šç¨‹å¼ç¢¼è¦†è“‹çŽ‡æ”¶é›†çš„ç’°å¢ƒè®Šæ•¸

### ðŸ”¸ Test ç’°å¢ƒ (çŸ©é™£æ¸¬è©¦)

```toml
[tool.hatch.envs.test]
matrix-name-format = "{variable}-{value}"
...

[[tool.hatch.envs.test.matrix]]
spark = ["3.5.5", "4.0.0"]

[tool.hatch.envs.test.overrides]
matrix.spark.path = [
    { value = ".venvs/test.spark-3.5.5", if = ["3.5.5"] },
    { value = ".venvs/test.spark-4.0.0", if = ["4.0.0"] },
]
matrix.spark.extra-dependencies = [
    { value = "pyspark[connect]==3.5.5", if = ["3.5.5"] },
    { value = "pyspark[connect]==4.0.0", if = ["4.0.0"] },
]
```

ðŸ”¸ çŸ©é™£æ¸¬è©¦: è‡ªå‹•å»ºç«‹å…©å€‹ç’°å¢ƒæ¸¬è©¦ Spark 3.5.5 å’Œ 4.0.0
ðŸ”¸ æ¯å€‹ Spark ç‰ˆæœ¬æœ‰ç¨ç«‹çš„è™›æ“¬ç’°å¢ƒå’Œä¾è³´

### ðŸ”¸ Test-Spark ç’°å¢ƒ (PySpark æ•´åˆæ¸¬è©¦)

```toml
[tool.hatch.envs.test-spark]
dependencies = [
    "pytest>=8.4,<9",
    "pytest-xdist>=3.7,<4",      # å¹³è¡Œæ¸¬è©¦
    "pytest-timeout>=2.4,<3",    # æ¸¬è©¦è¶…æ™‚
    "pytest-reportlog>=0.4,<0.5", # æ¸¬è©¦å ±å‘Š
]

[tool.hatch.envs.test-spark.extra-scripts]
install-pyspark = "\"{env:HATCH_UV}\" pip install --force-reinstall 'pyspark[connect] @ opt/spark/python/dist/pyspark-{matrix:spark}.tar.gz'"
```

å¾žæœ¬åœ° Spark åŽŸå§‹ç¢¼å®‰è£ PySpark

### ðŸ”¸ Test-Ibis ç’°å¢ƒ

```toml
[tool.hatch.envs.test-ibis]
dependencies = [
    "pyspark[connect]==3.5.5",
    "ibis-framework[pyspark]>=11,<12",
    "hypothesis>=6.58.0,<7",      # Property-based testing
    "pytest-xdist>=2.3.0,<4",     # å¹³è¡Œæ¸¬è©¦
    ...
]
path = ".venvs/test-ibis"
```

Ibis DataFrame æ¡†æž¶ç›¸å®¹æ€§æ¸¬è©¦ç’°å¢ƒ

## Build Targets

```toml
[tool.hatch.build.targets.sdist]
packages = ["python/pysail"]

[tool.hatch.build.targets.wheel]
packages = ["python/pysail"]
```

æŒ‡å®š source distribution å’Œ wheel çš„æ‰“åŒ…ç›®éŒ„

## Ruff Lint è¨­å®š

```toml
[tool.ruff.lint.per-file-ignores]
"crates/**/*.py" = ["INP001"]           # å¿½ç•¥ implicit namespace package
"python/pysail/docs/conf.py" = ["INP001"]
"python/pysail/examples/**/*.py" = ["T201"]  # å…è¨± print()
"python/pysail/tests/**/*.py" = ["S101"]     # å…è¨± assert
"scripts/**/*.py" = ["SLF001"]               # å…è¨± private member access
```

Ruff æ˜¯ Python linterï¼Œé€™è£¡è¨­å®šç‰¹å®šæª”æ¡ˆå¿½ç•¥ç‰¹å®šè¦å‰‡

## Pytest è¨­å®š

```toml
[tool.pytest.ini_options]
testpaths = ["python"]
```

pytest æ¸¬è©¦ç›®éŒ„è¨­å®šã€‚è¨»è§£èªªæ˜Žä¸è¦åœ¨é€™è£¡åŠ å…¶ä»–è¨­å®šï¼Œæ‡‰è©²ç”¨ conftest.py hook
