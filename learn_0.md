# Tonic å¦‚ä½•ç”Ÿæˆ Server ç«¯èˆ‡ Client ç«¯é‚è¼¯

é€™ç¯‡æ–‡ç« æ·±å…¥æ¢è¨ Tonicï¼ˆRust çš„ gRPC æ¡†æ¶ï¼‰æ˜¯å¦‚ä½•å¾ `.proto` æ–‡ä»¶ç”Ÿæˆå®Œæ•´çš„ Server ç«¯èˆ‡ Client ç«¯ä»£ç¢¼çš„ã€‚æˆ‘å€‘æœƒè¿½è¹¤æ•´å€‹ä»£ç¢¼ç”Ÿæˆæµç¨‹ï¼Œå¾ build.rs åŸ·è¡Œåˆ°æœ€çµ‚çš„ Rust ä»£ç¢¼ã€‚

---

## å®Œæ•´æµç¨‹æ¦‚è¦½

```
.proto æ–‡ä»¶
   â†“
cargo build è§¸ç™¼ build.rs
   â†“
build.rs èª¿ç”¨ tonic-build
   â†“
tonic-build èª¿ç”¨ prost-build
   â†“
prost-build èª¿ç”¨ protocï¼ˆGoogle çš„ Protobuf ç·¨è­¯å™¨ï¼‰
   â†“
protoc è§£æ .proto æ–‡ä»¶ï¼Œç”Ÿæˆ FileDescriptorSetï¼ˆä¸­é–“è¡¨ç¤ºï¼‰
   â†“
prost-build è®€å– FileDescriptorSetï¼Œç”Ÿæˆ Message structs
   â†“
tonic-build è®€å– FileDescriptorSetï¼Œç”Ÿæˆ Service trait + Server + Client
   â†“
å¯«å…¥ $OUT_DIR/spark.connect.rs
   â†“
src/lib.rs ä½¿ç”¨ include!() å®å¼•å…¥ç”Ÿæˆçš„ä»£ç¢¼
   â†“
ç·¨è­¯å™¨ç·¨è­¯æœ€çµ‚çš„ Rust ä»£ç¢¼
```

---

## ç¬¬ä¸€æ­¥ï¼šbuild.rs çš„è§¸ç™¼æ©Ÿåˆ¶

### ğŸ”¸ Cargo çš„ Build Script æ©Ÿåˆ¶

æª”æ¡ˆä½ç½®ï¼š`crates/sail-spark-connect/build.rs`

Cargo åœ¨ç·¨è­¯ crate **ä¹‹å‰**æœƒå…ˆæª¢æŸ¥æ˜¯å¦å­˜åœ¨ `build.rs` æ–‡ä»¶ã€‚å¦‚æœå­˜åœ¨ï¼Œæœƒå…ˆç·¨è­¯ä¸¦åŸ·è¡Œå®ƒã€‚

```rust
// build.rs æ˜¯ä¸€å€‹ç¨ç«‹çš„å¯åŸ·è¡Œç¨‹åº
fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("cargo:rerun-if-changed=build.rs");  // ğŸ”¥ å‘Šè¨´ Cargo ä½•æ™‚é‡æ–°é‹è¡Œ
    build_proto()?;       // ç”Ÿæˆ protobuf ä»£ç¢¼
    build_spark_config()?; // ç”Ÿæˆ Spark é…ç½®å¸¸é‡
    Ok(())
}
```

ğŸ”¸ **cargo:rerun-if-changed æŒ‡ä»¤**

é€™æ˜¯ Cargo çš„ç‰¹æ®Šè¼¸å‡ºæ ¼å¼ï¼Œç”¨æ–¼æ§åˆ¶ä½•æ™‚é‡æ–°é‹è¡Œ build.rsï¼š

```rust
println!("cargo:rerun-if-changed=build.rs");
println!("cargo:rerun-if-changed=proto/spark/connect/base.proto");
```

æ„æ€æ˜¯ï¼šåªæœ‰ç•¶ `build.rs` æˆ– `.proto` æ–‡ä»¶æ”¹è®Šæ™‚ï¼Œæ‰é‡æ–°é‹è¡Œ build scriptã€‚

ğŸ”¸ **OUT_DIR ç’°å¢ƒè®Šé‡**

Cargo åœ¨é‹è¡Œ build.rs æ™‚æœƒè¨­ç½® `OUT_DIR` ç’°å¢ƒè®Šé‡ï¼š

```rust
let out_dir = PathBuf::from(std::env::var("OUT_DIR")?);
// out_dir = "target/debug/build/sail-spark-connect-<hash>/out/"
```

é€™å€‹ç›®éŒ„æ˜¯å°ˆé–€ç”¨ä¾†å­˜æ”¾ç”Ÿæˆçš„ä»£ç¢¼çš„ã€‚

---

## ç¬¬äºŒæ­¥ï¼štonic-build çš„å·¥ä½œåŸç†

### ğŸ”¸ tonic-build çš„ API

æª”æ¡ˆä½ç½®ï¼š`crates/sail-spark-connect/build.rs:14-36`

```rust
tonic_prost_build::configure()
    .protoc_arg("--experimental_allow_proto3_optional")  // 1. å‚³éçµ¦ protoc çš„åƒæ•¸
    .file_descriptor_set_path(&descriptor_path)          // 2. ä¿å­˜ FileDescriptorSet
    .compile_well_known_types(true)                      // 3. åŒ…å« google.protobuf.* é¡å‹
    .extern_path(".google.protobuf", "::pbjson_types")   // 4. å¤–éƒ¨é¡å‹æ˜ å°„
    .build_server(true)                                   // 5. ğŸ”¥ ç”Ÿæˆ Server ç«¯ä»£ç¢¼
    .compile_with_config(
        config,
        &[
            "proto/spark/connect/base.proto",  // è¦ç·¨è­¯çš„ .proto æ–‡ä»¶åˆ—è¡¨
            // ...
        ],
        &["proto"],  // proto æ–‡ä»¶çš„æœç´¢è·¯å¾‘ï¼ˆç”¨æ–¼ importï¼‰
    )?;
```

ğŸ”¸ **é—œéµé…ç½®é¸é …**

| é…ç½® | ä½œç”¨ |
|------|------|
| `.build_server(true)` | ç”Ÿæˆ Server ç«¯ä»£ç¢¼ï¼ˆService traitã€Server builderï¼‰ |
| `.build_client(true)` | ç”Ÿæˆ Client ç«¯ä»£ç¢¼ï¼ˆé è¨­å•Ÿç”¨ï¼‰ |
| `.file_descriptor_set_path()` | ä¿å­˜ FileDescriptorSetï¼ˆç”¨æ–¼åå°„å’Œ JSON åºåˆ—åŒ–ï¼‰ |
| `.compile_well_known_types(true)` | åŒ…å« google.protobuf.Timestamp ç­‰å¸¸ç”¨é¡å‹ |
| `.extern_path()` | å°‡æŸäº› protobuf é¡å‹æ˜ å°„åˆ°å¤–éƒ¨ Rust é¡å‹ |

---

## ç¬¬ä¸‰æ­¥ï¼šprotoc ç”Ÿæˆ FileDescriptorSet

### ğŸ”¸ ä»€éº¼æ˜¯ FileDescriptorSetï¼Ÿ

`FileDescriptorSet` æ˜¯ Protobuf çš„ä¸­é–“è¡¨ç¤ºï¼ˆIntermediate Representationï¼‰ï¼Œå®ƒæ˜¯ä¸€å€‹äºŒé€²åˆ¶æ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰ `.proto` æ–‡ä»¶çš„çµæ§‹åŒ–æè¿°ã€‚

**ç‚ºä»€éº¼éœ€è¦å®ƒï¼Ÿ**

`.proto` æ–‡ä»¶æ˜¯æ–‡æœ¬æ ¼å¼ï¼Œä¸æ–¹ä¾¿ç¨‹åºè™•ç†ã€‚`protoc` æœƒå°‡å…¶è§£ææˆçµæ§‹åŒ–çš„æ•¸æ“šï¼ŒåŒ…å«ï¼š
- æ‰€æœ‰ message çš„å­—æ®µä¿¡æ¯ï¼ˆåç¨±ã€é¡å‹ã€ç·¨è™Ÿï¼‰
- æ‰€æœ‰ service çš„ RPC æ–¹æ³•ä¿¡æ¯
- æ‰€æœ‰ enum çš„å€¼
- è¨»é‡‹ã€é¸é …ç­‰å…ƒä¿¡æ¯

### ğŸ”¸ FileDescriptorSet çš„çµæ§‹

```protobuf
// google/protobuf/descriptor.protoï¼ˆProtobuf è‡ªå¸¶çš„å®šç¾©ï¼‰
message FileDescriptorSet {
  repeated FileDescriptorProto file = 1;
}

message FileDescriptorProto {
  optional string name = 1;          // æ–‡ä»¶å "spark/connect/base.proto"
  optional string package = 2;       // åŒ…å "spark.connect"
  repeated DescriptorProto message_type = 4;  // æ‰€æœ‰ message å®šç¾©
  repeated EnumDescriptorProto enum_type = 5; // æ‰€æœ‰ enum å®šç¾©
  repeated ServiceDescriptorProto service = 6; // ğŸ”¥ æ‰€æœ‰ service å®šç¾©
  // ...
}

message ServiceDescriptorProto {
  optional string name = 1;  // "SparkConnectService"
  repeated MethodDescriptorProto method = 2;  // æ‰€æœ‰ RPC æ–¹æ³•
}

message MethodDescriptorProto {
  optional string name = 1;              // "ExecutePlan"
  optional string input_type = 2;        // ".spark.connect.ExecutePlanRequest"
  optional string output_type = 3;       // ".spark.connect.ExecutePlanResponse"
  optional bool client_streaming = 5;    // false
  optional bool server_streaming = 6;    // trueï¼ˆå› ç‚ºæœ‰ stream é—œéµå­—ï¼‰
}
```

### ğŸ”¸ æŸ¥çœ‹ç”Ÿæˆçš„ FileDescriptorSet

Sail ä¿å­˜äº†é€™å€‹æ–‡ä»¶ï¼š

```bash
$ ls -lh target/debug/build/sail-spark-connect-*/out/spark_connect_descriptor.bin
-rw-r--r--  237K spark_connect_descriptor.bin
```

å¯ä»¥ç”¨ `protoc` è§£ç¢¼å®ƒï¼š

```bash
$ protoc --decode=google.protobuf.FileDescriptorSet \
    google/protobuf/descriptor.proto \
    < target/debug/build/sail-spark-connect-*/out/spark_connect_descriptor.bin
```

---

## ç¬¬å››æ­¥ï¼šprost-build ç”Ÿæˆ Message Structs

### ğŸ”¸ prost-build çš„å·¥ä½œæµç¨‹

`prost` æ˜¯ Rust çš„ Protocol Buffers å¯¦ä½œï¼ˆé¡ä¼¼ Java çš„ protobuf-javaï¼‰ã€‚

**å·¥ä½œæµç¨‹**ï¼š

1. è®€å– FileDescriptorSet
2. éæ­·æ‰€æœ‰ `DescriptorProto`ï¼ˆmessage å®šç¾©ï¼‰
3. ç‚ºæ¯å€‹ message ç”Ÿæˆå°æ‡‰çš„ Rust struct
4. ç‚ºæ¯å€‹å­—æ®µæ·»åŠ  `#[prost(...)]` å±¬æ€§å®
5. å¯¦ä½œ `prost::Message` traitï¼ˆæä¾›åºåˆ—åŒ–/ååºåˆ—åŒ–æ–¹æ³•ï¼‰

### ğŸ”¸ ç”Ÿæˆçš„ä»£ç¢¼ç¯„ä¾‹

**Protobuf å®šç¾©**ï¼š

```protobuf
message ExecutePlanRequest {
  string session_id = 1;
  UserContext user_context = 2;
  Plan plan = 3;
  optional string operation_id = 6;
  repeated string tags = 7;
}
```

**ç”Ÿæˆçš„ Rust ä»£ç¢¼**ï¼š

```rust
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecutePlanRequest {
    #[prost(string, tag = "1")]
    pub session_id: ::prost::alloc::string::String,

    #[prost(message, optional, tag = "2")]
    pub user_context: ::core::option::Option<UserContext>,

    #[prost(message, optional, tag = "3")]
    pub plan: ::core::option::Option<Plan>,

    #[prost(string, optional, tag = "6")]
    pub operation_id: ::core::option::Option<::prost::alloc::string::String>,

    #[prost(string, repeated, tag = "7")]
    pub tags: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
```

ğŸ”¸ **#[prost(...)] å±¬æ€§å®**

é€™äº›å±¬æ€§å®åœ¨ç·¨è­¯æ™‚æœƒè¢« `prost` çš„éç¨‹å®ï¼ˆprocedural macroï¼‰è™•ç†ï¼Œç”Ÿæˆåºåˆ—åŒ–/ååºåˆ—åŒ–ä»£ç¢¼ã€‚

```rust
// prost::Message trait æä¾›çš„æ–¹æ³•
impl prost::Message for ExecutePlanRequest {
    fn encode_raw<B>(&self, buf: &mut B) where B: BufMut {
        // å°‡ session_id ç·¨ç¢¼ç‚º tag=1 çš„å­—æ®µ
        // å°‡ user_context ç·¨ç¢¼ç‚º tag=2 çš„å­—æ®µ
        // ...
    }

    fn decode<B>(buf: B) -> Result<Self, prost::DecodeError> where B: Buf {
        // å¾äºŒé€²åˆ¶æ•¸æ“šè§£ç¢¼
    }

    fn encoded_len(&self) -> usize {
        // è¨ˆç®—åºåˆ—åŒ–å¾Œçš„é•·åº¦
    }
}
```

---

## ç¬¬äº”æ­¥ï¼štonic-build ç”Ÿæˆ Service ä»£ç¢¼ï¼ˆæ ¸å¿ƒï¼ï¼‰

é€™æ˜¯æœ€é—œéµçš„éƒ¨åˆ†ï¼tonic-build æœƒç‚ºæ¯å€‹ `service` å®šç¾©ç”Ÿæˆä¸‰éƒ¨åˆ†ä»£ç¢¼ï¼š

### ğŸ”¸ 5.1 ç”Ÿæˆ Service Trait

**Protobuf å®šç¾©**ï¼š

```protobuf
service SparkConnectService {
  rpc ExecutePlan(ExecutePlanRequest) returns (stream ExecutePlanResponse);
  rpc AnalyzePlan(AnalyzePlanRequest) returns (AnalyzePlanResponse);
  rpc Config(ConfigRequest) returns (ConfigResponse);
}
```

**ç”Ÿæˆçš„ Trait**ï¼š

```rust
#[async_trait]
pub trait SparkConnectService: Send + Sync + 'static {
    // å°æ–¼ server streaming RPCï¼Œç”Ÿæˆé—œè¯é¡å‹
    type ExecutePlanStream: futures::Stream<
            Item = Result<ExecutePlanResponse, tonic::Status>
        > + Send + 'static;

    // ç”Ÿæˆ async æ–¹æ³•
    async fn execute_plan(
        &self,
        request: tonic::Request<ExecutePlanRequest>,
    ) -> Result<tonic::Response<Self::ExecutePlanStream>, tonic::Status>;

    // Unary RPC ç›´æ¥è¿”å› Response
    async fn analyze_plan(
        &self,
        request: tonic::Request<AnalyzePlanRequest>,
    ) -> Result<tonic::Response<AnalyzePlanResponse>, tonic::Status>;

    async fn config(
        &self,
        request: tonic::Request<ConfigRequest>,
    ) -> Result<tonic::Response<ConfigResponse>, tonic::Status>;
}
```

ğŸ”¸ **ä»£ç¢¼ç”Ÿæˆé‚è¼¯ï¼ˆtonic-build å…§éƒ¨ï¼‰**

```rust
// tonic-build çš„å…§éƒ¨é‚è¼¯ï¼ˆç°¡åŒ–ç‰ˆï¼‰
for service in file_descriptor.service {
    let trait_name = service.name;  // "SparkConnectService"

    for method in service.method {
        let method_name = to_snake_case(method.name);  // "execute_plan"
        let input_type = method.input_type;   // ".spark.connect.ExecutePlanRequest"
        let output_type = method.output_type; // ".spark.connect.ExecutePlanResponse"
        let is_server_streaming = method.server_streaming;

        if is_server_streaming {
            // ç”Ÿæˆé—œè¯é¡å‹ï¼ˆAssociated Typeï¼‰
            generate_associated_type(method_name, output_type);
        }

        // ç”Ÿæˆ async fn ç°½å
        generate_method_signature(method_name, input_type, output_type, is_server_streaming);
    }
}
```

### ğŸ”¸ 5.2 ç”Ÿæˆ Server Builder

**ç”Ÿæˆçš„ Server ä»£ç¢¼**ï¼ˆç°¡åŒ–ç‰ˆï¼‰ï¼š

```rust
pub mod spark_connect_service_server {
    pub struct SparkConnectServiceServer<T> {
        inner: Arc<T>,  // T æ˜¯å¯¦ä½œäº† SparkConnectService trait çš„é¡å‹
        // ... å£“ç¸®ã€æ¶ˆæ¯å¤§å°é™åˆ¶ç­‰é…ç½®
    }

    impl<T: SparkConnectService> SparkConnectServiceServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }

        pub fn from_arc(inner: Arc<T>) -> Self {
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
    }
}
```

### ğŸ”¸ 5.3 ç”Ÿæˆ HTTP è·¯ç”±é‚è¼¯ï¼ˆæœ€æ ¸å¿ƒï¼ï¼‰

é€™æ˜¯ tonic-build æœ€è¤‡é›œçš„éƒ¨åˆ†ï¼šå°‡ HTTP/2 è«‹æ±‚è·¯ç”±åˆ°å°æ‡‰çš„ trait æ–¹æ³•ã€‚

**ç”Ÿæˆçš„ä»£ç¢¼**ï¼ˆç°¡åŒ–ç‰ˆï¼Œå¯¦éš›ä»£ç¢¼æ›´è¤‡é›œï¼‰ï¼š

```rust
impl<T: SparkConnectService> tonic::codegen::Service<http::Request<Body>>
    for SparkConnectServiceServer<T>
{
    type Response = http::Response<tonic::body::BoxBody>;
    type Error = std::convert::Infallible;
    type Future = BoxFuture<Self::Response, Self::Error>;

    fn poll_ready(&mut self, _cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        Poll::Ready(Ok(()))
    }

    // ğŸ”¥ æ ¸å¿ƒï¼šæ ¹æ“š HTTP è·¯å¾‘è·¯ç”±åˆ°å°æ‡‰çš„æ–¹æ³•
    fn call(&mut self, req: http::Request<Body>) -> Self::Future {
        let inner = self.inner.clone();

        match req.uri().path() {
            "/spark.connect.SparkConnectService/ExecutePlan" => {
                // 1. ååºåˆ—åŒ–è«‹æ±‚
                let codec = tonic::codec::ProstCodec::default();
                let mut grpc = tonic::server::Grpc::new(codec);

                // 2. èª¿ç”¨ trait æ–¹æ³•
                Box::pin(async move {
                    let res = grpc.server_streaming(inner, req).await;
                    Ok(res)
                })
            }

            "/spark.connect.SparkConnectService/AnalyzePlan" => {
                // Unary RPC è™•ç†
                Box::pin(async move {
                    let codec = tonic::codec::ProstCodec::default();
                    let mut grpc = tonic::server::Grpc::new(codec);
                    let res = grpc.unary(inner, req).await;
                    Ok(res)
                })
            }

            "/spark.connect.SparkConnectService/Config" => {
                // ...
            }

            _ => {
                // 404 Not Found
                Box::pin(async move {
                    Ok(http::Response::builder()
                        .status(404)
                        .body(empty_body())
                        .unwrap())
                })
            }
        }
    }
}
```

ğŸ”¸ **HTTP è·¯å¾‘æ˜ å°„**

gRPC ä½¿ç”¨ HTTP/2 ä½œç‚ºå‚³è¼¸å±¤ï¼Œæ¯å€‹ RPC æ–¹æ³•å°æ‡‰ä¸€å€‹ HTTP è·¯å¾‘ï¼š

```
POST /spark.connect.SparkConnectService/ExecutePlan
POST /spark.connect.SparkConnectService/AnalyzePlan
POST /spark.connect.SparkConnectService/Config
```

è·¯å¾‘æ ¼å¼ï¼š`/<package>.<service>/<method>`

---

## ç¬¬å…­æ­¥ï¼šè©³ç´°çš„è«‹æ±‚è™•ç†æµç¨‹

è®“æˆ‘å€‘æ·±å…¥çœ‹ `grpc.server_streaming()` åšäº†ä»€éº¼ï¼š

```rust
// tonic å…§éƒ¨çš„ grpc.server_streaming() æ–¹æ³•ï¼ˆç°¡åŒ–ç‰ˆï¼‰
pub async fn server_streaming<T, S>(
    &mut self,
    service: Arc<T>,
    req: http::Request<Body>,
) -> http::Response<BoxBody>
where
    T: SparkConnectService,
    S: futures::Stream<Item = Result<ExecutePlanResponse, Status>>,
{
    // 1. å¾ HTTP body è®€å–äºŒé€²åˆ¶æ•¸æ“š
    let body = req.into_body();
    let mut body_bytes = Vec::new();
    while let Some(chunk) = body.next().await {
        body_bytes.extend_from_slice(&chunk?);
    }

    // 2. ä½¿ç”¨ prost ååºåˆ—åŒ–ç‚º ExecutePlanRequest
    let request_message = ExecutePlanRequest::decode(&body_bytes[..])?;

    // 3. åŒ…è£æˆ tonic::Requestï¼ˆæ·»åŠ  metadataï¼‰
    let request = tonic::Request::new(request_message);

    // 4. ğŸ”¥ èª¿ç”¨å¯¦ä½œçš„ trait æ–¹æ³•
    let response = service.execute_plan(request).await?;

    // 5. å–å‡ºéŸ¿æ‡‰æµ
    let mut response_stream = response.into_inner();

    // 6. å‰µå»º HTTP/2 response
    let (tx, rx) = mpsc::channel(128);

    // 7. Spawn ç•°æ­¥ä»»å‹™ï¼Œå°‡æµä¸­çš„æ¯å€‹ ExecutePlanResponse åºåˆ—åŒ–ä¸¦ç™¼é€
    tokio::spawn(async move {
        while let Some(item) = response_stream.next().await {
            match item {
                Ok(response_message) => {
                    // ä½¿ç”¨ prost åºåˆ—åŒ–ç‚ºäºŒé€²åˆ¶
                    let mut buf = Vec::new();
                    response_message.encode(&mut buf)?;

                    // ç™¼é€åˆ° HTTP/2 æµ
                    tx.send(Ok(buf)).await?;
                }
                Err(status) => {
                    // ç™¼é€éŒ¯èª¤ç‹€æ…‹
                    tx.send(Err(status)).await?;
                    break;
                }
            }
        }
    });

    // 8. è¿”å› HTTP response
    http::Response::builder()
        .status(200)
        .header("content-type", "application/grpc")
        .header("grpc-encoding", "identity")
        .body(BoxBody::new(ReceiverStream::new(rx)))
        .unwrap()
}
```

---

## ç¬¬ä¸ƒæ­¥ï¼šä»£ç¢¼å¯«å…¥èˆ‡ Include

### ğŸ”¸ å¯«å…¥ç”Ÿæˆçš„ä»£ç¢¼

tonic-build å°‡æ‰€æœ‰ç”Ÿæˆçš„ä»£ç¢¼å¯«å…¥ä¸€å€‹æ–‡ä»¶ï¼š

```rust
// tonic-build å…§éƒ¨é‚è¼¯
let output_file = out_dir.join("spark.connect.rs");
let mut file = File::create(output_file)?;

// å¯«å…¥æ–‡ä»¶é ­
writeln!(file, "// This file is @generated by prost-build.")?;

// å¯«å…¥æ‰€æœ‰ Message structs
for message in messages {
    writeln!(file, "{}", generate_message_struct(message))?;
}

// å¯«å…¥æ‰€æœ‰ Service traits
for service in services {
    writeln!(file, "{}", generate_service_trait(service))?;
    writeln!(file, "{}", generate_server_builder(service))?;
    writeln!(file, "{}", generate_client_stub(service))?;
}
```

### ğŸ”¸ Include ç”Ÿæˆçš„ä»£ç¢¼

æª”æ¡ˆä½ç½®ï¼š`crates/sail-spark-connect/src/lib.rs:18-26`

```rust
pub mod spark {
    pub mod connect {
        // ğŸ”¥ é€™å€‹å®åœ¨ç·¨è­¯æ™‚æœƒå±•é–‹ç‚ºï¼š
        // include!(concat!(env!("OUT_DIR"), "/spark.connect.rs"));
        tonic::include_proto!("spark.connect");
    }
}
```

ğŸ”¸ **include!() å®çš„å·¥ä½œåŸç†**

`include!()` æ˜¯ Rust ç·¨è­¯å™¨çš„å…§å»ºå®ï¼Œæœƒåœ¨ç·¨è­¯æ™‚å°‡æ–‡ä»¶å…§å®¹**åŸåœ°å±•é–‹**ï¼š

```rust
// å±•é–‹å‰
tonic::include_proto!("spark.connect");

// å±•é–‹å¾Œï¼ˆç°¡åŒ–ï¼‰
include!(concat!(env!("OUT_DIR"), "/spark.connect.rs"));

// é€²ä¸€æ­¥å±•é–‹ï¼ˆç·¨è­¯å™¨åšçš„ï¼‰
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecutePlanRequest { /* ... */ }

#[async_trait]
pub trait SparkConnectService: Send + Sync + 'static { /* ... */ }

pub mod spark_connect_service_server { /* ... */ }

pub mod spark_connect_service_client { /* ... */ }
```

---

## å®Œæ•´çš„ä»£ç¢¼ç”Ÿæˆæ™‚åºåœ–

```
æ™‚é–“è»¸ï¼ˆCompile Timeï¼‰                     æ–‡ä»¶ç³»çµ±
    |
    | 1. cargo build
    |    â†“
    | 2. ç·¨è­¯ä¸¦åŸ·è¡Œ build.rs
    |    â†“
    | 3. build.rs èª¿ç”¨ tonic_prost_build::configure()
    |    â†“
    | 4. tonic-build èª¿ç”¨ protoc
    |    â†“                                  base.proto
    |    |                                      â†“
    | 5. protoc è§£æ .proto                 [protoc]
    |    â†“                                      â†“
    |    |                              spark_connect_descriptor.bin
    | 6. ç”Ÿæˆ FileDescriptorSet              â†“
    |    â†“
    | 7. prost-build è®€å– FileDescriptorSet
    |    â†“
    | 8. ç‚ºæ¯å€‹ message ç”Ÿæˆ Rust struct
    |    â†“
    | 9. tonic-build è®€å– FileDescriptorSet
    |    â†“
    | 10. ç‚ºæ¯å€‹ service ç”Ÿæˆ trait
    |    â†“
    | 11. ç”Ÿæˆ Server builder
    |    â†“
    | 12. ç”Ÿæˆ Client stub
    |    â†“
    | 13. å°‡æ‰€æœ‰ä»£ç¢¼å¯«å…¥æ–‡ä»¶               spark.connect.rs
    |    â†“                                      â†“
    | 14. build.rs åŸ·è¡Œå®Œæˆ
    |    â†“
    | 15. Cargo ç·¨è­¯ src/lib.rs
    |    â†“
    | 16. é‡åˆ° tonic::include_proto!()
    |    â†“
    | 17. å±•é–‹ç‚º include!($OUT_DIR/spark.connect.rs)
    |    â†“
    | 18. ç·¨è­¯å™¨å°‡ç”Ÿæˆçš„ä»£ç¢¼åŸåœ°æ’å…¥         [ç·¨è­¯å™¨å…§å­˜]
    |    â†“
    | 19. ç·¨è­¯æ•´å€‹ crate
    |    â†“
    | 20. ç”Ÿæˆæœ€çµ‚çš„äºŒé€²åˆ¶æ–‡ä»¶              libsail_spark_connect.rlib
    |
```

---

## é—œéµè¨­è¨ˆæ€æƒ³

### ğŸ”¸ ç‚ºä»€éº¼ä½¿ç”¨ Traitï¼Ÿ

Tonic ç”Ÿæˆçš„æ˜¯ **trait** è€Œä¸æ˜¯å…·é«”çš„å¯¦ä½œï¼Œé€™æ˜¯ä¸€å€‹ç²¾å¦™çš„è¨­è¨ˆï¼š

**å„ªé»**ï¼š
1. **è§£è€¦**ï¼šgRPC æ¡†æ¶ä»£ç¢¼èˆ‡æ¥­å‹™é‚è¼¯å®Œå…¨åˆ†é›¢
2. **éˆæ´»æ€§**ï¼šä½ å¯ä»¥ç”¨ä»»ä½•æ–¹å¼å¯¦ä½œ traitï¼ˆä½¿ç”¨ä¸åŒçš„æ•¸æ“šåº«ã€ç·©å­˜ç­‰ï¼‰
3. **å¯æ¸¬è©¦æ€§**ï¼šå¯ä»¥è¼•é¬†å‰µå»º mock å¯¦ä½œé€²è¡Œæ¸¬è©¦
4. **é¡å‹å®‰å…¨**ï¼šç·¨è­¯å™¨å¼·åˆ¶ä½ å¯¦ä½œæ‰€æœ‰ RPC æ–¹æ³•

**å°æ¯”å…¶ä»–èªè¨€**ï¼š

```java
// Java gRPCï¼ˆç”Ÿæˆçš„æ˜¯æŠ½è±¡é¡ï¼Œéœ€è¦ç¹¼æ‰¿ï¼‰
public abstract class SparkConnectServiceImplBase {
    public void executePlan(ExecutePlanRequest req, StreamObserver<ExecutePlanResponse> observer) {
        throw new StatusRuntimeException(Status.UNIMPLEMENTED);
    }
}

// ä½ éœ€è¦ç¹¼æ‰¿
public class MyService extends SparkConnectServiceImplBase {
    @Override
    public void executePlan(...) {
        // å¯¦ä½œ
    }
}
```

```rust
// Rust gRPCï¼ˆç”Ÿæˆçš„æ˜¯ traitï¼Œéœ€è¦å¯¦ä½œï¼‰
#[async_trait]
pub trait SparkConnectService: Send + Sync + 'static {
    async fn execute_plan(...) -> Result<...>;
}

// ä½ éœ€è¦å¯¦ä½œ trait
impl SparkConnectService for MyService {
    async fn execute_plan(...) -> Result<...> {
        // å¯¦ä½œ
    }
}
```

Rust çš„ trait æ–¹å¼æ›´åŠ éˆæ´»ï¼Œå› ç‚ºï¼š
- å¯ä»¥ç‚ºä»»ä½•é¡å‹å¯¦ä½œ traitï¼ˆä¸é™æ–¼ç¹¼æ‰¿ï¼‰
- æ”¯æ´å¤šå€‹ trait çµ„åˆï¼ˆRust æ²’æœ‰ç¹¼æ‰¿ï¼Œä½†æœ‰ trait boundsï¼‰
- é›¶æˆæœ¬æŠ½è±¡ï¼ˆç·¨è­¯æ™‚å–®æ…‹åŒ–ï¼Œæ²’æœ‰è™›è¡¨é–‹éŠ·ï¼‰

### ğŸ”¸ ç‚ºä»€éº¼ä½¿ç”¨ #[async_trait]ï¼Ÿ

Rust åŸç”Ÿä¸æ”¯æ´ trait ä¸­çš„ async fnï¼Œå› ç‚º async fn æœƒè¿”å› `impl Future`ï¼Œè€Œ trait æ–¹æ³•ä¸èƒ½è¿”å› `impl Trait`ã€‚

`#[async_trait]` å®æœƒå°‡ï¼š

```rust
#[async_trait]
trait SparkConnectService {
    async fn execute_plan(&self, req: Request<ExecutePlanRequest>)
        -> Result<Response<Stream>, Status>;
}
```

è½‰æ›ç‚ºï¼š

```rust
trait SparkConnectService {
    fn execute_plan(&self, req: Request<ExecutePlanRequest>)
        -> Pin<Box<dyn Future<Output = Result<Response<Stream>, Status>> + Send + 'static>>;
}
```

é€™æ¨£å°±å¯ä»¥åœ¨ trait ä¸­ä½¿ç”¨ç•°æ­¥æ–¹æ³•äº†ã€‚

### ğŸ”¸ ç‚ºä»€éº¼ä½¿ç”¨é—œè¯é¡å‹ï¼ˆAssociated Typeï¼‰ï¼Ÿ

å°æ–¼ streaming RPCï¼Œtonic ä½¿ç”¨é—œè¯é¡å‹ï¼š

```rust
trait SparkConnectService {
    type ExecutePlanStream: Stream<Item = Result<ExecutePlanResponse, Status>> + Send;

    async fn execute_plan(...) -> Result<Response<Self::ExecutePlanStream>, Status>;
}
```

**ç‚ºä»€éº¼ä¸ç”¨æ³›å‹ï¼Ÿ**

```rust
// å¦‚æœç”¨æ³›å‹ï¼ˆä¸æ¨è–¦ï¼‰
trait SparkConnectService<S: Stream<...>> {
    async fn execute_plan(...) -> Result<Response<S>, Status>;
}
```

å•é¡Œï¼š
1. æ¯å€‹å¯¦ä½œå¿…é ˆæŒ‡å®šæµé¡å‹ï¼š`impl SparkConnectService<MyStream> for MyService`
2. Server builder ä¹Ÿéœ€è¦æ³›å‹ï¼š`SparkConnectServiceServer<T, S>`
3. è¤‡é›œåº¦çˆ†ç‚¸

**ä½¿ç”¨é—œè¯é¡å‹çš„å„ªé»**ï¼š
1. å¯¦ä½œè€…æ±ºå®šæµé¡å‹ï¼š`type ExecutePlanStream = MyStream;`
2. Server builder åªéœ€è¦ä¸€å€‹æ³›å‹ï¼š`SparkConnectServiceServer<T>`
3. æ›´æ¸…æ™°çš„é¡å‹é—œä¿‚

---

## ç¸½çµï¼šTonic ä»£ç¢¼ç”Ÿæˆçš„ç²¾å¦™ä¹‹è™•

### ğŸ”¸ ç·¨è­¯æ™‚ä»£ç¢¼ç”Ÿæˆçš„å„ªå‹¢

1. **é›¶é‹è¡Œæ™‚é–‹éŠ·**ï¼šæ‰€æœ‰ä»£ç¢¼åœ¨ç·¨è­¯æ™‚ç”Ÿæˆï¼Œæ²’æœ‰åå°„æˆ–å‹•æ…‹åˆ†ç™¼
2. **é¡å‹å®‰å…¨**ï¼šç·¨è­¯å™¨æª¢æŸ¥æ‰€æœ‰é¡å‹ï¼Œé¿å…é‹è¡Œæ™‚éŒ¯èª¤
3. **IDE æ”¯æ´**ï¼šç”Ÿæˆçš„ä»£ç¢¼å¯ä»¥è¢« rust-analyzer åˆ†æï¼Œæä¾›è‡ªå‹•è£œå…¨
4. **å¯èª¿è©¦**ï¼šå¯ä»¥æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç¢¼ï¼Œç†è§£æ¯ä¸€è¡Œåœ¨åšä»€éº¼

### ğŸ”¸ Tonic çš„è¨­è¨ˆå“²å­¸

1. **æœ€å°åŒ–æ‰‹å¯«ä»£ç¢¼**ï¼šåªéœ€è¦å¯¦ä½œ trait æ–¹æ³•ï¼Œå…¶ä»–éƒ½è‡ªå‹•ç”Ÿæˆ
2. **å”è­°å„ªå…ˆ**ï¼š`.proto` æ–‡ä»¶æ˜¯å”¯ä¸€çš„çœŸç›¸ä¾†æº
3. **Rust æ…£ç”¨æ³•**ï¼šç”Ÿæˆçš„ä»£ç¢¼éµå¾ª Rust çš„æœ€ä½³å¯¦è¸
4. **å¯æ“´å±•æ€§**ï¼šå¯ä»¥é€šé `tonic::include_proto!` å’Œè‡ªå®šç¾©é…ç½®æ“´å±•

### ğŸ”¸ èˆ‡å…¶ä»–èªè¨€ gRPC æ¡†æ¶çš„å°æ¯”

| èªè¨€ | æ¡†æ¶ | ä»£ç¢¼ç”Ÿæˆæ™‚æ©Ÿ | æŠ½è±¡æ–¹å¼ |
|------|------|--------------|----------|
| Rust | Tonic | ç·¨è­¯æ™‚ï¼ˆbuild.rsï¼‰ | Trait |
| Java | grpc-java | ç·¨è­¯å‰ï¼ˆprotoc æ’ä»¶ï¼‰ | Abstract Class |
| Go | grpc-go | ç·¨è­¯å‰ï¼ˆprotoc æ’ä»¶ï¼‰ | Interface |
| Python | grpcio | é‹è¡Œå‰ï¼ˆprotoc æ’ä»¶ï¼‰ | Duck Typing |

Rust çš„ç·¨è­¯æ™‚ç”Ÿæˆæ˜¯æœ€ç¨ç‰¹çš„ï¼Œå› ç‚ºå®ƒèˆ‡ Cargo çš„ build script æ©Ÿåˆ¶æ·±åº¦é›†æˆã€‚

---

## å¯¦æˆ°ï¼šæŸ¥çœ‹ç”Ÿæˆçš„ä»£ç¢¼

### ğŸ”¸ æ­¥é©Ÿ 1ï¼šç·¨è­¯é …ç›®

```bash
cd /Users/stanhsu/projects/sail
cargo build -p sail-spark-connect
```

### ğŸ”¸ æ­¥é©Ÿ 2ï¼šæ‰¾åˆ°ç”Ÿæˆçš„ä»£ç¢¼

```bash
# æ‰¾åˆ° OUT_DIR
find target/debug/build -name "spark.connect.rs"

# è¼¸å‡ºï¼štarget/debug/build/sail-spark-connect-<hash>/out/spark.connect.rs
```

### ğŸ”¸ æ­¥é©Ÿ 3ï¼šæŸ¥çœ‹ç”Ÿæˆçš„ä»£ç¢¼

```bash
# æŸ¥çœ‹æ–‡ä»¶å¤§å°
ls -lh target/debug/build/sail-spark-connect-*/out/spark.connect.rs
# -rw-r--r--  300K spark.connect.rs

# æŸ¥çœ‹å‰ 100 è¡Œ
head -100 target/debug/build/sail-spark-connect-*/out/spark.connect.rs

# æœç´¢ SparkConnectService trait
grep -n "pub trait SparkConnectService" target/debug/build/sail-spark-connect-*/out/spark.connect.rs
```

### ğŸ”¸ æ­¥é©Ÿ 4ï¼šç†è§£ç”Ÿæˆçš„ä»£ç¢¼çµæ§‹

```bash
# çµ±è¨ˆè¡Œæ•¸
wc -l target/debug/build/sail-spark-connect-*/out/spark.connect.rs
# ç´„ 7000+ è¡Œ

# æŸ¥çœ‹åŒ…å«çš„ä¸»è¦éƒ¨åˆ†
grep -E "^(pub struct|pub trait|pub mod|pub enum)" target/debug/build/sail-spark-connect-*/out/spark.connect.rs | head -50
```

---

## å»¶ä¼¸é–±è®€

å¦‚æœä½ æƒ³æ›´æ·±å…¥äº†è§£ Tonic çš„å…§éƒ¨å¯¦ä½œï¼Œå¯ä»¥é–±è®€ï¼š

1. **Tonic æºç¢¼**ï¼šhttps://github.com/hyperium/tonic
   - `tonic-build/src/server.rs` - Server ä»£ç¢¼ç”Ÿæˆé‚è¼¯
   - `tonic-build/src/client.rs` - Client ä»£ç¢¼ç”Ÿæˆé‚è¼¯
   - `tonic/src/server/grpc.rs` - Server é‹è¡Œæ™‚é‚è¼¯

2. **Prost æºç¢¼**ï¼šhttps://github.com/tokio-rs/prost
   - `prost-build/src/code_generator.rs` - Message ä»£ç¢¼ç”Ÿæˆ

3. **Protocol Buffers æ–‡æª”**ï¼šhttps://protobuf.dev/
   - FileDescriptorSet è¦ç¯„
   - Protobuf åºåˆ—åŒ–æ ¼å¼

4. **Rust ç•°æ­¥ç·¨ç¨‹**ï¼š
   - `async_trait` crate æ–‡æª”
   - Tokio æ–‡æª”ï¼ˆTonic åŸºæ–¼ Tokioï¼‰

---

---

## Client ç«¯ä»£ç¢¼ç”Ÿæˆ

åœ¨ `build.rs` ä¸­ï¼Œtonic-build é è¨­æœƒåŒæ™‚ç”Ÿæˆ Server å’Œ Client ç«¯ä»£ç¢¼ï¼š

```rust
tonic_prost_build::configure()
    .build_server(true)   // ğŸ”¥ ç”Ÿæˆ Server ç«¯
    .build_client(true)   // ğŸ”¥ ç”Ÿæˆ Client ç«¯ï¼ˆé è¨­å·²å•Ÿç”¨ï¼‰
    .compile_with_config(...)
```

### ğŸ”¸ ç”Ÿæˆçš„ Client çµæ§‹

tonic-build æœƒç‚ºæ¯å€‹ service ç”Ÿæˆä¸€å€‹ `{ServiceName}Client` çµæ§‹é«”ã€‚

æª”æ¡ˆä½ç½®ï¼š`target/debug/build/sail-spark-connect-*/out/spark.connect.rs`ï¼ˆç”Ÿæˆçš„ä»£ç¢¼ï¼‰

**å®Œæ•´çš„ Client ä»£ç¢¼çµæ§‹**ï¼š

```rust
pub mod spark_connect_service_client {
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;

    // ğŸ”¥ Client çµæ§‹é«”
    #[derive(Debug, Clone)]
    pub struct SparkConnectServiceClient<T> {
        inner: tonic::client::Grpc<T>,  // å°è£åº•å±¤ gRPC é€£æ¥
    }

    // ğŸ”¥ ä¾¿åˆ©æ–¹æ³•ï¼šç›´æ¥é€£æ¥åˆ° endpoint
    impl SparkConnectServiceClient<tonic::transport::Channel> {
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }

    // ğŸ”¥ æ³›å‹å¯¦ä½œï¼šæ”¯æ´ä»»ä½•å‚³è¼¸å±¤
    impl<T> SparkConnectServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }

        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> SparkConnectServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
        {
            // æ·»åŠ æ””æˆªå™¨ï¼ˆç”¨æ–¼èº«ä»½é©—è­‰ã€æ—¥èªŒç­‰ï¼‰
            SparkConnectServiceClient::new(InterceptedService::new(inner, interceptor))
        }

        // ğŸ”¥ RPC æ–¹æ³•ï¼šExecutePlanï¼ˆServer Streamingï¼‰
        pub async fn execute_plan(
            &mut self,
            request: impl tonic::IntoRequest<super::ExecutePlanRequest>,
        ) -> Result<
            tonic::Response<tonic::codec::Streaming<super::ExecutePlanResponse>>,
            tonic::Status,
        > {
            // 1. ç¢ºä¿é€£æ¥å°±ç·’
            self.inner.ready().await.map_err(|e| {
                tonic::Status::unknown(format!("Service was not ready: {}", e.into()))
            })?;

            // 2. å‰µå»º codecï¼ˆç”¨æ–¼åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼‰
            let codec = tonic_prost::ProstCodec::default();

            // 3. è¨­ç½® HTTP è·¯å¾‘
            let path = http::uri::PathAndQuery::from_static(
                "/spark.connect.SparkConnectService/ExecutePlan",
            );

            // 4. è½‰æ›è«‹æ±‚
            let mut req = request.into_request();
            req.extensions_mut().insert(
                GrpcMethod::new("spark.connect.SparkConnectService", "ExecutePlan"),
            );

            // 5. ğŸ”¥ ç™¼é€ server_streaming è«‹æ±‚
            self.inner.server_streaming(req, path, codec).await
        }

        // ğŸ”¥ RPC æ–¹æ³•ï¼šAnalyzePlanï¼ˆUnaryï¼‰
        pub async fn analyze_plan(
            &mut self,
            request: impl tonic::IntoRequest<super::AnalyzePlanRequest>,
        ) -> Result<tonic::Response<super::AnalyzePlanResponse>, tonic::Status> {
            self.inner.ready().await.map_err(|e| {
                tonic::Status::unknown(format!("Service was not ready: {}", e.into()))
            })?;

            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/spark.connect.SparkConnectService/AnalyzePlan",
            );

            let mut req = request.into_request();
            req.extensions_mut().insert(
                GrpcMethod::new("spark.connect.SparkConnectService", "AnalyzePlan"),
            );

            // ğŸ”¥ ç™¼é€ unary è«‹æ±‚
            self.inner.unary(req, path, codec).await
        }

        // ... å…¶ä»– RPC æ–¹æ³•
    }
}
```

---

### ğŸ”¸ Client çš„å·¥ä½œæµç¨‹

è®“æˆ‘å€‘è¿½è¹¤ä¸€å€‹ Client è«‹æ±‚çš„å®Œæ•´æµç¨‹ï¼š

```rust
// ä½¿ç”¨ Client çš„ç¤ºä¾‹ä»£ç¢¼
use spark::connect::spark_connect_service_client::SparkConnectServiceClient;
use spark::connect::ExecutePlanRequest;

async fn call_server() -> Result<(), Box<dyn std::error::Error>> {
    // æ­¥é©Ÿ 1: é€£æ¥åˆ° Server
    let mut client = SparkConnectServiceClient::connect("http://localhost:50051").await?;

    // æ­¥é©Ÿ 2: å‰µå»ºè«‹æ±‚
    let request = ExecutePlanRequest {
        session_id: "my-session".to_string(),
        // ... å…¶ä»–å­—æ®µ
    };

    // æ­¥é©Ÿ 3: ç™¼é€è«‹æ±‚ï¼ˆå…§éƒ¨æµç¨‹ï¼‰
    let response = client.execute_plan(request).await?;

    // æ­¥é©Ÿ 4: è™•ç†éŸ¿æ‡‰æµ
    let mut stream = response.into_inner();
    while let Some(item) = stream.message().await? {
        println!("Received: {:?}", item);
    }

    Ok(())
}
```

**å…§éƒ¨æµç¨‹è©³è§£**ï¼š

```
1. client.execute_plan(request)
   â†“
2. self.inner.ready().await
   - æª¢æŸ¥åº•å±¤ HTTP/2 é€£æ¥æ˜¯å¦å°±ç·’
   - å¦‚æœé€£æ¥æ± æœ‰å¯ç”¨é€£æ¥ï¼Œç›´æ¥ä½¿ç”¨
   - å¦å‰‡ç­‰å¾…é€£æ¥å¯ç”¨
   â†“
3. request.into_request()
   - å°‡ ExecutePlanRequest åŒ…è£æˆ tonic::Request<ExecutePlanRequest>
   - Request åŒ…å« metadataï¼ˆé¡ä¼¼ HTTP headersï¼‰
   â†“
4. req.extensions_mut().insert(GrpcMethod::new(...))
   - æ·»åŠ æ–¹æ³•å…ƒä¿¡æ¯ï¼ˆç”¨æ–¼è¿½è¹¤å’Œæ—¥èªŒï¼‰
   â†“
5. self.inner.server_streaming(req, path, codec).await
   â†“
   5.1 ä½¿ç”¨ prost åºåˆ—åŒ– ExecutePlanRequest
       - ExecutePlanRequest::encode(&mut buf)
       - ç”ŸæˆäºŒé€²åˆ¶æ•¸æ“š
   â†“
   5.2 å‰µå»º HTTP/2 POST è«‹æ±‚
       POST /spark.connect.SparkConnectService/ExecutePlan HTTP/2
       Content-Type: application/grpc

       [äºŒé€²åˆ¶æ•¸æ“š]
   â†“
   5.3 ç™¼é€åˆ° Server
   â†“
   5.4 æ¥æ”¶ HTTP/2 éŸ¿æ‡‰æµ
   â†“
   5.5 å‰µå»º tonic::codec::Streaming<ExecutePlanResponse>
       - é€™æ˜¯ä¸€å€‹ Streamï¼Œæ¯æ¬¡èª¿ç”¨ .message().await æœƒï¼š
         a. å¾ HTTP/2 æµè®€å–ä¸€å€‹æ¶ˆæ¯å¹€
         b. ä½¿ç”¨ prost ååºåˆ—åŒ–ç‚º ExecutePlanResponse
         c. è¿”å›çµ¦èª¿ç”¨è€…
   â†“
6. è¿”å› Result<Response<Streaming<ExecutePlanResponse>>, Status>
```

---

### ğŸ”¸ Client ç«¯èˆ‡ Server ç«¯çš„å°æ‡‰é—œä¿‚

| æ¦‚å¿µ | Server ç«¯ | Client ç«¯ |
|------|-----------|-----------|
| **æŠ½è±¡æ–¹å¼** | Traitï¼ˆéœ€è¦å¯¦ä½œï¼‰ | Structï¼ˆç›´æ¥ä½¿ç”¨ï¼‰ |
| **ç”Ÿæˆçš„é¡å‹** | `SparkConnectService` trait | `SparkConnectServiceClient<T>` struct |
| **æ–¹æ³•ç°½å** | `async fn execute_plan(&self, req: Request<...>) -> Result<Response<Stream>, Status>` | `async fn execute_plan(&mut self, req: impl IntoRequest<...>) -> Result<Response<Streaming<...>>, Status>` |
| **å‚³è¼¸å±¤** | ç¶å®šåˆ°å…·é«”çš„ TCP listener | æ³›å‹ `T: GrpcService<Body>` |
| **ä½¿ç”¨æ–¹å¼** | `impl SparkConnectService for MyService` | `SparkConnectServiceClient::connect(url).await` |
| **æµé¡å‹** | è‡ªå®šç¾© `type ExecutePlanStream` | å›ºå®š `tonic::codec::Streaming<Response>` |

---

### ğŸ”¸ Client çš„é—œéµè¨­è¨ˆ

**1. æ³›å‹å‚³è¼¸å±¤**

```rust
pub struct SparkConnectServiceClient<T> {
    inner: tonic::client::Grpc<T>,
}
```

`T` å¯ä»¥æ˜¯ï¼š
- `tonic::transport::Channel` - é è¨­çš„ HTTP/2 å‚³è¼¸
- è‡ªå®šç¾©å‚³è¼¸å±¤ï¼ˆä¾‹å¦‚ Unix domain socketï¼‰
- Mock å‚³è¼¸ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰

**2. IntoRequest trait**

```rust
pub async fn execute_plan(
    &mut self,
    request: impl tonic::IntoRequest<super::ExecutePlanRequest>,
) -> ...
```

`IntoRequest` å…è¨±ä»¥ä¸‹å¹¾ç¨®èª¿ç”¨æ–¹å¼ï¼š

```rust
// æ–¹å¼ 1: ç›´æ¥å‚³é Message
client.execute_plan(ExecutePlanRequest { ... }).await?;

// æ–¹å¼ 2: å‚³é tonic::Requestï¼ˆå¯ä»¥æ·»åŠ  metadataï¼‰
let mut req = tonic::Request::new(ExecutePlanRequest { ... });
req.metadata_mut().insert("authorization", "Bearer token".parse()?);
client.execute_plan(req).await?;
```

**3. Interceptor æ¨¡å¼**

```rust
pub fn with_interceptor<F>(
    inner: T,
    interceptor: F,
) -> SparkConnectServiceClient<InterceptedService<T, F>>
where
    F: tonic::service::Interceptor,
```

Interceptor å¯ä»¥åœ¨æ¯å€‹è«‹æ±‚ç™¼é€å‰ä¿®æ”¹å®ƒï¼Œå¸¸ç”¨æ–¼ï¼š

```rust
// æ·»åŠ èº«ä»½é©—è­‰
fn auth_interceptor(mut req: Request<()>) -> Result<Request<()>, Status> {
    let token = get_auth_token()?;
    req.metadata_mut().insert(
        "authorization",
        format!("Bearer {}", token).parse().unwrap(),
    );
    Ok(req)
}

let client = SparkConnectServiceClient::connect(url)
    .await?
    .with_interceptor(auth_interceptor);
```

---

### ğŸ”¸ å››ç¨® RPC æ¨¡å¼çš„ Client ç«¯å¯¦ä½œ

tonic-build æ ¹æ“š RPC çš„æµé¡å‹ç”Ÿæˆä¸åŒçš„ Client æ–¹æ³•ï¼š

**1. Unary RPC**

```protobuf
rpc AnalyzePlan(AnalyzePlanRequest) returns (AnalyzePlanResponse);
```

```rust
// ç”Ÿæˆçš„ Client æ–¹æ³•
pub async fn analyze_plan(
    &mut self,
    request: impl tonic::IntoRequest<super::AnalyzePlanRequest>,
) -> Result<tonic::Response<super::AnalyzePlanResponse>, tonic::Status> {
    self.inner.unary(req, path, codec).await
    //         ^^^^^ ğŸ”¥ ä½¿ç”¨ unary æ–¹æ³•
}
```

**2. Server Streaming RPC**

```protobuf
rpc ExecutePlan(ExecutePlanRequest) returns (stream ExecutePlanResponse);
```

```rust
// ç”Ÿæˆçš„ Client æ–¹æ³•
pub async fn execute_plan(
    &mut self,
    request: impl tonic::IntoRequest<super::ExecutePlanRequest>,
) -> Result<
    tonic::Response<tonic::codec::Streaming<super::ExecutePlanResponse>>,
    //              ^^^^^^^^^^^^^^^^^^^^^^^^^ ğŸ”¥ è¿”å›ä¸€å€‹ Stream
    tonic::Status,
> {
    self.inner.server_streaming(req, path, codec).await
    //         ^^^^^^^^^^^^^^^^ ğŸ”¥ ä½¿ç”¨ server_streaming æ–¹æ³•
}

// ä½¿ç”¨æ–¹å¼
let response = client.execute_plan(request).await?;
let mut stream = response.into_inner();
while let Some(msg) = stream.message().await? {
    println!("{:?}", msg);
}
```

**3. Client Streaming RPC**

```protobuf
rpc Upload(stream UploadRequest) returns (UploadResponse);
```

```rust
// ç”Ÿæˆçš„ Client æ–¹æ³•
pub async fn upload(
    &mut self,
    request: impl tonic::IntoStreamingRequest<Message = super::UploadRequest>,
    //       ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ğŸ”¥ æ¥æ”¶ä¸€å€‹ Stream
) -> Result<tonic::Response<super::UploadResponse>, tonic::Status> {
    self.inner.client_streaming(req, path, codec).await
    //         ^^^^^^^^^^^^^^^^ ğŸ”¥ ä½¿ç”¨ client_streaming æ–¹æ³•
}

// ä½¿ç”¨æ–¹å¼
let stream = tokio_stream::iter(vec![
    UploadRequest { chunk: vec![1, 2, 3] },
    UploadRequest { chunk: vec![4, 5, 6] },
]);
let response = client.upload(stream).await?;
```

**4. Bidirectional Streaming RPC**

```protobuf
rpc Chat(stream ChatMessage) returns (stream ChatMessage);
```

```rust
// ç”Ÿæˆçš„ Client æ–¹æ³•
pub async fn chat(
    &mut self,
    request: impl tonic::IntoStreamingRequest<Message = super::ChatMessage>,
) -> Result<
    tonic::Response<tonic::codec::Streaming<super::ChatMessage>>,
    //              ^^^^^^^^^^^^^^^^^^^^^^^^^ ğŸ”¥ è¿”å›ä¸€å€‹ Stream
    tonic::Status,
> {
    self.inner.streaming(req, path, codec).await
    //         ^^^^^^^^^ ğŸ”¥ ä½¿ç”¨ streaming æ–¹æ³•
}

// ä½¿ç”¨æ–¹å¼
let input_stream = tokio_stream::iter(vec![
    ChatMessage { text: "Hello".to_string() },
    ChatMessage { text: "World".to_string() },
]);
let response = client.chat(input_stream).await?;
let mut output_stream = response.into_inner();
while let Some(msg) = output_stream.message().await? {
    println!("Received: {}", msg.text);
}
```

---

### ğŸ”¸ Client ç«¯èˆ‡ Server ç«¯çš„ä»£ç¢¼å°æ¯”

è®“æˆ‘å€‘ä¸¦æ’å°æ¯”ç›¸åŒ RPC æ–¹æ³•çš„ Server å’Œ Client å¯¦ä½œï¼š

**Server ç«¯ï¼ˆTraitï¼‰**ï¼š

```rust
#[async_trait]
pub trait SparkConnectService: Send + Sync + 'static {
    type ExecutePlanStream: Stream<Item = Result<ExecutePlanResponse, Status>> + Send;

    async fn execute_plan(
        &self,  // ğŸ”¥ &selfï¼ˆä¸å¯è®Šï¼‰
        request: tonic::Request<ExecutePlanRequest>,
    ) -> Result<tonic::Response<Self::ExecutePlanStream>, tonic::Status>;
    //                          ^^^^^^^^^^^^^^^^^^^^^^ ğŸ”¥ è‡ªå®šç¾©æµé¡å‹
}
```

**Client ç«¯ï¼ˆStructï¼‰**ï¼š

```rust
pub struct SparkConnectServiceClient<T> {
    inner: tonic::client::Grpc<T>,
}

impl<T: GrpcService<Body>> SparkConnectServiceClient<T> {
    pub async fn execute_plan(
        &mut self,  // ğŸ”¥ &mut selfï¼ˆéœ€è¦ä¿®æ”¹å…§éƒ¨ç‹€æ…‹ï¼‰
        request: impl tonic::IntoRequest<ExecutePlanRequest>,
        //       ^^^^ ğŸ”¥ IntoRequest traitï¼ˆæ›´éˆæ´»ï¼‰
    ) -> Result<
        tonic::Response<tonic::codec::Streaming<ExecutePlanResponse>>,
        //              ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ğŸ”¥ å›ºå®šçš„ Streaming é¡å‹
        tonic::Status,
    > {
        self.inner.server_streaming(request.into_request(), path, codec).await
    }
}
```

**é—œéµå·®ç•°**ï¼š

| æ–¹é¢ | Server ç«¯ | Client ç«¯ |
|------|-----------|-----------|
| `self` é¡å‹ | `&self`ï¼ˆä¸å¯è®Šï¼‰ | `&mut self`ï¼ˆéœ€è¦ä¿®æ”¹é€£æ¥ç‹€æ…‹ï¼‰ |
| è«‹æ±‚é¡å‹ | `Request<T>` | `impl IntoRequest<T>`ï¼ˆæ”¯æ´å¤šç¨®è¼¸å…¥ï¼‰ |
| æµé¡å‹ | é—œè¯é¡å‹ `Self::Stream`ï¼ˆéˆæ´»ï¼‰ | å›ºå®š `Streaming<T>`ï¼ˆçµ±ä¸€ï¼‰ |
| å¯¦ä½œæ–¹å¼ | éœ€è¦å¯¦ä½œ trait | ç›´æ¥ä½¿ç”¨ç”Ÿæˆçš„ struct |

---

### ğŸ”¸ å¯¦éš›æ¡ˆä¾‹ï¼šSail ä¸­æ²’æœ‰ä½¿ç”¨ Client

æœ‰è¶£çš„æ˜¯ï¼ŒSail æœ¬èº«ä¸¦**ä¸ä½¿ç”¨**ç”Ÿæˆçš„ Client ä»£ç¢¼ï¼

```rust
// crates/sail-spark-connect/build.rs
tonic_prost_build::configure()
    .build_server(true)   // âœ… ä½¿ç”¨ï¼šSail æ˜¯ä¸€å€‹ gRPC Server
    .build_client(true)   // âš ï¸  ç”Ÿæˆä½†ä¸ä½¿ç”¨ï¼ˆé è¨­å•Ÿç”¨ï¼‰
    .compile_with_config(...)
```

**ç‚ºä»€éº¼ä¸ä½¿ç”¨ Clientï¼Ÿ**

å› ç‚º Sail çš„æ¶æ§‹æ˜¯ï¼š

```
PySpark Client (Python) --gRPC--> Sail Server (Rust)
                                       |
                                       v
                                  DataFusion
```

Sail æ˜¯ Server ç«¯ï¼Œå®ƒæ¥æ”¶ä¾†è‡ª PySpark çš„è«‹æ±‚ã€‚PySpark ä½¿ç”¨ Python çš„ gRPC å®¢æˆ¶ç«¯åº«ï¼Œè€Œä¸æ˜¯ Rust çš„ã€‚

**å¦‚æœè¦æ¸¬è©¦ Sailï¼Œå¯ä»¥ç”¨ä»¥ä¸‹æ–¹å¼**ï¼š

1. ä½¿ç”¨ PySpark å®¢æˆ¶ç«¯ï¼ˆå®˜æ–¹æ”¯æ´ï¼‰
2. ä½¿ç”¨ `grpcurl` å‘½ä»¤è¡Œå·¥å…·
3. å¯«ä¸€å€‹ Rust æ¸¬è©¦ç¨‹åºï¼Œä½¿ç”¨ç”Ÿæˆçš„ `SparkConnectServiceClient`

**Rust æ¸¬è©¦ Client ç¤ºä¾‹**ï¼ˆå¦‚æœè¦æ¸¬è©¦çš„è©±ï¼‰ï¼š

```rust
#[cfg(test)]
mod tests {
    use super::spark::connect::spark_connect_service_client::SparkConnectServiceClient;
    use super::spark::connect::{ExecutePlanRequest, Plan};

    #[tokio::test]
    async fn test_execute_plan() {
        // é€£æ¥åˆ° Sail Server
        let mut client = SparkConnectServiceClient::connect("http://localhost:50051")
            .await
            .unwrap();

        // å‰µå»ºè«‹æ±‚
        let request = ExecutePlanRequest {
            session_id: "test-session".to_string(),
            user_context: None,
            plan: Some(Plan {
                // ... æ§‹å»º SQL æŸ¥è©¢è¨ˆåŠƒ
            }),
            operation_id: None,
            tags: vec![],
        };

        // ç™¼é€è«‹æ±‚
        let response = client.execute_plan(request).await.unwrap();

        // è™•ç†éŸ¿æ‡‰
        let mut stream = response.into_inner();
        while let Some(msg) = stream.message().await.unwrap() {
            println!("Response: {:?}", msg);
        }
    }
}
```

---

## ç¸½çµï¼šServer èˆ‡ Client çš„å®Œæ•´å°æ¯”

### ğŸ”¸ ä»£ç¢¼ç”Ÿæˆçš„ä¸‰å€‹ç”¢ç‰©

å¾ä¸€å€‹ `.proto` service å®šç¾©ï¼Œtonic-build ç”Ÿæˆï¼š

| ç”¢ç‰© | é¡å‹ | ç”¨é€” | ä½ç½® |
|------|------|------|------|
| **Message Structs** | `pub struct ExecutePlanRequest` | åºåˆ—åŒ–/ååºåˆ—åŒ– | ç”± prost-build ç”Ÿæˆ |
| **Service Trait** | `pub trait SparkConnectService` | Server ç«¯å¯¦ä½œ | ç”± tonic-build ç”Ÿæˆ |
| **Server Builder** | `pub struct SparkConnectServiceServer<T>` | å‰µå»º gRPC Server | ç”± tonic-build ç”Ÿæˆ |
| **Client Stub** | `pub struct SparkConnectServiceClient<T>` | Client ç«¯èª¿ç”¨ | ç”± tonic-build ç”Ÿæˆ |

### ğŸ”¸ å®Œæ•´çš„ gRPC é€šä¿¡æµç¨‹

```
Client ç«¯                        ç¶²çµ¡                         Server ç«¯
   |                              |                              |
   | 1. å‰µå»º Message               |                              |
   |    ExecutePlanRequest        |                              |
   |                              |                              |
   | 2. èª¿ç”¨ Client æ–¹æ³•           |                              |
   |    client.execute_plan()     |                              |
   |                              |                              |
   | 3. prost åºåˆ—åŒ–               |                              |
   |    Message -> bytes          |                              |
   |                              |                              |
   | 4. å‰µå»º HTTP/2 POST           |                              |
   |    Path: /pkg.Svc/Method     |                              |
   |         |                    |                              |
   |         +--------------------+----------------------------->|
   |                              |                              |
   |                              |  5. è·¯ç”±åˆ° trait æ–¹æ³•        |
   |                              |     match req.uri().path()  |
   |                              |                              |
   |                              |  6. prost ååºåˆ—åŒ–           |
   |                              |     bytes -> Message        |
   |                              |                              |
   |                              |  7. èª¿ç”¨å¯¦ä½œçš„ trait æ–¹æ³•    |
   |                              |     service.execute_plan()  |
   |                              |                              |
   |                              |  8. æ¥­å‹™é‚è¼¯è™•ç†             |
   |                              |     (DataFusion æŸ¥è©¢)       |
   |                              |                              |
   |                              |  9. è¿”å› Stream              |
   |                              |                              |
   |         +<-------------------+------------------------------+
   |         |                    |  10. prost åºåˆ—åŒ–æ¯å€‹éŸ¿æ‡‰    |
   | 11. Streaming<Response>      |      Response -> bytes      |
   |     stream.message().await   |                              |
   |                              |                              |
   | 12. prost ååºåˆ—åŒ–            |                              |
   |     bytes -> Response        |                              |
   |                              |                              |
   | 13. æ¥­å‹™é‚è¼¯è™•ç†              |                              |
   |     println!("{:?}", msg)    |                              |
```

---

å¸Œæœ›é€™ç¯‡æ–‡ç« å¹«åŠ©ä½ å¾¹åº•ç†è§£äº† Tonic æ˜¯å¦‚ä½•å¾ `.proto` æ–‡ä»¶ç”Ÿæˆå®Œæ•´çš„ Server ç«¯èˆ‡ Client ç«¯é‚è¼¯çš„ï¼
