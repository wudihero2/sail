# sail-cli

Sail çš„å‘½ä»¤åˆ—ä»‹é¢ï¼Œæä¾› Spark Connect ä¼ºæœå™¨ã€PySpark Shell å’Œ MCP ä¼ºæœå™¨åŠŸèƒ½ã€‚

## ğŸ“ æª”æ¡ˆçµæ§‹

```
sail-cli/src/
â”œâ”€â”€ main.rs           # ç¨‹å¼å…¥å£é»ï¼Œè™•ç† Python åµŒå…¥é‚è¼¯
â”œâ”€â”€ lib.rs            # æ¨¡çµ„å®šç¾©èˆ‡åŒ¯å‡º
â”œâ”€â”€ runner.rs         # CLI å‘½ä»¤è§£æèˆ‡åˆ†ç™¼ï¼ˆä½¿ç”¨ clapï¼‰
â”œâ”€â”€ python.rs         # Python æ¨¡çµ„è¼‰å…¥å™¨èˆ‡æ—¥èªŒæ©‹æ¥
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ mod.rs        # Spark å­æ¨¡çµ„åŒ¯å‡º
â”‚   â”œâ”€â”€ server.rs     # Spark Connect gRPC ä¼ºæœå™¨
â”‚   â”œâ”€â”€ shell.rs      # PySpark äº’å‹•å¼ Shell
â”‚   â””â”€â”€ mcp_server.rs # MCP (Model Context Protocol) ä¼ºæœå™¨
â””â”€â”€ worker/
    â”œâ”€â”€ mod.rs        # Worker å­æ¨¡çµ„åŒ¯å‡º
    â””â”€â”€ entrypoint.rs # åˆ†æ•£å¼ Worker å…¥å£é»
```

## ğŸ”¸ CLI å‘½ä»¤

```
sail
â”œâ”€â”€ spark
â”‚   â”œâ”€â”€ server --ip --port -C     # å•Ÿå‹• Spark Connect ä¼ºæœå™¨
â”‚   â”œâ”€â”€ shell                      # å•Ÿå‹• PySpark Shell
â”‚   â””â”€â”€ mcp-server --host --port --transport --spark-remote
â””â”€â”€ worker                         # å…§éƒ¨ä½¿ç”¨çš„ Worker ç¨‹åº
```

## ğŸ”¸ å»ºè­°é–±è®€é †åº

| é †åº | æª”æ¡ˆ | èªªæ˜ |
|------|------|------|
| 1 | main.rs | ç¨‹å¼å…¥å£ï¼Œç†è§£ Python åµŒå…¥æ©Ÿåˆ¶ |
| 2 | runner.rs | CLI çµæ§‹å®šç¾©ï¼Œäº†è§£æ‰€æœ‰å¯ç”¨å‘½ä»¤ |
| 3 | spark/server.rs | æ ¸å¿ƒä¼ºæœå™¨å•Ÿå‹•é‚è¼¯ |
| 4 | spark/shell.rs | äº’å‹•å¼ Shell å¯¦ä½œ |
| 5 | python.rs | Python èˆ‡ Rust çš„æ©‹æ¥å±¤ |
| 6 | worker/entrypoint.rs | åˆ†æ•£å¼åŸ·è¡Œçš„ Worker |
| 7 | sail-common | è¨­å®šè¼‰å…¥æ©Ÿåˆ¶ |
| 8 | sail-spark-connect | gRPC ä¼ºæœå™¨å¯¦ä½œ |

## ğŸ”¸ èª¿ç”¨éˆç¸½è¦½

```
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚           main.rs::main()           â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                                   â”‚
         [RUN_PYTHON=true]                                   [RUN_PYTHON=false]
                    â”‚                                                   â”‚
                    â–¼                                                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ run_python_interpreter()  â”‚                    â”‚    Python::initialize()      â”‚
    â”‚   ç›´æ¥å•Ÿå‹• Python ç›´è­¯å™¨  â”‚                    â”‚    åˆå§‹åŒ–åµŒå…¥å¼ Python       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â”‚
                                                                    â–¼
                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                     â”‚    runner::main(args)        â”‚
                                                     â”‚    è§£æ CLI åƒæ•¸ä¸¦åˆ†ç™¼       â”‚
                                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚                   â”‚               â”‚
                    â–¼                   â–¼                   â–¼               â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ run_worker  â”‚    â”‚ run_spark_server â”‚  â”‚ run_shell   â”‚  â”‚ run_mcp_serverâ”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”¸ Dependencies

| Crate | ç”¨é€” |
|-------|------|
| sail-common | å…±ç”¨è¨­å®šï¼ˆAppConfigã€CliConfigï¼‰èˆ‡éŒ¯èª¤è™•ç† |
| sail-execution | åˆ†æ•£å¼åŸ·è¡Œå¼•æ“ï¼ŒWorker ä½¿ç”¨ |
| sail-telemetry | é™æ¸¬ã€è¿½è¹¤èˆ‡æ—¥èªŒåˆå§‹åŒ– |
| sail-spark-connect | Spark Connect gRPC æœå‹™å¯¦ä½œ |
| sail-server | gRPC ä¼ºæœå™¨å»ºæ§‹å™¨ |
| clap | CLI åƒæ•¸è§£æï¼Œä½¿ç”¨ derive å·¨é›† |
| tokio | ç•°æ­¥é‹è¡Œæ™‚ï¼Œè™•ç†ä¸¦ç™¼é€£ç·š |
| pyo3 | Python åµŒå…¥èˆ‡ FFI ç¶å®š |
| mimalloc | é«˜æ•ˆèƒ½è¨˜æ†¶é«”åˆ†é…å™¨ï¼ˆå¯é¸ç‰¹æ€§ï¼‰ |
| rustls | TLS åŠ å¯†ï¼Œä½¿ç”¨ aws-lc-rs å¾Œç«¯ |
| fastrace | åˆ†æ•£å¼è¿½è¹¤ï¼ŒçµæŸæ™‚ flush |
| figment | è¨­å®šè¼‰å…¥ï¼Œæ”¯æ´å¤šä¾†æºåˆä½µ |

## ğŸ”¸ ä½¿ç”¨ç¯„ä¾‹

```bash
# å•Ÿå‹• Spark Connect ä¼ºæœå™¨ï¼ˆé è¨­ 127.0.0.1:50051ï¼‰
sail spark server --port 50051

# å•Ÿå‹• PySpark äº’å‹•å¼ Shell
sail spark shell

# å•Ÿå‹• MCP ä¼ºæœå™¨ï¼ˆSSE å‚³è¼¸ï¼‰
sail spark mcp-server --transport sse --port 8000

# å•Ÿå‹• MCP ä¼ºæœå™¨ä¸¦é€£æ¥åˆ°å¤–éƒ¨ Spark
sail spark mcp-server --spark-remote "sc://remote-host:50051"
```

---

## ğŸ”¸ å®Œæ•´èª¿ç”¨éˆè©³è§£ï¼šsail spark server

é€™è£¡ä»¥æœ€å¸¸ç”¨çš„ `sail spark server` å‘½ä»¤ç‚ºä¾‹ï¼Œå¾é ­åˆ°å°¾è§£é‡‹æ¯ä¸€å€‹å‡½æ•¸èª¿ç”¨ã€‚

### ç¬¬ä¸€å±¤ï¼šmain.rs::main()

```rust
use std::ffi::NulError;

use pyo3::ffi::{PyUnicode_AsWideCharString, PyUnicode_FromString, Py_Main};
use pyo3::Python;
use sail_common::config::{CliConfig, CliConfigEnv};
use sail_common::error::CommonError;
```

é€™æ®µæ˜¯æ¨¡çµ„å¼•å…¥ï¼š
- `std::ffi::NulError`ï¼šè™•ç† C å­—ä¸²ä¸­åŒ…å« null å­—å…ƒçš„éŒ¯èª¤å‹åˆ¥
- `pyo3::ffi::*`ï¼šPython C API çš„ä½éš FFI ç¶å®šï¼Œç”¨æ–¼ç›´æ¥æ“ä½œ Python ç›´è­¯å™¨
- `pyo3::Python`ï¼špyo3 çš„é«˜éš APIï¼Œç®¡ç† Python ç›´è­¯å™¨ç”Ÿå‘½é€±æœŸ
- `CliConfig`ï¼šCLI è¨­å®šçµæ§‹ï¼Œå¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥
- `CommonError`ï¼šçµ±ä¸€éŒ¯èª¤å‹åˆ¥

```rust
#[cfg(feature = "mimalloc")]
#[global_allocator]
static GLOBAL: mimalloc::MiMalloc = mimalloc::MiMalloc;
```

Rust èªæ³•è§£èªªï¼š
- `#[cfg(feature = "mimalloc")]`ï¼šæ¢ä»¶ç·¨è­¯å±¬æ€§ï¼Œåªæœ‰åœ¨ Cargo.toml ä¸­å•Ÿç”¨ `mimalloc` feature æ™‚æ‰ç·¨è­¯é€™æ®µç¨‹å¼ç¢¼
- `#[global_allocator]`ï¼šç‰¹æ®Šå±¬æ€§ï¼ŒæŒ‡å®šé€™å€‹éœæ…‹è®Šæ•¸ç‚ºå…¨åŸŸè¨˜æ†¶é«”åˆ†é…å™¨
- `static GLOBAL`ï¼šéœæ…‹è®Šæ•¸ï¼Œç”Ÿå‘½é€±æœŸæ˜¯æ•´å€‹ç¨‹å¼åŸ·è¡ŒæœŸé–“
- `mimalloc::MiMalloc`ï¼šmimalloc åˆ†é…å™¨çš„å¯¦ä¾‹

é€™è¡Œçš„ä½œç”¨æ˜¯æŠŠæ•´å€‹ç¨‹å¼çš„å…¨åŸŸè¨˜æ†¶é«”é…ç½®å™¨æ›æˆ mimallocã€‚ä¹Ÿå°±æ˜¯èªªï¼šä¹‹å¾Œæ‰€æœ‰ `Box`, `Vec`, `String`, `HashMap` ç­‰åœ¨ heap ä¸Š alloc/freeï¼Œå…¨éƒ¨éƒ½æœƒèµ° mimallocã€‚mimalloc æ˜¯å¾®è»Ÿé–‹ç™¼çš„é«˜æ•ˆèƒ½è¨˜æ†¶é«”åˆ†é…å™¨ï¼Œæ¯”ç³»çµ±é è¨­çš„ malloc å¿«ã€‚

```rust
fn main() -> Result<(), Box<dyn std::error::Error>> {
    if rustls::crypto::aws_lc_rs::default_provider()
        .install_default()
        .is_err()
    {
        Err(CommonError::InternalError(
            "failed to install crypto provider".to_string(),
        ))?;
    }
```

Rust èªæ³•è§£èªªï¼š
- `Result<(), Box<dyn std::error::Error>>`ï¼šå‡½æ•¸å›å‚³å‹åˆ¥
  - `()`ï¼šunit typeï¼Œä»£è¡¨æˆåŠŸæ™‚ä¸å›å‚³ä»»ä½•å€¼
  - `Box<dyn std::error::Error>`ï¼šå‹•æ…‹åˆ†æ´¾çš„éŒ¯èª¤å‹åˆ¥
    - `Box`ï¼šå †ç©åˆ†é…çš„æ™ºæ…§æŒ‡æ¨™ï¼Œæ“æœ‰è³‡æ–™çš„æ‰€æœ‰æ¬Š
    - `dyn`ï¼šå‹•æ…‹åˆ†æ´¾ï¼ŒåŸ·è¡Œæ™‚æ‰æ±ºå®šå…·é«”å‹åˆ¥
    - `std::error::Error`ï¼šæ¨™æº–éŒ¯èª¤ trait
- `rustls::crypto::aws_lc_rs::default_provider()`ï¼šå–å¾—é è¨­çš„åŠ å¯†æä¾›è€…ï¼ˆaws-lc-rsï¼‰
- `.install_default()`ï¼šå˜—è©¦å°‡å®ƒè¨­ç‚ºå…¨åŸŸé è¨­
- `.is_err()`ï¼šæª¢æŸ¥æ˜¯å¦å¤±æ•—
- `Err(...)?`ï¼šå»ºç«‹ä¸€å€‹éŒ¯èª¤ä¸¦ç”¨ `?` é‹ç®—å­ææ—©å›å‚³

é€™æ®µåˆå§‹åŒ– TLS åŠ å¯†æä¾›è€…ã€‚rustls æ˜¯ Rust çš„ TLS å¯¦ä½œï¼Œaws-lc-rs æ˜¯ AWS çš„åŠ å¯†åº«ï¼ˆåŸºæ–¼ BoringSSLï¼‰ã€‚å¦‚æœåˆå§‹åŒ–å¤±æ•—ï¼Œæ•´å€‹ç¨‹å¼å°±æœƒææ—©çµæŸã€‚

```rust
    let config = CliConfig::load()?;
```

é€™è¡Œå‘¼å« `CliConfig::load()` è¼‰å…¥ CLI è¨­å®šã€‚`?` é‹ç®—å­æœƒåœ¨å¤±æ•—æ™‚ææ—©å›å‚³éŒ¯èª¤ã€‚

### ç¬¬äºŒå±¤ï¼šCliConfig::load() (sail-common/src/config/cli.rs)

```rust
use figment::providers::{Env, Serialized};
use figment::Figment;
use serde::{Deserialize, Serialize};

use crate::error::{CommonError, CommonResult};

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct CliConfig {
    pub run_python: bool,
}
```

Rust èªæ³•è§£èªªï¼š
- `#[derive(...)]`ï¼šè‡ªå‹•å¯¦ä½œ traits
  - `Debug`ï¼šè®“çµæ§‹å¯ä»¥ç”¨ `{:?}` æ ¼å¼åŒ–è¼¸å‡º
  - `Clone`ï¼šè®“çµæ§‹å¯ä»¥å‘¼å« `.clone()` è¤‡è£½
  - `Default`ï¼šæä¾›é è¨­å€¼ï¼ˆ`run_python: false`ï¼‰
  - `Serialize`/`Deserialize`ï¼šserde çš„åºåˆ—åŒ–/ååºåˆ—åŒ–
- `pub struct CliConfig`ï¼šå…¬é–‹çš„çµæ§‹é«”
- `pub run_python: bool`ï¼šå…¬é–‹æ¬„ä½ï¼Œå¸ƒæ—å€¼

```rust
impl CliConfig {
    pub fn load() -> CommonResult<Self> {
        Figment::from(Serialized::defaults(CliConfig::default()))
            .merge(Env::prefixed("SAIL_INTERNAL__").map(|p| p.as_str().replace("__", ".").into()))
            .extract()
            .map_err(|e| CommonError::InvalidArgument(e.to_string()))
    }
}
```

Rust èªæ³•è§£èªªï¼š
- `impl CliConfig`ï¼šç‚º `CliConfig` å¯¦ä½œæ–¹æ³•
- `pub fn load() -> CommonResult<Self>`ï¼š
  - `CommonResult<Self>`ï¼šå‹åˆ¥åˆ¥åï¼Œç­‰åŒæ–¼ `Result<CliConfig, CommonError>`
  - `Self`ï¼šä»£è¡¨ `CliConfig` æœ¬èº«
- `Figment::from(...)`ï¼šå»ºç«‹è¨­å®šè¼‰å…¥å™¨
  - `Serialized::defaults(CliConfig::default())`ï¼šä½¿ç”¨ `CliConfig` çš„é è¨­å€¼ä½œç‚ºåŸºç¤å±¤
- `.merge(...)`ï¼šåˆä½µå¦ä¸€å€‹è¨­å®šä¾†æº
  - `Env::prefixed("SAIL_INTERNAL__")`ï¼šè®€å–ä»¥ `SAIL_INTERNAL__` é–‹é ­çš„ç’°å¢ƒè®Šæ•¸
  - `.map(|p| p.as_str().replace("__", ".").into())`ï¼šå°‡é›™åº•ç·šæ›¿æ›ç‚ºé»ï¼ˆä¾‹å¦‚ `SAIL_INTERNAL__RUN_PYTHON` è®Šæˆ `run_python`ï¼‰
- `.extract()`ï¼šæå–ä¸¦ååºåˆ—åŒ–ç‚º `CliConfig`
- `.map_err(...)`ï¼šå°‡éŒ¯èª¤è½‰æ›ç‚º `CommonError`

é€™å€‹å‡½æ•¸æœƒæª¢æŸ¥ç’°å¢ƒè®Šæ•¸ `SAIL_INTERNAL__RUN_PYTHON`ã€‚å¦‚æœè¨­ç‚º `true`ï¼Œ`config.run_python` å°±æœƒæ˜¯ `true`ã€‚

### å›åˆ°ç¬¬ä¸€å±¤ï¼šmain.rs::main()

```rust
    if config.run_python {
        run_python_interpreter()
    } else {
        std::env::set_var(CliConfigEnv::RUN_PYTHON, "true");
        Python::initialize();
        let args = std::env::args().collect();
        match sail_cli::runner::main(args) {
            Ok(()) => {}
            Err(e) => {
                eprintln!("Error: {e}");
                std::process::exit(1);
            }
        }
    }
    Ok(())
}
```

é€™æ˜¯æ ¸å¿ƒåˆ†æ”¯é‚è¼¯ï¼š
- å¦‚æœ `config.run_python` æ˜¯ `true`ï¼šé€™æ˜¯ä¸€å€‹è¢« fork çš„å­ç¨‹åºï¼Œå‘¼å« `run_python_interpreter()` ç›´æ¥å•Ÿå‹• Python ç›´è­¯å™¨ï¼ˆè©³è¦‹ä¸‹ä¸€ç¯€ï¼‰
- å¦‚æœæ˜¯ `false`ï¼ˆæ­£å¸¸æƒ…æ³ï¼‰ï¼š
  - `std::env::set_var(CliConfigEnv::RUN_PYTHON, "true")`ï¼šè¨­å®šç’°å¢ƒè®Šæ•¸ `SAIL_INTERNAL__RUN_PYTHON=true`ï¼Œè®“æœªä¾† fork çš„å­ç¨‹åºçŸ¥é“è¦ä»¥ Python æ¨¡å¼é‹è¡Œ
  - `Python::initialize()`ï¼šåˆå§‹åŒ–åµŒå…¥å¼ Python ç›´è­¯å™¨ï¼ˆpyo3 crate æä¾›ï¼Œè©³è¦‹ä¸‹æ–¹èªªæ˜ï¼‰
  - `std::env::args().collect()`ï¼šæ”¶é›†å‘½ä»¤åˆ—åƒæ•¸ç‚º `Vec<String>`
  - `sail_cli::runner::main(args)`ï¼šå‘¼å«ä¸»è¦çš„ CLI é‚è¼¯
  - `match` è™•ç†çµæœï¼šæˆåŠŸå°±ç¹¼çºŒï¼Œå¤±æ•—å°±å°éŒ¯èª¤ä¸¦ `exit(1)`

### Python::initialize() èªªæ˜

```rust
Python::initialize();
```

é€™æ˜¯ pyo3 crate æä¾›çš„å‡½æ•¸ï¼ˆé sail repo æºç¢¼ï¼‰ï¼Œç”¨æ–¼åˆå§‹åŒ–åµŒå…¥å¼ Python ç›´è­¯å™¨ã€‚

ä¸»è¦ä½œç”¨ï¼š
- åˆå§‹åŒ– Python é‹è¡Œæ™‚ï¼Œè®“ Rust ç¨‹å¼å¯ä»¥åŸ·è¡Œ Python ç¨‹å¼ç¢¼
- è¨­å®š `sys.executable` æŒ‡å‘ç•¶å‰åŸ·è¡Œæª”ï¼ˆ`sail` äºŒé€²ä½æª”ï¼‰
- åˆå§‹åŒ–å¾Œå¯ä»¥ä½¿ç”¨ `Python::attach(|py| { ... })` åŸ·è¡Œ Python ç¨‹å¼ç¢¼

ç‚ºä»€éº¼éœ€è¦ï¼Ÿ
- Sail CLI éœ€è¦åŸ·è¡Œ Python ç¨‹å¼ç¢¼ï¼ˆä¾‹å¦‚å•Ÿå‹• PySpark Shellï¼‰
- `sys.executable` æŒ‡å‘ `sail` æ˜¯ç‚ºä»€éº¼ multiprocessing fork æ™‚éœ€è¦ `run_python_interpreter()` çš„åŸå› 

Rust èªæ³•è§£èªªï¼š
- `eprintln!(...)`ï¼šå°åˆ°æ¨™æº–éŒ¯èª¤è¼¸å‡ºçš„å·¨é›†
- `std::process::exit(1)`ï¼šä»¥ç‹€æ…‹ç¢¼ 1 çµæŸç¨‹åº
- `{e}`ï¼šæ ¼å¼åŒ–å­—ä¸²ï¼Œç­‰åŒæ–¼ `{}`ï¼Œä½†è®Šæ•¸åç¨±æ›´æ¸…æ¥š

ç‚ºä»€éº¼éœ€è¦é€™å€‹æ©Ÿåˆ¶ï¼Ÿç•¶ Python çš„ `multiprocessing` æ¨¡çµ„ fork å­ç¨‹åºæ™‚ï¼Œå®ƒæœƒç”¨ `sys.executable`ï¼ˆæŒ‡å‘ sail äºŒé€²ä½æª”ï¼‰ä¾†å•Ÿå‹•æ–°ç¨‹åºã€‚é€™å€‹æ©Ÿåˆ¶è®“ fork å‡ºä¾†çš„ç¨‹åºèƒ½æ­£ç¢ºåœ°ä»¥ Python æ¨¡å¼é‹è¡Œã€‚

### run_python_interpreter() åˆ†æ”¯è©³è§£

ç•¶ `config.run_python` ç‚º `true` æ™‚ï¼ˆå­ç¨‹åºæ¨¡å¼ï¼‰ï¼Œæœƒå‘¼å« `run_python_interpreter()`ï¼š

```rust
fn run_python_interpreter() -> ! {
    let args = std::env::args();

    let argc = args.len() as i32;
    let Ok(mut argv) = args
        .into_iter()
        .map(|arg| {
            let arg = std::ffi::CString::new(arg)?;
            let arg = unsafe {
                let obj = PyUnicode_FromString(arg.as_ptr());
                PyUnicode_AsWideCharString(obj, std::ptr::null_mut())
            };
            Ok(arg)
        })
        .collect::<Result<Vec<_>, NulError>>()
    else {
        eprintln!("Error: null bytes found in command line argument strings");
        std::process::exit(1);
    };
    argv.push(std::ptr::null_mut());

    let code = unsafe { Py_Main(argc, argv.as_mut_ptr()) };
    std::process::exit(code)
}
```

Rust èªæ³•è§£èªªï¼š
- `fn run_python_interpreter() -> !`ï¼šå‡½æ•¸å›å‚³å‹åˆ¥æ˜¯ `!`ï¼ˆNever typeï¼‰
  - Never type è¡¨ç¤ºé€™å€‹å‡½æ•¸æ°¸é ä¸æœƒæ­£å¸¸å›å‚³
  - åªæœƒé€é `std::process::exit()` çµæŸç¨‹åº
- `std::env::args()`ï¼šå–å¾—å‘½ä»¤åˆ—åƒæ•¸çš„è¿­ä»£å™¨
- `args.len() as i32`ï¼šå‹åˆ¥è½‰æ›ï¼Œå°‡ `usize` è½‰ç‚º `i32`
  - Python C API éœ€è¦ `i32` å‹åˆ¥çš„ argc

åƒæ•¸è½‰æ›éç¨‹ï¼š
```rust
let Ok(mut argv) = args
    .into_iter()
    .map(|arg| {
        let arg = std::ffi::CString::new(arg)?;
        let arg = unsafe {
            let obj = PyUnicode_FromString(arg.as_ptr());
            PyUnicode_AsWideCharString(obj, std::ptr::null_mut())
        };
        Ok(arg)
    })
    .collect::<Result<Vec<_>, NulError>>()
else {
    eprintln!("Error: null bytes found in command line argument strings");
    std::process::exit(1);
};
```

Rust èªæ³•è§£èªªï¼š
- `.into_iter()`ï¼šæ¶ˆè€—è¿­ä»£å™¨ï¼Œå–å¾—æ¯å€‹åƒæ•¸çš„æ‰€æœ‰æ¬Š
- `.map(|arg| { ... })`ï¼šé–‰åŒ…ï¼Œè½‰æ›æ¯å€‹åƒæ•¸
  - `|arg|`ï¼šé–‰åŒ…åƒæ•¸
  - `{ ... }`ï¼šé–‰åŒ…ä¸»é«”
- `std::ffi::CString::new(arg)?`ï¼šå°‡ Rust String è½‰ç‚º C å­—ä¸²
  - C å­—ä¸²ä»¥ null (`\0`) çµå°¾
  - `?` æœƒåœ¨å­—ä¸²åŒ…å« null å­—å…ƒæ™‚å›å‚³éŒ¯èª¤
- `unsafe { ... }`ï¼šä¸å®‰å…¨å€å¡Šï¼Œå› ç‚ºè¦å‘¼å« FFI å‡½æ•¸
  - Rust ç„¡æ³•ä¿è­‰ C å‡½æ•¸çš„å®‰å…¨æ€§ï¼Œæ‰€ä»¥éœ€è¦æ˜ç¢ºæ¨™è¨˜
- `PyUnicode_FromString(arg.as_ptr())`ï¼šPython C API
  - å°‡ C å­—ä¸²è½‰ç‚º Python Unicode ç‰©ä»¶
  - `arg.as_ptr()`ï¼šå–å¾— C å­—ä¸²çš„æŒ‡æ¨™
- `PyUnicode_AsWideCharString(obj, std::ptr::null_mut())`ï¼šPython C API
  - å°‡ Python Unicode è½‰ç‚ºå¯¬å­—å…ƒå­—ä¸²ï¼ˆwchar_t*ï¼‰
  - Windows å’ŒæŸäº›å¹³å°éœ€è¦å¯¬å­—å…ƒ
  - `std::ptr::null_mut()`ï¼šå¯è®Šçš„ null æŒ‡æ¨™
- `.collect::<Result<Vec<_>, NulError>>()`ï¼šæ”¶é›†çµæœ
  - `Result<Vec<_>, NulError>`ï¼šTurbofish èªæ³•æŒ‡å®šå‹åˆ¥
  - `Vec<_>`ï¼šç·¨è­¯å™¨æ¨æ–·å…§éƒ¨å‹åˆ¥
  - å¦‚æœä»»ä½•ä¸€å€‹ `map` å›å‚³ `Err`ï¼Œæ•´å€‹ `collect` å°±æœƒæ˜¯ `Err`
- `let Ok(mut argv) = ... else { ... }`ï¼šlet-else èªæ³•ï¼ˆRust 1.65+ï¼‰
  - å¦‚æœæ˜¯ `Ok`ï¼Œè§£æ§‹å‡º `argv`
  - å¦‚æœæ˜¯ `Err`ï¼ŒåŸ·è¡Œ `else` å€å¡Š

ç‚ºä»€éº¼éœ€è¦å¯¬å­—å…ƒè½‰æ›ï¼Ÿ
- Windows çš„å‘½ä»¤åˆ—åƒæ•¸æ˜¯ UTF-16 ç·¨ç¢¼ï¼ˆå¯¬å­—å…ƒï¼‰
- `PyUnicode_AsWideCharString` ç¢ºä¿è·¨å¹³å°ç›¸å®¹æ€§
- Python å…§éƒ¨æœƒæ­£ç¢ºè™•ç†å„å¹³å°çš„å­—å…ƒç·¨ç¢¼

åŠ å…¥ null çµ‚æ­¢ç¬¦ï¼š
```rust
argv.push(std::ptr::null_mut());
```

Rust èªæ³•è§£èªªï¼š
- `std::ptr::null_mut()`ï¼šå»ºç«‹å¯è®Šçš„ null æŒ‡æ¨™
- C çš„ `argv` é™£åˆ—éœ€è¦ä»¥ null æŒ‡æ¨™çµå°¾
- é€™æ˜¯ C èªè¨€çš„æ…£ä¾‹ï¼Œè¡¨ç¤ºé™£åˆ—çš„çµæŸ

å•Ÿå‹• Python ç›´è­¯å™¨ï¼š
```rust
let code = unsafe { Py_Main(argc, argv.as_mut_ptr()) };
std::process::exit(code)
```

Rust èªæ³•è§£èªªï¼š
- `Py_Main(argc, argv.as_mut_ptr())`ï¼šPython C APIï¼Œå•Ÿå‹• Python ä¸»è¿´åœˆ
  - `argc`ï¼šåƒæ•¸æ•¸é‡
  - `argv.as_mut_ptr()`ï¼šå–å¾—å¯è®ŠæŒ‡æ¨™é™£åˆ—çš„æŒ‡æ¨™ï¼ˆ`**wchar_t`ï¼‰
  - é€™å€‹å‡½æ•¸æœƒå®Œå…¨æ¥ç®¡ç¨‹åºï¼ŒåŸ·è¡Œ Python ç¨‹å¼ç¢¼
- `std::process::exit(code)`ï¼šä»¥ Python çš„é€€å‡ºç¢¼çµæŸç¨‹åº
  - `code` æ˜¯ Python ç›´è­¯å™¨çš„é€€å‡ºç‹€æ…‹ï¼ˆé€šå¸¸ 0 è¡¨ç¤ºæˆåŠŸï¼‰

å®Œæ•´åŸ·è¡Œæµç¨‹ç¯„ä¾‹ï¼š

å‡è¨­ Python `multiprocessing` æ¨¡çµ„åŸ·è¡Œä»¥ä¸‹ç¨‹å¼ç¢¼ï¼š
```python
from multiprocessing import Process

def worker():
    print("Hello from worker")

if __name__ == "__main__":
    p = Process(target=worker)
    p.start()
    p.join()
```

åŸ·è¡Œæµç¨‹ï¼š
1. ä¸»ç¨‹åºï¼š`sail spark shell` å•Ÿå‹•ï¼Œ`SAIL_INTERNAL__RUN_PYTHON` æœªè¨­å®š
2. ä¸»ç¨‹åºï¼š`config.run_python = false`ï¼Œåˆå§‹åŒ– Python ä¸¦è¨­å®šç’°å¢ƒè®Šæ•¸
3. Python åŸ·è¡Œåˆ° `p.start()`ï¼Œéœ€è¦ fork æ–°ç¨‹åº
4. Python ä½¿ç”¨ `sys.executable`ï¼ˆæŒ‡å‘ `sail` äºŒé€²ä½æª”ï¼‰å•Ÿå‹•å­ç¨‹åº
5. å­ç¨‹åºï¼šå•Ÿå‹•æ™‚ `SAIL_INTERNAL__RUN_PYTHON=true`ï¼ˆç¹¼æ‰¿ç’°å¢ƒè®Šæ•¸ï¼‰
6. å­ç¨‹åºï¼š`config.run_python = true`ï¼Œå‘¼å« `run_python_interpreter()`
7. å­ç¨‹åºï¼šè½‰æ›å‘½ä»¤åˆ—åƒæ•¸ç‚º Python æ ¼å¼
8. å­ç¨‹åºï¼šå‘¼å« `Py_Main()`ï¼Œä»¥ç´” Python ç›´è­¯å™¨æ¨¡å¼é‹è¡Œ
9. å­ç¨‹åºï¼šåŸ·è¡Œ `worker()` å‡½æ•¸ï¼Œå°å‡º "Hello from worker"
10. å­ç¨‹åºï¼šå®Œæˆå¾Œ `exit(0)`

### ç¬¬ä¸‰å±¤ï¼šrunner::main()

```rust
use clap::{Parser, Subcommand};

use crate::spark::{
    run_pyspark_shell, run_spark_connect_server, run_spark_mcp_server, McpSettings, McpTransport,
};
use crate::worker::run_worker;
```

å¼•å…¥ clap çš„ derive å·¨é›†å’Œå…§éƒ¨æ¨¡çµ„ã€‚

```rust
#[derive(Parser)]
#[command(version, name = "sail", about = "Sail CLI")]
struct Cli {
    #[command(subcommand)]
    command: Command,
}
```

Rust èªæ³•è§£èªªï¼š
- `#[derive(Parser)]`ï¼šè‡ªå‹•å¯¦ä½œ clap çš„ `Parser` traitï¼Œèƒ½å¾å‘½ä»¤åˆ—åƒæ•¸è§£æ
- `#[command(version, name = "sail", about = "Sail CLI")]`ï¼š
  - `version`ï¼šè‡ªå‹•ä½¿ç”¨ `CARGO_PKG_VERSION`
  - `name = "sail"`ï¼šå‘½ä»¤åç¨±
  - `about = "..."`ï¼šèªªæ˜æ–‡å­—
- `struct Cli`ï¼šCLI çš„æ ¹çµæ§‹
- `#[command(subcommand)]`ï¼šæ¨™è¨˜é€™å€‹æ¬„ä½æ˜¯å­å‘½ä»¤

```rust
#[derive(Subcommand)]
enum Command {
    #[command(subcommand, about = "Run Spark workloads with Sail")]
    Spark(SparkCommand),
    #[command(about = "Start the Sail worker (internal use only)")]
    Worker,
}
```

Rust èªæ³•è§£èªªï¼š
- `#[derive(Subcommand)]`ï¼šè‡ªå‹•å¯¦ä½œå­å‘½ä»¤è§£æ
- `enum Command`ï¼šåˆ—èˆ‰å‹åˆ¥ï¼Œæ¯å€‹è®Šé«”ä»£è¡¨ä¸€å€‹å­å‘½ä»¤
- `Spark(SparkCommand)`ï¼š`spark` å­å‘½ä»¤ï¼Œé‚„æœ‰æ›´æ·±çš„å­å‘½ä»¤
- `Worker`ï¼š`worker` å­å‘½ä»¤ï¼Œä¸å¸¶é¡å¤–åƒæ•¸

```rust
#[derive(Subcommand)]
enum SparkCommand {
    #[command(about = "Start the Spark Connect server")]
    Server {
        #[arg(
            long,
            default_value = "127.0.0.1",
            help = "The IP address that the server binds to"
        )]
        ip: String,
        #[arg(
            long,
            default_value_t = 50051,
            help = "The port number that the server listens on"
        )]
        port: u16,
        #[arg(
            short = 'C',
            long,
            help = "The directory to change to before starting the server"
        )]
        directory: Option<String>,
    },
    #[command(
        about = "Start the PySpark shell with a Spark Connect server running in the background"
    )]
    Shell,
    #[command(about = "Start the Spark MCP (Model Context Protocol) server")]
    McpServer {
        #[arg(
            long,
            default_value = "127.0.0.1",
            help = "The host that the MCP server binds to (ignored for the stdio transport)"
        )]
        host: String,
        #[arg(
            long,
            default_value_t = 8000,
            help = "The port number that the server listens on (ignored for the stdio transport)"
        )]
        port: u16,
        #[arg(
            long,
            default_value_t = McpTransport::Sse,
            help = "The transport to use for the MCP server"
        )]
        transport: McpTransport,
        #[arg(long, help = "The Spark remote address to connect to (if specified)")]
        spark_remote: Option<String>,
        #[arg(
            short = 'C',
            long,
            help = "The directory to change to before starting the server"
        )]
        directory: Option<String>,
    },
}
```

Rust èªæ³•è§£èªªï¼š
- `#[arg(long)]`ï¼šé•·åƒæ•¸æ ¼å¼ `--ip`
- `#[arg(short = 'C')]`ï¼šçŸ­åƒæ•¸æ ¼å¼ `-C`
- `default_value = "127.0.0.1"`ï¼šå­—ä¸²é è¨­å€¼
- `default_value_t = 50051`ï¼šå‹åˆ¥åŒ–é è¨­å€¼ï¼ˆ`t` ä»£è¡¨ typedï¼‰ï¼Œæœƒè‡ªå‹•è½‰æ›ç‚º `u16`
- `Option<String>`ï¼šå¯é¸åƒæ•¸ï¼Œæ²’æä¾›æ™‚ç‚º `None`

```rust
pub fn main(args: Vec<String>) -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse_from(args);

    match cli.command {
        Command::Worker => run_worker(),
        Command::Spark(command) => match command {
            SparkCommand::Server { ip, port, directory } => {
                if let Some(directory) = directory {
                    std::env::set_current_dir(directory)?;
                }
                run_spark_connect_server(ip.parse()?, port)
            }
            SparkCommand::Shell => run_pyspark_shell(),
            SparkCommand::McpServer { host, port, transport, spark_remote, directory } => {
                if let Some(directory) = directory {
                    std::env::set_current_dir(directory)?;
                }
                run_spark_mcp_server(McpSettings { transport, host, port, spark_remote })
            }
        },
    }
}
```

Rust èªæ³•è§£èªªï¼š
- `Cli::parse_from(args)`ï¼šå¾åƒæ•¸åˆ—è¡¨è§£æ CLI çµæ§‹ï¼Œclap æœƒè‡ªå‹•è™•ç†
- `match cli.command`ï¼šæ¨¡å¼åŒ¹é…ï¼ŒRust è¦æ±‚è™•ç†æ‰€æœ‰è®Šé«”ï¼ˆexhaustiveï¼‰
- `SparkCommand::Server { ip, port, directory }`ï¼šè§£æ§‹ struct è®Šé«”ï¼Œå–å‡ºæ¬„ä½
- `if let Some(directory) = directory`ï¼šæ¢ä»¶è§£æ§‹ï¼Œåªæœ‰ `Some` æ™‚æ‰åŸ·è¡Œ
  - `std::env::set_current_dir(directory)?`ï¼šåˆ‡æ›å·¥ä½œç›®éŒ„
- `ip.parse()?`ï¼šå°‡å­—ä¸²è§£æç‚º `IpAddr` å‹åˆ¥ï¼Œ`?` å‚³æ’­éŒ¯èª¤

å°æ–¼ `sail spark server --port 50051` é€™å€‹å‘½ä»¤ï¼Œæœƒèµ°åˆ° `SparkCommand::Server` åˆ†æ”¯ï¼Œç„¶å¾Œå‘¼å« `run_spark_connect_server(ip.parse()?, port)`ã€‚

### ç¬¬å››å±¤ï¼šrun_spark_connect_server()

```rust
use std::net::IpAddr;
use std::sync::Arc;

use log::info;
use sail_common::config::AppConfig;
use sail_common::runtime::RuntimeManager;
use sail_spark_connect::entrypoint::{serve, SessionManagerOptions};
use sail_telemetry::telemetry::init_telemetry;
use tokio::net::TcpListener;
```

å¼•å…¥æ¨¡çµ„ï¼š
- `Arc`ï¼šAtomic Reference Countedï¼ŒåŸå­åƒè€ƒè¨ˆæ•¸æ™ºæ…§æŒ‡æ¨™ï¼Œç”¨æ–¼å¤šåŸ·è¡Œç·’å®‰å…¨çš„å…±äº«è³‡æ–™
- `log::info`ï¼šæ—¥èªŒå·¨é›†
- `AppConfig`ï¼šæ‡‰ç”¨ç¨‹å¼è¨­å®š
- `RuntimeManager`ï¼štokio åŸ·è¡Œæ™‚ç®¡ç†å™¨
- `serve`ï¼šå¯¦éš›çš„ gRPC ä¼ºæœå™¨å‡½æ•¸
- `init_telemetry`ï¼šåˆå§‹åŒ–é™æ¸¬ç³»çµ±
- `TcpListener`ï¼štokio çš„ TCP ç›£è½å™¨

```rust
async fn shutdown() {
    let _ = tokio::signal::ctrl_c().await;
    info!("Shutting down the Spark Connect server...");
}
```

Rust èªæ³•è§£èªªï¼š
- `async fn`ï¼šç•°æ­¥å‡½æ•¸ï¼Œå›å‚³ `impl Future<Output = ()>`
- `tokio::signal::ctrl_c()`ï¼šå»ºç«‹ä¸€å€‹ Futureï¼Œç­‰å¾… Ctrl+C è¨Šè™Ÿ
- `.await`ï¼šç­‰å¾… Future å®Œæˆ
- `let _ = ...`ï¼šå¿½ç•¥å›å‚³å€¼ï¼ˆResultï¼‰ï¼Œé¿å…ç·¨è­¯å™¨æœªä½¿ç”¨è­¦å‘Š
- `info!(...)`ï¼šå° info ç­‰ç´šçš„æ—¥èªŒ

é€™å€‹å‡½æ•¸æœƒä¸€ç›´é˜»å¡ç›´åˆ°æ”¶åˆ° Ctrl+Cï¼Œç„¶å¾Œå°æ—¥èªŒã€‚

```rust
pub fn run_spark_connect_server(ip: IpAddr, port: u16) -> Result<(), Box<dyn std::error::Error>> {
    init_telemetry()?;
```

å‘¼å« `init_telemetry()` åˆå§‹åŒ–é™æ¸¬ç³»çµ±ã€‚

### ç¬¬äº”å±¤ï¼šinit_telemetry() (sail-telemetry/src/telemetry.rs)

```rust
use std::borrow::Cow;
use std::env;
use std::io::Write;

use fastrace::collector::{Config, Reporter, SpanRecord};
use fastrace::prelude::*;
use fastrace_opentelemetry::OpenTelemetryReporter;
use opentelemetry::InstrumentationScope;
use opentelemetry_otlp::{Protocol, WithExportConfig, OTEL_EXPORTER_OTLP_TIMEOUT_DEFAULT};
use opentelemetry_sdk::Resource;

use crate::error::TelemetryResult;
```

å¼•å…¥æ¨¡çµ„ï¼š
- `Cow`ï¼šClone on Writeï¼Œå¯«å…¥æ™‚è¤‡è£½çš„æ™ºæ…§æŒ‡æ¨™
- `fastrace`ï¼šåˆ†æ•£å¼è¿½è¹¤åº«
- `opentelemetry`ï¼šOpenTelemetry å”è­°å¯¦ä½œ

```rust
pub fn init_telemetry() -> TelemetryResult<()> {
    let use_collector = match env::var("SAIL_OPENTELEMETRY_COLLECTOR") {
        Ok(val) => !val.is_empty(),
        Err(_) => false,
    };
    // Not getting any value out of this right now. Can re-enable when we revisit telemetry.
    // init_tracer(use_collector)?;
    init_logger(use_collector)?;
    Ok(())
}
```

Rust èªæ³•è§£èªªï¼š
- `env::var("...")`ï¼šè®€å–ç’°å¢ƒè®Šæ•¸ï¼Œå›å‚³ `Result<String, VarError>`
- `match` è™•ç†çµæœï¼š
  - `Ok(val) => !val.is_empty()`ï¼šå¦‚æœæœ‰å€¼ä¸”ä¸ç‚ºç©ºï¼Œ`use_collector` ç‚º `true`
  - `Err(_) => false`ï¼šå¦‚æœæ²’æœ‰é€™å€‹ç’°å¢ƒè®Šæ•¸ï¼Œ`use_collector` ç‚º `false`
- ç›®å‰åªå‘¼å« `init_logger(use_collector)?`ï¼Œtracer è¢«è¨»è§£æ‰äº†

```rust
pub fn init_logger(use_collector: bool) -> TelemetryResult<()> {
    env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("info"))
        .format(move |buf, record| {
            if use_collector {
                let event = Event::new(record.level().as_str()).with_properties(|| {
                    [("message", record.args().to_string())]
                });
                LocalSpan::add_event(event);
            }
            let level = record.level();
            let target = record.target();
            let style = buf.default_level_style(level);
            let timestamp = buf.timestamp();
            let args = record.args();
            if let Some(span_context) = SpanContext::current_local_parent() {
                let trace_id = span_context.trace_id.0;
                let span_id = span_context.span_id.0;
                writeln!(buf, "[{timestamp} {style}{level}{style:#} {target} trace: {trace_id} span: {span_id}] {args}")
            } else {
                writeln!(buf, "[{timestamp} {style}{level}{style:#} {target}] {args}")
            }
        })
        .init();
    Ok(())
}
```

Rust èªæ³•è§£èªªï¼š
- `env_logger::Builder::from_env(...)`ï¼šå¾ç’°å¢ƒè®Šæ•¸å»ºç«‹æ—¥èªŒå»ºæ§‹å™¨
- `.default_filter_or("info")`ï¼šé è¨­æ—¥èªŒç­‰ç´šç‚º `info`
- `.format(move |buf, record| { ... })`ï¼šè‡ªè¨‚æ—¥èªŒæ ¼å¼
  - `move`ï¼šé–‰åŒ…æ•ç² `use_collector` çš„æ‰€æœ‰æ¬Š
  - `buf`ï¼šè¼¸å‡ºç·©è¡å€
  - `record`ï¼šæ—¥èªŒè¨˜éŒ„
- `writeln!(buf, "...")`ï¼šæ ¼å¼åŒ–è¼¸å‡ºåˆ°ç·©è¡å€
- `{style}{level}{style:#}`ï¼šå¸¶é¡è‰²çš„æ—¥èªŒç­‰ç´šï¼ˆ`{style:#}` é‡è¨­æ¨£å¼ï¼‰

é€™å€‹å‡½æ•¸åˆå§‹åŒ–æ—¥èªŒç³»çµ±ï¼Œæ ¼å¼æœƒåŒ…å«æ™‚é–“æˆ³ã€ç­‰ç´šã€ç›®æ¨™å’Œè¨Šæ¯ã€‚å¦‚æœæœ‰ span contextï¼Œé‚„æœƒåŒ…å« trace ID å’Œ span IDã€‚

### å›åˆ°ç¬¬å››å±¤ï¼šrun_spark_connect_server()

```rust
    let config = Arc::new(AppConfig::load()?);
```

å‘¼å« `AppConfig::load()` è¼‰å…¥æ‡‰ç”¨ç¨‹å¼è¨­å®šï¼Œä¸¦ç”¨ `Arc` åŒ…è£ä»¥ä¾¿å…±äº«ã€‚

### ç¬¬å…­å±¤ï¼šAppConfig::load() (sail-common/src/config/application.rs)

```rust
const APP_CONFIG: &str = include_str!("application.yaml");
```

Rust èªæ³•è§£èªªï¼š
- `const`ï¼šç·¨è­¯æ™‚å¸¸æ•¸
- `include_str!(...)`ï¼šç·¨è­¯æ™‚å·¨é›†ï¼Œå°‡æª”æ¡ˆå…§å®¹åµŒå…¥ç‚ºå­—ä¸²å¸¸æ•¸

é€™è¡Œæœƒåœ¨ç·¨è­¯æ™‚æŠŠ `application.yaml` çš„å…§å®¹åµŒå…¥åˆ°äºŒé€²ä½æª”ä¸­ã€‚

```rust
#[derive(Debug, Clone, Deserialize)]
pub struct AppConfig {
    pub mode: ExecutionMode,
    pub runtime: RuntimeConfig,
    pub cluster: ClusterConfig,
    pub execution: ExecutionConfig,
    pub kubernetes: KubernetesConfig,
    pub parquet: ParquetConfig,
    pub catalog: CatalogConfig,
    pub optimizer: OptimizerConfig,
    pub spark: SparkConfig,
    #[serde(deserialize_with = "deserialize_unknown_unit")]
    pub internal: (),
}
```

é€™æ˜¯æ‡‰ç”¨ç¨‹å¼è¨­å®šçš„å®Œæ•´çµæ§‹ï¼ŒåŒ…å«æ‰€æœ‰å­è¨­å®šã€‚

```rust
struct InternalConfigPlaceholder;

impl Provider for InternalConfigPlaceholder {
    fn metadata(&self) -> Metadata {
        Metadata::named("Internal")
    }

    fn data(&self) -> Result<Map<Profile, Dict>, Error> {
        Ok(Map::from([(
            Profile::Default,
            Dict::from([(
                "internal".to_string(),
                Value::Empty(Tag::Default, Empty::Unit),
            )]),
        )]))
    }
}
```

Rust èªæ³•è§£èªªï¼š
- `impl Provider for InternalConfigPlaceholder`ï¼šå¯¦ä½œ figment çš„ `Provider` trait
- `fn metadata(&self)`ï¼šæä¾›å…ƒè³‡è¨Š
- `fn data(&self)`ï¼šæä¾›è¨­å®šè³‡æ–™
  - `Map::from([(...)])`ï¼šå»ºç«‹ map
  - `Value::Empty(Tag::Default, Empty::Unit)`ï¼šæä¾›ä¸€å€‹ç©ºçš„ unit å€¼çµ¦ `internal` æ¬„ä½

é€™å€‹ Provider çš„ä½œç”¨æ˜¯æ³¨å…¥ä¸€å€‹ä½”ä½ç¬¦çµ¦ `internal` æ¬„ä½ï¼Œç¢ºä¿ç’°å¢ƒè®Šæ•¸ `SAIL_INTERNAL_*` ä¸æœƒè¢«æ‡‰ç”¨ç¨‹å¼è¨­å®šä½¿ç”¨ã€‚

```rust
impl AppConfig {
    pub fn load() -> CommonResult<Self> {
        Figment::from(ConfigDefinition::new(APP_CONFIG))
            .merge(InternalConfigPlaceholder)
            .merge(Env::prefixed("SAIL_").map(|p| p.as_str().replace("__", ".").into()))
            .extract()
            .map_err(|e| CommonError::InvalidArgument(e.to_string()))
    }
}
```

Rust èªæ³•è§£èªªï¼š
- `Figment::from(ConfigDefinition::new(APP_CONFIG))`ï¼šå¾å…§åµŒçš„ YAML è¨­å®šé–‹å§‹
- `.merge(InternalConfigPlaceholder)`ï¼šåˆä½µå…§éƒ¨è¨­å®šä½”ä½ç¬¦
- `.merge(Env::prefixed("SAIL_")...)`ï¼šåˆä½µç’°å¢ƒè®Šæ•¸ï¼ˆ`SAIL_` é–‹é ­ï¼‰
  - `.map(|p| p.as_str().replace("__", ".").into())`ï¼šå°‡é›™åº•ç·šæ›¿æ›ç‚ºé»ï¼ˆä¾‹å¦‚ `SAIL_RUNTIME__STACK_SIZE` è®Šæˆ `runtime.stack_size`ï¼‰
- `.extract()`ï¼šæå–ä¸¦ååºåˆ—åŒ–ç‚º `AppConfig`

é€™å€‹å‡½æ•¸æœƒè¼‰å…¥ä¸‰å±¤è¨­å®šï¼š
1. åŸºç¤å±¤ï¼š`application.yaml` çš„é è¨­å€¼
2. å…§éƒ¨å±¤ï¼š`internal` æ¬„ä½ä½”ä½ç¬¦
3. ç’°å¢ƒè®Šæ•¸å±¤ï¼š`SAIL_*` ç’°å¢ƒè®Šæ•¸è¦†è“‹é è¨­å€¼

### å›åˆ°ç¬¬å››å±¤ï¼šrun_spark_connect_server()

```rust
    let runtime = RuntimeManager::try_new(&config.runtime)?;
```

å‘¼å« `RuntimeManager::try_new()` å»ºç«‹åŸ·è¡Œæ™‚ç®¡ç†å™¨ã€‚

### ç¬¬ä¸ƒå±¤ï¼šRuntimeManager::try_new() (sail-common/src/runtime.rs)

```rust
#[derive(Debug)]
pub struct RuntimeManager {
    primary: Runtime,
    io: Runtime,
    io_runtime_for_object_store: bool,
}
```

Rust èªæ³•è§£èªªï¼š
- `Runtime`ï¼štokio çš„åŸ·è¡Œæ™‚ï¼ˆruntimeï¼‰
- `primary`ï¼šä¸»åŸ·è¡Œæ™‚ï¼Œç”¨æ–¼ CPU å¯†é›†ä»»å‹™
- `io`ï¼šIO åŸ·è¡Œæ™‚ï¼Œç”¨æ–¼ IO å¯†é›†ä»»å‹™
- `io_runtime_for_object_store`ï¼šæ˜¯å¦ç‚º object store ä½¿ç”¨ç¨ç«‹åŸ·è¡Œæ™‚

```rust
impl RuntimeManager {
    pub fn try_new(config: &RuntimeConfig) -> CommonResult<Self> {
        let primary = Self::build_runtime(config.stack_size)?;
        let io = Self::build_runtime(config.stack_size)?;
        Ok(Self {
            primary,
            io,
            io_runtime_for_object_store: config.enable_secondary,
        })
    }
```

Rust èªæ³•è§£èªªï¼š
- `config: &RuntimeConfig`ï¼šå€Ÿç”¨ `RuntimeConfig` çš„åƒè€ƒ
- `Self::build_runtime(...)`ï¼šå‘¼å«é—œè¯å‡½æ•¸å»ºç«‹åŸ·è¡Œæ™‚
- `config.stack_size`ï¼šåŸ·è¡Œç·’å †ç–Šå¤§å°ï¼ˆå¾è¨­å®šæª”è®€å–ï¼‰

é€™å€‹å‡½æ•¸å»ºç«‹å…©å€‹ç¨ç«‹çš„ tokio åŸ·è¡Œæ™‚ã€‚

```rust
    fn build_runtime(stack_size: usize) -> CommonResult<Runtime> {
        tokio::runtime::Builder::new_multi_thread()
            .thread_stack_size(stack_size)
            .enable_all()
            .build()
            .map_err(|e| CommonError::internal(e.to_string()))
    }
```

Rust èªæ³•è§£èªªï¼š
- `tokio::runtime::Builder::new_multi_thread()`ï¼šå»ºç«‹å¤šåŸ·è¡Œç·’åŸ·è¡Œæ™‚å»ºæ§‹å™¨
- `.thread_stack_size(stack_size)`ï¼šè¨­å®šæ¯å€‹åŸ·è¡Œç·’çš„å †ç–Šå¤§å°
- `.enable_all()`ï¼šå•Ÿç”¨æ‰€æœ‰åŠŸèƒ½ï¼ˆIOã€æ™‚é–“ç­‰ï¼‰
- `.build()`ï¼šå»ºæ§‹åŸ·è¡Œæ™‚
- `.map_err(...)`ï¼šå°‡éŒ¯èª¤è½‰æ›ç‚º `CommonError`

```rust
    pub fn handle(&self) -> RuntimeHandle {
        let primary = self.primary.handle().clone();
        let io = self.io.handle().clone();
        let io_runtime_for_object_store = self.io_runtime_for_object_store;
        RuntimeHandle {
            primary,
            io,
            io_runtime_for_object_store,
        }
    }
}
```

Rust èªæ³•è§£èªªï¼š
- `self.primary.handle()`ï¼šå–å¾—åŸ·è¡Œæ™‚çš„ handleï¼ˆå¯ clone å’Œè·¨åŸ·è¡Œç·’å‚³éï¼‰
- `.clone()`ï¼šè¤‡è£½ handleï¼ˆå…§éƒ¨æ˜¯ `Arc`ï¼Œæ‰€ä»¥å¾ˆä¾¿å®œï¼‰

é€™å€‹æ–¹æ³•å›å‚³ `RuntimeHandle`ï¼Œå¯ä»¥åœ¨ä¸åŒåŸ·è¡Œç·’é–“å‚³éã€‚

```rust
#[derive(Debug, Clone)]
pub struct RuntimeHandle {
    primary: Handle,
    io: Handle,
    io_runtime_for_object_store: bool,
}

impl RuntimeHandle {
    pub fn primary(&self) -> &Handle {
        &self.primary
    }

    pub fn io(&self) -> &Handle {
        &self.io
    }

    pub fn io_runtime_for_object_store(&self) -> bool {
        self.io_runtime_for_object_store
    }
}
```

`RuntimeHandle` æä¾›å­˜å–å…©å€‹åŸ·è¡Œæ™‚ handle çš„æ–¹æ³•ã€‚

### å›åˆ°ç¬¬å››å±¤ï¼šrun_spark_connect_server()

```rust
    let options = SessionManagerOptions {
        config: Arc::clone(&config),
        runtime: runtime.handle(),
    };
```

Rust èªæ³•è§£èªªï¼š
- `Arc::clone(&config)`ï¼šè¤‡è£½ `Arc`ï¼ˆåªå¢åŠ åƒè€ƒè¨ˆæ•¸ï¼Œä¸è¤‡è£½è³‡æ–™ï¼‰
- `runtime.handle()`ï¼šå–å¾— `RuntimeHandle`
- `SessionManagerOptions { ... }`ï¼šçµæ§‹é«”åˆå§‹åŒ–èªæ³•

å»ºç«‹ `SessionManagerOptions`ï¼ŒåŒ…å«è¨­å®šå’ŒåŸ·è¡Œæ™‚ handleã€‚

```rust
    runtime.handle().primary().block_on(async {
        let listener = TcpListener::bind((ip, port)).await?;
        info!(
            "Starting the Spark Connect server on {}...",
            listener.local_addr()?
        );
        serve(listener, shutdown(), options).await?;
        info!("The Spark Connect server has stopped.");
        <Result<(), Box<dyn std::error::Error>>>::Ok(())
    })?;

    fastrace::flush();

    Ok(())
}
```

Rust èªæ³•è§£èªªï¼š
- `runtime.handle().primary()`ï¼šå–å¾—ä¸»åŸ·è¡Œæ™‚çš„ handle
- `.block_on(async { ... })`ï¼šé˜»å¡ç•¶å‰åŸ·è¡Œç·’ï¼ŒåŸ·è¡Œ async block
- `TcpListener::bind((ip, port))`ï¼šç¶å®š TCP ç›£è½å™¨
  - `(ip, port)`ï¼štuple ä½œç‚ºåƒæ•¸
  - `.await?`ï¼šç­‰å¾…ç¶å®šå®Œæˆï¼Œå¤±æ•—æ™‚ææ—©å›å‚³
- `listener.local_addr()?`ï¼šå–å¾—å¯¦éš›ç¶å®šçš„ä½å€
- `serve(listener, shutdown(), options).await?`ï¼šå•Ÿå‹• gRPC ä¼ºæœå™¨
  - `shutdown()`ï¼šå‘¼å« async å‡½æ•¸ï¼Œå›å‚³ Future
- `<Result<(), Box<dyn std::error::Error>>>::Ok(())`ï¼šTurbofish èªæ³•æ˜ç¢ºæŒ‡å®šå‹åˆ¥
  - å› ç‚º async block çš„å›å‚³å‹åˆ¥éœ€è¦æ˜ç¢ºï¼Œç·¨è­¯å™¨ç„¡æ³•æ¨æ–·
- `fastrace::flush()`ï¼šç¢ºä¿æ‰€æœ‰è¿½è¹¤è³‡æ–™éƒ½å·²å¯«å‡º

### ç¬¬å…«å±¤ï¼šserve() (sail-spark-connect/src/entrypoint.rs)

```rust
use std::future::Future;

use sail_common::config::GRPC_MAX_MESSAGE_LENGTH_DEFAULT;
use sail_server::ServerBuilder;
use tokio::net::TcpListener;
use tonic::codec::CompressionEncoding;

use crate::server::SparkConnectServer;
use crate::session_manager::SessionManager;
pub use crate::session_manager::SessionManagerOptions;
use crate::spark::connect::spark_connect_service_server::SparkConnectServiceServer;
```

å¼•å…¥æ¨¡çµ„ï¼š
- `Future`ï¼šæ¨™æº–åº«çš„ Future trait
- `ServerBuilder`ï¼šgRPC ä¼ºæœå™¨å»ºæ§‹å™¨
- `tonic`ï¼šRust çš„ gRPC æ¡†æ¶
- `SparkConnectServer`ï¼šSpark Connect æœå‹™å¯¦ä½œ
- `SessionManager`ï¼šæœƒè©±ç®¡ç†å™¨

```rust
pub async fn serve<F>(
    listener: TcpListener,
    signal: F,
    options: SessionManagerOptions,
) -> Result<(), Box<dyn std::error::Error>>
where
    F: Future<Output = ()>,
{
```

Rust èªæ³•è§£èªªï¼š
- `pub async fn serve<F>(...)`ï¼šæ³›å‹ç•°æ­¥å‡½æ•¸
  - `<F>`ï¼šæ³›å‹åƒæ•¸ï¼Œä»£è¡¨ shutdown signal çš„å‹åˆ¥
- `where F: Future<Output = ()>`ï¼štrait boundï¼Œ`F` å¿…é ˆæ˜¯è¼¸å‡ºç‚º `()` çš„ Future

#### æ­¥é©Ÿ 8.1ï¼šå»ºç«‹ SessionManager

```rust
let session_manager = SessionManager::new(options);
```

é€™è¡Œå‘¼å« `SessionManager::new(options)` å»ºç«‹æœƒè©±ç®¡ç†å™¨å¯¦ä¾‹ã€‚

ğŸ”¸ ä½ç½®ï¼š`crates/sail-spark-connect/src/session_manager.rs:60-67`

```rust
impl SessionManager {
    pub fn new(options: SessionManagerOptions) -> Self {
        let mut system = ActorSystem::new();
        let handle = system.spawn::<SessionManagerActor>(options);
        Self {
            system: Arc::new(Mutex::new(system)),
            handle,
        }
    }
}
```

Rust èªæ³•è§£èªªï¼š
- `ActorSystem::new()`ï¼šå»ºç«‹ä¸€å€‹æ–°çš„ Actor ç³»çµ±
  - Actor ç³»çµ±æ˜¯åŸºæ–¼è¨Šæ¯å‚³éçš„ä¸¦ç™¼æ¨¡å‹
  - æ‰€æœ‰ Actor åœ¨å–®ç¨çš„ä»»å‹™ä¸­é‹è¡Œï¼Œé€éè¨Šæ¯é€šè¨Š
- `system.spawn::<SessionManagerActor>(options)`ï¼šåœ¨ Actor ç³»çµ±ä¸­ç”Ÿæˆä¸€å€‹ `SessionManagerActor`
  - `spawn` æ–¹æ³•æœƒå»ºç«‹ä¸€å€‹ mpsc channelï¼Œä¸¦å•Ÿå‹• Actor çš„äº‹ä»¶è¿´åœˆ
  - å›å‚³ `ActorHandle` ç”¨æ–¼å‘ Actor ç™¼é€è¨Šæ¯
- `Arc::new(Mutex::new(system))`ï¼šåŒ…è£ Actor ç³»çµ±
  - `Arc`ï¼šAtomic Reference Countedï¼Œå¤šåŸ·è¡Œç·’å®‰å…¨çš„å…±äº«æŒ‡æ¨™
  - `Mutex`ï¼šäº’æ–¥é–ï¼Œç¢ºä¿åŒæ™‚åªæœ‰ä¸€å€‹åŸ·è¡Œç·’èƒ½å­˜å–

ğŸ”¸ ActorSystem::spawn è©³è§£ï¼ˆä½ç½®ï¼š`crates/sail-server/src/actor.rs:125-135`ï¼‰

```rust
pub fn spawn<T: Actor>(&mut self, options: T::Options) -> ActorHandle<T> {
    let (tx, rx) = mpsc::channel(ACTOR_CHANNEL_SIZE);
    let handle = ActorHandle { sender: tx };
    let runner = ActorRunner {
        actor: T::new(options),
        ctx: ActorContext::new(&handle),
        receiver: rx,
    };
    self.tasks.spawn(runner.run());
    handle
}
```

Rust èªæ³•è§£èªªï¼š
- `mpsc::channel(ACTOR_CHANNEL_SIZE)`ï¼šå»ºç«‹å¤šç”Ÿç”¢è€…å–®æ¶ˆè²»è€…é€šé“ï¼ˆchannelï¼‰
  - `ACTOR_CHANNEL_SIZE = 8`ï¼šé€šé“ç·©è¡å€å¤§å°
  - `tx`ï¼šç™¼é€ç«¯ï¼ˆSenderï¼‰ï¼Œå¯ä»¥ clone å¤šå€‹
  - `rx`ï¼šæ¥æ”¶ç«¯ï¼ˆReceiverï¼‰ï¼Œåªèƒ½æœ‰ä¸€å€‹
- `T::new(options)`ï¼šå‘¼å« `SessionManagerActor::new` å»ºç«‹ Actor å¯¦ä¾‹
- `ActorContext::new(&handle)`ï¼šå»ºç«‹ Actor ä¸Šä¸‹æ–‡
  - æä¾› `spawn`ã€`send`ã€`send_with_delay` ç­‰æ–¹æ³•
  - ç®¡ç† Actor ç”Ÿæˆçš„å­ä»»å‹™
- `self.tasks.spawn(runner.run())`ï¼šåœ¨ tokio åŸ·è¡Œç·’æ± ä¸­ç”Ÿæˆ Actor äº‹ä»¶è¿´åœˆ
  - `runner.run()` æ˜¯ä¸€å€‹ async å‡½æ•¸ï¼Œæœƒä¸€ç›´é‹è¡Œç›´åˆ° Actor åœæ­¢
  - `self.tasks` æ˜¯ä¸€å€‹ `JoinSet<()>`ï¼Œè¿½è¹¤æ‰€æœ‰ç”Ÿæˆçš„ä»»å‹™

ğŸ”¸ ActorRunner::run äº‹ä»¶è¿´åœˆï¼ˆä½ç½®ï¼š`crates/sail-server/src/actor.rs:185-206`ï¼‰

```rust
async fn run(mut self) {
    self.actor.start(&mut self.ctx).await;
    while let Some(message) = self.receiver.recv().await {
        let action = self.actor.receive(&mut self.ctx, message);
        match action {
            ActorAction::Continue => {}
            ActorAction::Warn(message) => {
                log::warn!("{message}");
            }
            ActorAction::Fail(message) => {
                log::error!("{message}");
                break;
            }
            ActorAction::Stop => {
                break;
            }
        }
        self.ctx.reap();
    }
    self.actor.stop(&mut self.ctx).await;
}
```

Rust èªæ³•è§£èªªï¼š
- `self.actor.start(&mut self.ctx).await`ï¼šå‘¼å« Actor çš„å•Ÿå‹•é‰¤å­ï¼ˆSessionManagerActor æ²’æœ‰è¦†å¯«é€™å€‹æ–¹æ³•ï¼‰
- `while let Some(message) = self.receiver.recv().await`ï¼šäº‹ä»¶è¿´åœˆ
  - `.recv().await` æœƒé˜»å¡ç›´åˆ°æ”¶åˆ°è¨Šæ¯
  - å¦‚æœé€šé“é—œé–‰ï¼ˆæ‰€æœ‰ Sender éƒ½ drop äº†ï¼‰ï¼Œæœƒå›å‚³ `None` ä¸¦çµæŸè¿´åœˆ
- `self.actor.receive(&mut self.ctx, message)`ï¼šè™•ç†è¨Šæ¯
  - é€™æ˜¯ `SessionManagerActor::receive` æ–¹æ³•
  - å›å‚³ `ActorAction` æ±ºå®šä¸‹ä¸€æ­¥å‹•ä½œ
- `self.ctx.reap()`ï¼šæ¸…ç†å·²å®Œæˆçš„å­ä»»å‹™
  - ä½¿ç”¨ `JoinSet::try_join_next()` æª¢æŸ¥æ˜¯å¦æœ‰ä»»å‹™å®Œæˆ
  - è¨˜éŒ„ä»»ä½•éŒ¯èª¤
- `self.actor.stop(&mut self.ctx).await`ï¼šå‘¼å«åœæ­¢é‰¤å­

ğŸ”¸ SessionManagerActor::newï¼ˆä½ç½®ï¼š`crates/sail-spark-connect/src/session_manager.rs:323-331`ï¼‰

```rust
fn new(options: Self::Options) -> Self {
    Self {
        options,
        sessions: HashMap::new(),
        global_file_listing_cache: None,
        global_file_statistics_cache: None,
        global_file_metadata_cache: None,
    }
}
```

å»ºç«‹ç©ºçš„æœƒè©±ç®¡ç†å™¨ç‹€æ…‹ï¼š
- `options`ï¼šæ‡‰ç”¨ç¨‹å¼è¨­å®šå’ŒåŸ·è¡Œæ™‚ handle
- `sessions: HashMap::new()`ï¼šç©ºçš„æœƒè©±è¡¨ï¼Œå„²å­˜ `SessionKey -> SessionContext`
- ä¸‰å€‹å…¨å±€ç·©å­˜éƒ½åˆå§‹åŒ–ç‚º `None`ï¼ˆå»¶é²åˆå§‹åŒ–ï¼Œç¬¬ä¸€æ¬¡å»ºç«‹ session æ™‚æ‰æœƒå»ºç«‹ï¼‰

#### æ­¥é©Ÿ 8.2ï¼šå»ºç«‹ SparkConnectServer

```rust
let server = SparkConnectServer::new(session_manager);
```

ğŸ”¸ ä½ç½®ï¼š`crates/sail-spark-connect/src/server.rs:29-33`

```rust
pub fn new(session_manager: SessionManager) -> Self {
    Self { session_manager }
}
```

é€™åªæ˜¯ç°¡å–®åœ°å°‡ `SessionManager` åŒ…è£åˆ° `SparkConnectServer` çµæ§‹ä¸­ã€‚`SparkConnectServer` å¯¦ä½œäº† `SparkConnectService` traitï¼ˆç”± tonic å¾ protobuf è‡ªå‹•ç”Ÿæˆï¼‰ï¼Œæä¾›æ‰€æœ‰ gRPC æ–¹æ³•çš„å¯¦ç¾ï¼š
- `execute_plan`ï¼šåŸ·è¡ŒæŸ¥è©¢è¨ˆåŠƒ
- `analyze_plan`ï¼šåˆ†æè¨ˆåŠƒï¼ˆschemaã€explain ç­‰ï¼‰
- `config`ï¼šè¨­å®šç®¡ç†
- `add_artifacts`ï¼šä¸Šå‚³ UDF/JAR
- `interrupt`ï¼šä¸­æ–·æ“ä½œ
- ç­‰ç­‰

#### æ­¥é©Ÿ 8.3ï¼šå»ºç«‹ Tonic gRPC æœå‹™

```rust
let service = SparkConnectServiceServer::new(server)
    .max_decoding_message_size(GRPC_MAX_MESSAGE_LENGTH_DEFAULT)
    .accept_compressed(CompressionEncoding::Gzip)
    .accept_compressed(CompressionEncoding::Zstd)
    .send_compressed(CompressionEncoding::Gzip)
    .send_compressed(CompressionEncoding::Zstd);
```

Rust èªæ³•è§£èªªï¼š
- `SparkConnectServiceServer::new(server)`ï¼šç”± tonic å¾ protobuf è‡ªå‹•ç”Ÿæˆçš„çµæ§‹
  - å°‡æˆ‘å€‘çš„ `SparkConnectServer` åŒ…è£æˆç¬¦åˆ tonic è¦ç¯„çš„ gRPC æœå‹™
  - è™•ç† HTTP/2 å”è­°ã€è¨Šæ¯åºåˆ—åŒ–/ååºåˆ—åŒ–
- `.max_decoding_message_size(GRPC_MAX_MESSAGE_LENGTH_DEFAULT)`ï¼šé™åˆ¶æ¥æ”¶è¨Šæ¯å¤§å°
  - `GRPC_MAX_MESSAGE_LENGTH_DEFAULT` é€šå¸¸æ˜¯ 4MB æˆ– 128MBï¼ˆè¦–è¨­å®šï¼‰
  - é˜²æ­¢å®¢æˆ¶ç«¯ç™¼é€éå¤§çš„è¨Šæ¯å°è‡´è¨˜æ†¶é«”è€—ç›¡
- `.accept_compressed(CompressionEncoding::Gzip)`ï¼šæ¥å— Gzip å£“ç¸®çš„è«‹æ±‚
  - å®¢æˆ¶ç«¯å¯ä»¥ç”¨ `grpc-encoding: gzip` header ç™¼é€å£“ç¸®è¨Šæ¯
- `.accept_compressed(CompressionEncoding::Zstd)`ï¼šæ¥å— Zstandard å£“ç¸®çš„è«‹æ±‚
  - Zstd é€šå¸¸æ¯” Gzip æ›´å¿«ä¸”å£“ç¸®ç‡æ›´é«˜
- `.send_compressed(...)`ï¼šå›æ‡‰æ™‚ä½¿ç”¨å£“ç¸®
  - ä¼ºæœå™¨æœƒæ ¹æ“šå®¢æˆ¶ç«¯çš„ `grpc-accept-encoding` header å”å•†å£“ç¸®æ–¹å¼

é€™æ˜¯ builder patternï¼Œæ¯å€‹æ–¹æ³•éƒ½å›å‚³ `self`ï¼Œå¯ä»¥éˆå¼å‘¼å«ã€‚

#### æ­¥é©Ÿ 8.4ï¼šå»ºç«‹ä¸¦é…ç½® ServerBuilder

```rust
ServerBuilder::new("sail_spark_connect", Default::default())
    .add_service(service, Some(crate::spark::connect::FILE_DESCRIPTOR_SET))
    .await
    .serve(listener, signal)
    .await
```

ğŸ”¸ ServerBuilder::newï¼ˆä½ç½®ï¼š`crates/sail-server/src/builder.rs:47-79`ï¼‰

```rust
pub fn new(name: &'static str, options: ServerBuilderOptions) -> Self {
    let (health_reporter, health_server) = tonic_health::server::health_reporter();

    let reflection_server_builder = tonic_reflection::server::Builder::configure()
        .register_encoded_file_descriptor_set(tonic_health::pb::FILE_DESCRIPTOR_SET);

    let layer = ServiceBuilder::new()
        .layer(TraceLayer::new(name))
        .into_inner();

    let router = tonic::transport::Server::builder()
        .tcp_nodelay(options.nodelay)
        .tcp_keepalive(options.keepalive)
        .http2_keepalive_interval(options.http2_keepalive_interval)
        .http2_keepalive_timeout(options.http2_keepalive_timeout)
        .http2_adaptive_window(options.http2_adaptive_window)
        .layer(layer)
        .add_service(health_server);

    Self {
        name,
        options,
        health_reporter,
        reflection_server_builder,
        router,
    }
}
```

é€™å€‹å»ºæ§‹å™¨æ•´åˆäº†å¤šå€‹ Tonic åŠŸèƒ½ï¼š

1. **å¥åº·æª¢æŸ¥æœå‹™**ï¼š`tonic_health::server::health_reporter()`
   - å¯¦ä½œ gRPC Health Checking Protocol
   - `health_reporter` ç”¨æ–¼æ›´æ–°æœå‹™ç‹€æ…‹ï¼ˆSERVINGã€NOT_SERVINGï¼‰
   - `health_server` æ˜¯å¯¦éš›çš„ gRPC æœå‹™ï¼Œå›æ‡‰ `/grpc.health.v1.Health/Check` è«‹æ±‚

2. **åå°„æœå‹™å»ºæ§‹å™¨**ï¼š`tonic_reflection::server::Builder::configure()`
   - å¯¦ä½œ gRPC Server Reflection Protocol
   - è®“å®¢æˆ¶ç«¯ï¼ˆå¦‚ grpcurlï¼‰å¯ä»¥æŸ¥è©¢æœå‹™çš„ protobuf å®šç¾©
   - è¨»å†Šå¥åº·æª¢æŸ¥æœå‹™çš„æè¿°ç¬¦

3. **è¿½è¹¤å±¤**ï¼š`TraceLayer::new(name)`
   - ä½¿ç”¨ tower middleware è¨˜éŒ„è«‹æ±‚/å›æ‡‰
   - æ•´åˆ OpenTelemetry è¿½è¹¤

4. **Tonic ä¼ºæœå™¨**ï¼š`tonic::transport::Server::builder()`
   - TCP å’Œ HTTP/2 é…ç½®ï¼ˆnodelayã€keepaliveï¼‰
   - æ·»åŠ è¿½è¹¤å±¤å’Œå¥åº·æª¢æŸ¥æœå‹™

ğŸ”¸ add_serviceï¼ˆä½ç½®ï¼š`crates/sail-server/src/builder.rs:81-100`ï¼‰

```rust
pub async fn add_service<S>(mut self, service: S, file_descriptor_set: Option<&'b [u8]>) -> Self
where
    S: Service<Request<Body>, Error = Infallible> + NamedService + Clone + Send + Sync + 'static,
    S::Response: axum::response::IntoResponse,
    S::Future: Send + 'static,
{
    self.health_reporter.set_serving::<S>().await;
    if let Some(file_descriptor_set) = file_descriptor_set {
        self.reflection_server_builder = self
            .reflection_server_builder
            .register_encoded_file_descriptor_set(file_descriptor_set);
    }
    self.router = self.router.add_service(service);
    self
}
```

Rust èªæ³•è§£èªªï¼š
- `self.health_reporter.set_serving::<S>().await`ï¼šå°‡æœå‹™æ¨™è¨˜ç‚º SERVING ç‹€æ…‹
  - Turbofish èªæ³• `::<S>` æŒ‡å®šæœå‹™å‹åˆ¥
  - å¥åº·æª¢æŸ¥ç«¯é»æœƒå›å‚³é€™å€‹ç‹€æ…‹
- `register_encoded_file_descriptor_set(file_descriptor_set)`ï¼šè¨»å†Š protobuf æè¿°ç¬¦
  - `FILE_DESCRIPTOR_SET` æ˜¯ç·¨è­¯ protobuf æ™‚ç”Ÿæˆçš„äºŒé€²ä½è³‡æ–™
  - åŒ…å«æ‰€æœ‰è¨Šæ¯ã€æœå‹™ã€æ–¹æ³•çš„å®šç¾©
  - åå°„æœå‹™æœƒç”¨å®ƒä¾†å›ç­”å®¢æˆ¶ç«¯çš„æŸ¥è©¢
- `self.router.add_service(service)`ï¼šå°‡ Spark Connect æœå‹™æ·»åŠ åˆ°è·¯ç”±å™¨
  - è·¯ç”±å™¨æœƒæ ¹æ“š gRPC è·¯å¾‘ï¼ˆå¦‚ `/spark.connect.SparkConnectService/ExecutePlan`ï¼‰åˆ†ç™¼è«‹æ±‚

ğŸ”¸ serveï¼ˆä½ç½®ï¼š`crates/sail-server/src/builder.rs:102-125`ï¼‰

```rust
pub async fn serve<F>(
    self,
    listener: TcpListener,
    signal: F,
) -> Result<(), Box<dyn std::error::Error>>
where
    F: Future<Output = ()>,
{
    let reflection_server = self.reflection_server_builder.build_v1()?;
    let router = self.router.add_service(reflection_server);

    let incoming = TcpIncoming::from(listener)
        .with_nodelay(Some(self.options.nodelay))
        .with_keepalive(self.options.keepalive);

    router
        .serve_with_incoming_shutdown(incoming, signal)
        .await?;

    Ok(())
}
```

Rust èªæ³•è§£èªªï¼š
- `self.reflection_server_builder.build_v1()?`ï¼šå®Œæˆåå°„æœå‹™çš„å»ºæ§‹
  - ä½¿ç”¨ v1 ç‰ˆæœ¬çš„åå°„å”è­°
  - åŒ…å«ä¹‹å‰è¨»å†Šçš„æ‰€æœ‰æè¿°ç¬¦
- `self.router.add_service(reflection_server)`ï¼šæ·»åŠ åå°„æœå‹™åˆ°è·¯ç”±å™¨
  - ç¾åœ¨è·¯ç”±å™¨åŒ…å«ä¸‰å€‹æœå‹™ï¼šå¥åº·æª¢æŸ¥ã€åå°„ã€Spark Connect
- `TcpIncoming::from(listener)`ï¼šå°‡ tokio çš„ `TcpListener` è½‰æ›ç‚º Tonic çš„é€£ç·šæµ
  - `.with_nodelay(Some(true))`ï¼šç¦ç”¨ Nagle æ¼”ç®—æ³•ï¼Œæ¸›å°‘å»¶é²
  - `.with_keepalive(Some(60s))`ï¼šæ¯ 60 ç§’ç™¼é€ TCP keepalive
- `router.serve_with_incoming_shutdown(incoming, signal).await?`ï¼šå•Ÿå‹•ä¼ºæœå™¨
  - é–‹å§‹ç›£è½ TCP é€£ç·š
  - å°æ¯å€‹é€£ç·šè™•ç† HTTP/2 å’Œ gRPC è«‹æ±‚
  - ç•¶ `signal` Future å®Œæˆæ™‚ï¼ˆå¦‚ Ctrl+Cï¼‰ï¼Œå„ªé›…é—œé–‰ï¼š
    1. åœæ­¢æ¥å—æ–°é€£ç·š
    2. ç­‰å¾…ç¾æœ‰è«‹æ±‚å®Œæˆ
    3. é—œé–‰æ‰€æœ‰é€£ç·š

#### æœå‹™å™¨å•Ÿå‹•å®Œæˆ

æ­¤æ™‚ï¼Œä¼ºæœå™¨å·²ç¶“å®Œå…¨å•Ÿå‹•ä¸¦æº–å‚™æ¥æ”¶è«‹æ±‚ï¼š

```
1. TCP ç›£è½å™¨ç¶å®šåˆ° 127.0.0.1:50051
2. Actor ç³»çµ±é‹è¡Œä¸­ï¼ŒSessionManagerActor ç­‰å¾…è¨Šæ¯
3. gRPC ä¼ºæœå™¨é‹è¡Œä¸­ï¼Œç­‰å¾…å®¢æˆ¶ç«¯é€£ç·š
4. ä¸‰å€‹æœå‹™å·²è¨»å†Šï¼š
   - grpc.health.v1.Healthï¼ˆå¥åº·æª¢æŸ¥ï¼‰
   - grpc.reflection.v1.ServerReflectionï¼ˆåå°„ï¼‰
   - spark.connect.SparkConnectServiceï¼ˆSpark Connectï¼‰
5. è¿½è¹¤å’Œæ—¥èªŒç³»çµ±å·²åˆå§‹åŒ–
6. ç­‰å¾… shutdown è¨Šè™Ÿï¼ˆCtrl+Cï¼‰
```

ç•¶å®¢æˆ¶ç«¯é€£ç·šæ™‚ï¼š
1. Tonic æ¥å— TCP é€£ç·šä¸¦å»ºç«‹ HTTP/2 é€£ç·š
2. å®¢æˆ¶ç«¯ç™¼é€ gRPC è«‹æ±‚ï¼ˆå¦‚ `ExecutePlanRequest`ï¼‰
3. è·¯ç”±å™¨æ ¹æ“šè·¯å¾‘åˆ†ç™¼åˆ°å°æ‡‰çš„æœå‹™ï¼ˆ`SparkConnectServer`ï¼‰
4. è¿½è¹¤å±¤è¨˜éŒ„è«‹æ±‚
5. æœå‹™æ–¹æ³•ï¼ˆå¦‚ `execute_plan`ï¼‰è¢«å‘¼å«
6. æœå‹™é€é `SessionManager` çš„ `ActorHandle` ç™¼é€è¨Šæ¯çµ¦ `SessionManagerActor`
7. Actor è™•ç†è¨Šæ¯ï¼ˆå»ºç«‹æˆ–å–å¾— sessionï¼‰
8. å›æ‡‰é€é gRPC æµå¼è¿”å›çµ¦å®¢æˆ¶ç«¯

é€™å€‹å‡½æ•¸æœƒä¸€ç›´é‹è¡Œç›´åˆ°æ”¶åˆ° shutdown è¨Šè™Ÿï¼ˆCtrl+Cï¼‰ã€‚

---

## ğŸ”¸ å®Œæ•´èª¿ç”¨éˆè©³è§£ï¼šsail worker

Worker æ˜¯ Sail åˆ†æ•£å¼åŸ·è¡Œæ¨¡å¼ä¸‹çš„å·¥ä½œç¨‹åºï¼Œç”± Driver é€é RPC å•Ÿå‹•ã€‚

### ç¬¬ä¸€å±¤ï¼šrunner::main() â†’ run_worker()

ç•¶ä½¿ç”¨è€…åŸ·è¡Œ `sail worker` å‘½ä»¤æ™‚ï¼Œ`runner::main()` æœƒåŒ¹é…åˆ° `Command::Worker` åˆ†æ”¯ä¸¦å‘¼å« `run_worker()`ã€‚

### ç¬¬äºŒå±¤ï¼šrun_worker() (sail-cli/src/worker/entrypoint.rs)

```rust
use sail_common::config::AppConfig;
use sail_common::runtime::RuntimeManager;
use sail_telemetry::telemetry::init_telemetry;

pub fn run_worker() -> Result<(), Box<dyn std::error::Error>> {
    init_telemetry()?;

    let config = AppConfig::load()?;
    let runtime = RuntimeManager::try_new(&config.runtime)?;
    runtime
        .handle()
        .primary()
        .block_on(sail_execution::run_worker(&config, runtime.handle()))?;

    fastrace::flush();

    Ok(())
}
```

é€™å€‹å‡½æ•¸çš„åŸ·è¡Œæ­¥é©Ÿï¼š

1. **åˆå§‹åŒ–é™æ¸¬ç³»çµ±**ï¼š`init_telemetry()?`ï¼ˆå·²åœ¨ server ç« ç¯€è©³ç´°èªªæ˜ï¼‰
2. **è¼‰å…¥è¨­å®š**ï¼š`AppConfig::load()?`ï¼ˆå·²åœ¨ server ç« ç¯€è©³ç´°èªªæ˜ï¼‰
3. **å»ºç«‹åŸ·è¡Œæ™‚**ï¼š`RuntimeManager::try_new(&config.runtime)?`ï¼ˆå·²åœ¨ server ç« ç¯€è©³ç´°èªªæ˜ï¼‰
4. **åŸ·è¡Œ Worker ä¸»é‚è¼¯**ï¼š`block_on(sail_execution::run_worker(...))`
5. **åˆ·æ–°è¿½è¹¤è³‡æ–™**ï¼š`fastrace::flush()`

### ç¬¬ä¸‰å±¤ï¼šsail_execution::run_worker() (sail-execution/src/worker/entrypoint.rs)

```rust
use sail_common::config::AppConfig;
use sail_common::runtime::RuntimeHandle;
use sail_server::actor::ActorSystem;

use crate::worker::{WorkerActor, WorkerOptions};

pub async fn run_worker(
    config: &AppConfig,
    runtime: RuntimeHandle,
) -> Result<(), Box<dyn std::error::Error>> {
    let mut system = ActorSystem::new();
    let options = WorkerOptions::try_new(config, runtime)?;
    let _handle = system.spawn::<WorkerActor>(options);
    system.join().await;
    Ok(())
}
```

Rust èªæ³•è§£èªªï¼š
- `ActorSystem::new()`ï¼šå»ºç«‹æ–°çš„ Actor ç³»çµ±ï¼ˆèˆ‡ SessionManager ä½¿ç”¨ç›¸åŒçš„æ©Ÿåˆ¶ï¼‰
- `WorkerOptions::try_new(config, runtime)?`ï¼šå»ºç«‹ Worker é…ç½®
  - åŒ…å«åŸ·è¡Œæ™‚ handleã€ç¶²è·¯é…ç½®ã€å„²å­˜é…ç½®ç­‰
- `system.spawn::<WorkerActor>(options)`ï¼šç”Ÿæˆ WorkerActor
  - å»ºç«‹ mpsc channel
  - å•Ÿå‹• Actor äº‹ä»¶è¿´åœˆ
  - å›å‚³ `ActorHandle`ï¼ˆé€™è£¡ç”¨ `_handle` å¿½ç•¥ï¼Œå› ç‚º Worker ä¸éœ€è¦ä¸»å‹•ç™¼é€è¨Šæ¯ï¼‰
- `system.join().await`ï¼šç­‰å¾…æ‰€æœ‰ Actor åœæ­¢
  - é€™æœƒé˜»å¡ç›´åˆ° Worker æ”¶åˆ°åœæ­¢è¨Šè™Ÿ
  - ç•¶ Driver ç™¼é€åœæ­¢è¨Šæ¯æ™‚ï¼ŒWorkerActor æœƒè™•ç†ä¸¦çµæŸ

### WorkerActor çš„è·è²¬

WorkerActor åœ¨ Actor äº‹ä»¶è¿´åœˆä¸­è™•ç†ä¾†è‡ª Driver çš„è¨Šæ¯ï¼š

1. **åŸ·è¡Œä»»å‹™**ï¼šæ¥æ”¶ Driver ç™¼ä¾†çš„ä»»å‹™ï¼ˆTaskï¼‰ï¼ŒåŸ·è¡Œ DataFusion ç‰©ç†è¨ˆåŠƒ
2. **è³‡æ–™ Shuffle**ï¼šèˆ‡å…¶ä»– Worker äº¤æ›è³‡æ–™ï¼ˆmap-side shuffleã€reduce-side shuffleï¼‰
3. **å›å ±ç‹€æ…‹**ï¼šå‘ Driver å›å ±ä»»å‹™åŸ·è¡Œç‹€æ…‹ï¼ˆé€²åº¦ã€å®Œæˆã€å¤±æ•—ï¼‰
4. **è³‡æºç®¡ç†**ï¼šç®¡ç†æœ¬åœ°æš«å­˜è³‡æ–™ã€è¨˜æ†¶é«”ä½¿ç”¨

Worker é€šå¸¸ä¸æ˜¯ç”±ä½¿ç”¨è€…æ‰‹å‹•å•Ÿå‹•ï¼Œè€Œæ˜¯ï¼š
- **LocalCluster æ¨¡å¼**ï¼šç”± Driver åœ¨æœ¬åœ°å•Ÿå‹•å­ç¨‹åº
- **Kubernetes æ¨¡å¼**ï¼šç”± Driver é€é Kubernetes API å»ºç«‹ Pod

---

## ğŸ”¸ å®Œæ•´èª¿ç”¨éˆè©³è§£ï¼šsail spark shell

Shell æ˜¯ä¸€å€‹æ•´åˆäº† Spark Connect æœå‹™å’Œ Python REPL çš„äº’å‹•å¼ç’°å¢ƒã€‚

### ç¬¬ä¸€å±¤ï¼šrunner::main() â†’ run_pyspark_shell()

ç•¶ä½¿ç”¨è€…åŸ·è¡Œ `sail spark shell` å‘½ä»¤æ™‚ï¼Œ`runner::main()` æœƒåŒ¹é…åˆ° `SparkCommand::Shell` åˆ†æ”¯ä¸¦å‘¼å« `run_pyspark_shell()`ã€‚

### ç¬¬äºŒå±¤ï¼šrun_pyspark_shell() (sail-cli/src/spark/shell.rs)

```rust
use std::net::Ipv4Addr;
use std::sync::Arc;

use pyo3::prelude::PyAnyMethods;
use pyo3::{PyResult, Python};
use sail_common::config::AppConfig;
use sail_common::runtime::RuntimeManager;
use sail_spark_connect::entrypoint::{serve, SessionManagerOptions};
use tokio::net::TcpListener;
use tokio::sync::oneshot;

use crate::python::Modules;

pub fn run_pyspark_shell() -> Result<(), Box<dyn std::error::Error>> {
    let config = Arc::new(AppConfig::load()?);
    let runtime = RuntimeManager::try_new(&config.runtime)?;
    let options = SessionManagerOptions {
        config,
        runtime: runtime.handle(),
    };
    let (_tx, rx) = oneshot::channel::<()>();
    let handle = runtime.handle().primary().clone();
    let (server_port, server_task) = handle.block_on(async move {
        let listener = TcpListener::bind((Ipv4Addr::new(127, 0, 0, 1), 0)).await?;
        let port = listener.local_addr()?.port();
        let shutdown = async {
            let _ = rx.await;
        };
        let task = async {
            let _ = serve(listener, shutdown, options).await;
        };
        <Result<_, Box<dyn std::error::Error>>>::Ok((port, task))
    })?;
    handle.spawn(server_task);
    Python::attach(|py| -> PyResult<_> {
        let shell = Modules::SPARK_SHELL.load(py)?;
        shell
            .getattr("run_pyspark_shell")?
            .call((server_port,), None)?;
        Ok(())
    })?;
    Ok(())
}
```

é€™å€‹å‡½æ•¸çµåˆäº† Spark Connect æœå‹™å’Œ Python Shellï¼ŒåŸ·è¡Œæ­¥é©Ÿå¦‚ä¸‹ï¼š

#### æ­¥é©Ÿ 1ï¼šè¼‰å…¥è¨­å®šå’Œå»ºç«‹åŸ·è¡Œæ™‚

```rust
let config = Arc::new(AppConfig::load()?);
let runtime = RuntimeManager::try_new(&config.runtime)?;
let options = SessionManagerOptions {
    config,
    runtime: runtime.handle(),
};
```

èˆ‡ `run_spark_connect_server` ç›¸åŒï¼Œè¼‰å…¥è¨­å®šå’Œå»ºç«‹åŸ·è¡Œæ™‚ã€‚

#### æ­¥é©Ÿ 2ï¼šå»ºç«‹ shutdown channel

```rust
let (_tx, rx) = oneshot::channel::<()>();
```

Rust èªæ³•è§£èªªï¼š
- `oneshot::channel::<()>()`ï¼šå»ºç«‹ä¸€æ¬¡æ€§é€šé“ï¼ˆåªèƒ½ç™¼é€ä¸€å€‹å€¼ï¼‰
  - `_tx`ï¼šç™¼é€ç«¯ï¼ˆSenderï¼‰ï¼Œç”¨åº•ç·šå‰ç¶´è¡¨ç¤ºåˆ»æ„ä¸ä½¿ç”¨
  - `rx`ï¼šæ¥æ”¶ç«¯ï¼ˆReceiverï¼‰
- ç‚ºä»€éº¼ä¸ä½¿ç”¨ `_tx`ï¼Ÿ
  - Shell ä¸éœ€è¦å„ªé›…é—œé–‰æœå‹™å™¨
  - ç•¶ Python REPL é€€å‡ºæ™‚ï¼Œæ•´å€‹ç¨‹åºæœƒçµæŸï¼Œæœå‹™å™¨ä¹Ÿæœƒè‡ªå‹•åœæ­¢
  - `rx.await` æœƒæ°¸é ç­‰å¾…ï¼ˆå› ç‚º `_tx` è¢« drop äº†ï¼Œé€šé“æœƒé—œé–‰ä½†ä¸æœƒç™¼é€å€¼ï¼‰

#### æ­¥é©Ÿ 3ï¼šç¶å®šéš¨æ©ŸåŸ ä¸¦å»ºç«‹æœå‹™å™¨ä»»å‹™

```rust
let handle = runtime.handle().primary().clone();
let (server_port, server_task) = handle.block_on(async move {
    let listener = TcpListener::bind((Ipv4Addr::new(127, 0, 0, 1), 0)).await?;
    let port = listener.local_addr()?.port();
    let shutdown = async {
        let _ = rx.await;
    };
    let task = async {
        let _ = serve(listener, shutdown, options).await;
    };
    <Result<_, Box<dyn std::error::Error>>>::Ok((port, task))
})?;
```

Rust èªæ³•è§£èªªï¼š
- `Ipv4Addr::new(127, 0, 0, 1)`ï¼šå»ºç«‹ IPv4 ä½å€ `127.0.0.1`ï¼ˆlocalhostï¼‰
  - åªç›£è½æœ¬åœ°ä»‹é¢ï¼Œä¸æ¥å—å¤–éƒ¨é€£ç·šï¼ˆå®‰å…¨æ€§è€ƒé‡ï¼‰
- `TcpListener::bind((127.0.0.1, 0))`ï¼šç¶å®šåˆ°éš¨æ©ŸåŸ 
  - åŸ è™Ÿ `0` è¡¨ç¤ºè®“ä½œæ¥­ç³»çµ±è‡ªå‹•åˆ†é…å¯ç”¨åŸ 
  - é¿å…èˆ‡å…¶ä»–æœå‹™è¡çª
- `listener.local_addr()?.port()`ï¼šå–å¾—å¯¦éš›ç¶å®šçš„åŸ è™Ÿ
  - éœ€è¦å‚³éçµ¦ Python Shellï¼Œè®“ PySpark é€£ç·šåˆ°é€™å€‹åŸ 
- `let shutdown = async { let _ = rx.await; }`ï¼šå»ºç«‹æ°¸ä¸å®Œæˆçš„ Future
  - `rx.await` æœƒä¸€ç›´ç­‰å¾…ï¼ˆå› ç‚º `_tx` å·²ç¶“ dropï¼‰
  - é€™å€‹ Future æ°¸é ä¸æœƒ resolveï¼Œæ‰€ä»¥æœå‹™å™¨æœƒä¸€ç›´é‹è¡Œ
- `let task = async { let _ = serve(listener, shutdown, options).await; }`ï¼šå»ºç«‹æœå‹™å™¨ä»»å‹™
  - æ³¨æ„é€™è£¡åªæ˜¯**å»ºç«‹** Futureï¼Œé‚„æ²’æœ‰åŸ·è¡Œ
  - `serve` å‡½æ•¸èˆ‡ `run_spark_connect_server` ä¸­ä½¿ç”¨çš„ç›¸åŒ

#### æ­¥é©Ÿ 4ï¼šåœ¨èƒŒæ™¯åŸ·è¡Œæœå‹™å™¨

```rust
handle.spawn(server_task);
```

Rust èªæ³•è§£èªªï¼š
- `handle.spawn(...)`ï¼šåœ¨ tokio åŸ·è¡Œæ™‚ä¸­ç”Ÿæˆä»»å‹™
  - `server_task` æ˜¯ä¸€å€‹ Futureï¼Œæœƒåœ¨èƒŒæ™¯åŸ·è¡Œ
  - ä¸æœƒé˜»å¡ç•¶å‰åŸ·è¡Œç·’
  - æœå‹™å™¨æœƒåœ¨èƒŒæ™¯æŒçºŒé‹è¡Œï¼ŒåŒæ™‚å¯ä»¥åŸ·è¡Œ Python Shell

é€™è£¡èˆ‡ `run_spark_connect_server` çš„é—œéµå·®ç•°ï¼š
- **Server æ¨¡å¼**ï¼š`block_on(serve(...))`ï¼Œä¸»åŸ·è¡Œç·’é˜»å¡ç­‰å¾…æœå‹™å™¨
- **Shell æ¨¡å¼**ï¼š`spawn(serve(...))`ï¼ŒèƒŒæ™¯åŸ·è¡Œæœå‹™å™¨ï¼Œä¸»åŸ·è¡Œç·’ç¹¼çºŒåŸ·è¡Œ Python Shell

#### æ­¥é©Ÿ 5ï¼šå•Ÿå‹• Python Shell

```rust
Python::attach(|py| -> PyResult<_> {
    let shell = Modules::SPARK_SHELL.load(py)?;
    shell
        .getattr("run_pyspark_shell")?
        .call((server_port,), None)?;
    Ok(())
})?;
```

Rust èªæ³•è§£èªªï¼š
- `Python::attach(|py| { ... })`ï¼šé™„åŠ åˆ°å·²åˆå§‹åŒ–çš„ Python ç›´è­¯å™¨
  - `py` æ˜¯ Python åŸ·è¡Œä¸Šä¸‹æ–‡ï¼ˆGIL tokenï¼‰
  - é–‰åŒ…å…§çš„ç¨‹å¼ç¢¼æœƒæŒæœ‰ Python çš„ Global Interpreter Lock (GIL)
- `Modules::SPARK_SHELL.load(py)?`ï¼šè¼‰å…¥å…§åµŒçš„ Python æ¨¡çµ„
  - `SPARK_SHELL` æ˜¯å¸¸æ•¸ï¼Œå®šç¾©åœ¨ `python.rs`

ğŸ”¸ Modules::SPARK_SHELL å®šç¾©ï¼ˆä½ç½®ï¼š`crates/sail-cli/src/python.rs:42-45`ï¼‰

```rust
pub const SPARK_SHELL: Module<()> = Module::new(
    "_sail_cli_spark_shell",
    include_str!("python/spark_shell.py"),
);
```

Rust èªæ³•è§£èªªï¼š
- `Module::new(...)`ï¼šå»ºç«‹æ¨¡çµ„å®šç¾©
  - ç¬¬ä¸€å€‹åƒæ•¸ï¼šæ¨¡çµ„åç¨± `_sail_cli_spark_shell`
  - ç¬¬äºŒå€‹åƒæ•¸ï¼šæ¨¡çµ„æºç¢¼ï¼ˆé€é `include_str!` å·¨é›†åµŒå…¥ï¼‰
- `include_str!("python/spark_shell.py")`ï¼šç·¨è­¯æ™‚å°‡ Python æª”æ¡ˆå…§å®¹åµŒå…¥ç‚ºå­—ä¸²
  - é€™æ¨£ Sail äºŒé€²ä½æª”ä¸éœ€è¦å¤–éƒ¨ Python æª”æ¡ˆå°±èƒ½é‹è¡Œ
- `Module<()>`ï¼šæ³›å‹åƒæ•¸ `()` è¡¨ç¤ºæ²’æœ‰é¡å¤–çš„åˆå§‹åŒ–å™¨
  - `NativeLogging` ä½¿ç”¨ `Module<NativeLogging>` å› ç‚ºéœ€è¦è¨»å†Š Python class

ğŸ”¸ Module::load æ–¹æ³•ï¼ˆä½ç½®ï¼š`crates/sail-cli/src/python.rs:23-32`ï¼‰

```rust
pub fn load<'py>(&self, py: Python<'py>) -> PyResult<Bound<'py, PyModule>> {
    let m = PyModule::from_code(
        py,
        CString::new(self.source)?.as_c_str(),
        CString::new("")?.as_c_str(),
        CString::new(self.name)?.as_c_str(),
    )?;
    I::init(&m)?;
    Ok(m)
}
```

Rust èªæ³•è§£èªªï¼š
- `PyModule::from_code(...)`ï¼šå¾ Python æºç¢¼å»ºç«‹æ¨¡çµ„
  - ç¬¬ä¸€å€‹åƒæ•¸ï¼šPython ä¸Šä¸‹æ–‡
  - ç¬¬äºŒå€‹åƒæ•¸ï¼šPython æºç¢¼ï¼ˆC å­—ä¸²ï¼‰
  - ç¬¬ä¸‰å€‹åƒæ•¸ï¼šæª”æ¡ˆåç¨±ï¼ˆç©ºå­—ä¸²ï¼Œå› ç‚ºæ˜¯å…§åµŒæ¨¡çµ„ï¼‰
  - ç¬¬å››å€‹åƒæ•¸ï¼šæ¨¡çµ„åç¨±
- `I::init(&m)?`ï¼šå‘¼å«åˆå§‹åŒ–å™¨
  - å°æ–¼ `Module<()>`ï¼Œé€™æ˜¯ç©ºæ“ä½œ
  - å°æ–¼ `Module<NativeLogging>`ï¼Œæœƒè¨»å†Š `NativeLogging` class

è¼‰å…¥æ¨¡çµ„å¾Œï¼Œç¹¼çºŒåŸ·è¡Œï¼š

```rust
shell
    .getattr("run_pyspark_shell")?
    .call((server_port,), None)?;
```

Rust èªæ³•è§£èªªï¼š
- `.getattr("run_pyspark_shell")?`ï¼šå–å¾— Python å‡½æ•¸
  - ç­‰åŒæ–¼ Python çš„ `shell.run_pyspark_shell`
- `.call((server_port,), None)?`ï¼šå‘¼å«å‡½æ•¸
  - ç¬¬ä¸€å€‹åƒæ•¸ï¼šä½ç½®åƒæ•¸ tuple `(server_port,)`
    - æ³¨æ„å°¾éš¨é€—è™Ÿï¼Œè¡¨ç¤ºå–®å…ƒç´  tuple
  - ç¬¬äºŒå€‹åƒæ•¸ï¼šé—œéµå­—åƒæ•¸ï¼ˆ`None` è¡¨ç¤ºæ²’æœ‰ï¼‰
  - ç­‰åŒæ–¼ Python çš„ `shell.run_pyspark_shell(server_port)`

### ç¬¬ä¸‰å±¤ï¼šrun_pyspark_shell() (Python ç¨‹å¼ç¢¼)

ğŸ”¸ ä½ç½®ï¼š`crates/sail-cli/src/python/spark_shell.py:10-29`

```python
import code
import platform
import readline
from rlcompleter import Completer

import pyspark
from pyspark.sql import SparkSession


def run_pyspark_shell(port: int):
    spark = SparkSession.builder.remote(f"sc://localhost:{port}").getOrCreate()
    namespace = {"spark": spark}
    readline.parse_and_bind("tab: complete")
    readline.set_completer(Completer(namespace).complete)

    python_version = platform.python_version()
    (build_number, build_date) = platform.python_build()
    banner = rf"""Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version {pyspark.__version__}
      /_/

Using Python version {python_version} ({build_number}, {build_date})
Client connected to the Sail Spark Connect server at localhost:{port}
SparkSession available as 'spark'."""
    code.interact(local=namespace, banner=banner, exitmsg="")
```

é€™æ®µ Python ç¨‹å¼ç¢¼çš„åŸ·è¡Œæµç¨‹ï¼š

1. **å»ºç«‹ SparkSession**ï¼š`SparkSession.builder.remote(f"sc://localhost:{port}").getOrCreate()`
   - é€£ç·šåˆ°èƒŒæ™¯é‹è¡Œçš„ Spark Connect æœå‹™å™¨
   - `sc://` æ˜¯ Spark Connect å”è­°çš„ URL scheme
   - é€™æœƒå»ºç«‹ gRPC é€£ç·šåˆ° `localhost:{port}`

2. **è¨­å®šå‘½åç©ºé–“**ï¼š`namespace = {"spark": spark}`
   - Shell ä¸­å¯ç”¨çš„è®Šæ•¸
   - ä½¿ç”¨è€…å¯ä»¥ç›´æ¥ä½¿ç”¨ `spark` è®Šæ•¸

3. **å•Ÿç”¨ Tab è‡ªå‹•å®Œæˆ**ï¼š
   ```python
   readline.parse_and_bind("tab: complete")
   readline.set_completer(Completer(namespace).complete)
   ```
   - ä½¿ç”¨ `readline` å’Œ `rlcompleter` æä¾› Tab è‡ªå‹•å®Œæˆ
   - å¯ä»¥æŒ‰ Tab éµè£œå…¨ `spark.` çš„å±¬æ€§å’Œæ–¹æ³•

4. **é¡¯ç¤ºæ­¡è¿è¨Šæ¯**ï¼šå»ºç«‹ PySpark é¢¨æ ¼çš„ banner
   - é¡¯ç¤º PySpark ç‰ˆæœ¬ã€Python ç‰ˆæœ¬
   - æç¤ºé€£ç·šåˆ° Sail Spark Connect æœå‹™å™¨

5. **å•Ÿå‹•äº’å‹•å¼ REPL**ï¼š`code.interact(local=namespace, banner=banner, exitmsg="")`
   - `code.interact` æ˜¯ Python æ¨™æº–åº«çš„äº’å‹•å¼ REPL
   - `local=namespace`ï¼šæä¾› `spark` è®Šæ•¸
   - `banner=banner`ï¼šé¡¯ç¤ºæ­¡è¿è¨Šæ¯
   - `exitmsg=""`ï¼šé€€å‡ºæ™‚ä¸é¡¯ç¤ºè¨Šæ¯
   - ä½¿ç”¨è€…å¯ä»¥è¼¸å…¥ Python ç¨‹å¼ç¢¼ï¼Œä¾‹å¦‚ï¼š
     ```python
     >>> spark.sql("SELECT 1+1").show()
     +-------+
     |(1 + 1)|
     +-------+
     |      2|
     +-------+
     ```

### Shell æ¨¡å¼çš„å®Œæ•´æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     sail spark shell                     â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Tokio Runtime (Background)           â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚    Spark Connect gRPC Server             â”‚   â”‚  â”‚
â”‚  â”‚  â”‚    - SessionManager (Actor)              â”‚   â”‚  â”‚
â”‚  â”‚  â”‚    - TCP Listener (127.0.0.1:random)     â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†‘ gRPC                          â”‚
â”‚                          â”‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Python REPL (Foreground)                  â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  >>> spark.sql("SELECT 1")                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚   PySpark Client (SparkSession)          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   - gRPC client to sc://localhost:port   â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ç•¶ä½¿ç”¨è€…åŸ·è¡Œ `spark.sql("SELECT 1+1").show()` æ™‚ï¼š
1. PySpark å®¢æˆ¶ç«¯å°‡ SQL å°è£ç‚º `ExecutePlanRequest` gRPC è¨Šæ¯
2. é€é localhost çš„ gRPC é€£ç·šç™¼é€åˆ°èƒŒæ™¯çš„ Spark Connect æœå‹™å™¨
3. æœå‹™å™¨è™•ç†è«‹æ±‚ï¼ˆè§£æ SQLã€åŸ·è¡ŒæŸ¥è©¢ã€ç”¢ç”Ÿçµæœï¼‰
4. çµæœé€é gRPC æµå¼è¿”å›çµ¦ PySpark å®¢æˆ¶ç«¯
5. PySpark å°‡çµæœæ ¼å¼åŒ–ä¸¦é¡¯ç¤ºåœ¨ REPL ä¸­

ç•¶ä½¿ç”¨è€…æŒ‰ Ctrl+D æˆ–è¼¸å…¥ `exit()` æ™‚ï¼š
1. `code.interact()` é€€å‡º
2. Python å‡½æ•¸å›å‚³
3. Rust çš„ `run_pyspark_shell()` å‡½æ•¸çµæŸ
4. æ•´å€‹ç¨‹åºé€€å‡ºï¼ˆèƒŒæ™¯çš„æœå‹™å™¨ä»»å‹™ä¹Ÿæœƒè¢«çµ‚æ­¢ï¼‰

---

## ğŸ”¸ ç°¡å–®ç¯„ä¾‹ï¼šSELECT 1+1

ç•¶ä½ åŸ·è¡Œ `sail spark server` ä¸¦ç”¨ PySpark é€£ç·šåŸ·è¡Œ `SELECT 1+1` æ™‚ï¼Œå®Œæ•´æµç¨‹å¦‚ä¸‹ï¼š

```
1. å•Ÿå‹•ä¼ºæœå™¨ï¼šsail spark server --port 50051
   â”‚
   â”œâ”€ main.rs::main()
   â”‚  â”œâ”€ rustls::crypto::aws_lc_rs::default_provider().install_default()
   â”‚  â”œâ”€ CliConfig::load()
   â”‚  â”‚  â””â”€ Figment å¾ç’°å¢ƒè®Šæ•¸ SAIL_INTERNAL__RUN_PYTHON è¼‰å…¥è¨­å®š
   â”‚  â”œâ”€ Python::initialize()
   â”‚  â””â”€ runner::main(args)
   â”‚     â”œâ”€ Cli::parse_from(args) è§£æå‘½ä»¤åˆ—åƒæ•¸
   â”‚     â””â”€ run_spark_connect_server(ip, port)
   â”‚
   â”œâ”€ run_spark_connect_server()
   â”‚  â”œâ”€ init_telemetry()
   â”‚  â”‚  â”œâ”€ env::var("SAIL_OPENTELEMETRY_COLLECTOR") æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
   â”‚  â”‚  â””â”€ init_logger() åˆå§‹åŒ–æ—¥èªŒç³»çµ±
   â”‚  â”œâ”€ AppConfig::load()
   â”‚  â”‚  â””â”€ Figment å¾ application.yaml å’Œç’°å¢ƒè®Šæ•¸è¼‰å…¥è¨­å®š
   â”‚  â”œâ”€ RuntimeManager::try_new()
   â”‚  â”‚  â”œâ”€ build_runtime() å»ºç«‹ primary åŸ·è¡Œæ™‚
   â”‚  â”‚  â””â”€ build_runtime() å»ºç«‹ io åŸ·è¡Œæ™‚
   â”‚  â”œâ”€ runtime.handle().primary().block_on(async { ... })
   â”‚  â”‚  â”œâ”€ TcpListener::bind((ip, port)) ç¶å®š 127.0.0.1:50051
   â”‚  â”‚  â””â”€ serve(listener, shutdown(), options)
   â”‚  â”‚     â”œâ”€ SessionManager::new() å»ºç«‹æœƒè©±ç®¡ç†å™¨
   â”‚  â”‚     â”œâ”€ SparkConnectServer::new() å»ºç«‹ Spark Connect ä¼ºæœå™¨
   â”‚  â”‚     â”œâ”€ SparkConnectServiceServer::new() å»ºç«‹ gRPC æœå‹™
   â”‚  â”‚     â””â”€ ServerBuilder::new().serve() å•Ÿå‹•ä¼ºæœå™¨
   â”‚  â”‚
   â”‚  â””â”€ fastrace::flush() ç¢ºä¿è¿½è¹¤è³‡æ–™å¯«å‡º
   â”‚
   â””â”€ ä¼ºæœå™¨é‹è¡Œä¸­ï¼Œç­‰å¾…é€£ç·š...

2. PySpark é€£ç·š
   spark = SparkSession.builder.remote("sc://localhost:50051").getOrCreate()
   â”‚
   â””â”€ gRPC å»ºç«‹é€£ç·šåˆ° 127.0.0.1:50051
      â””â”€ SessionManager å»ºç«‹æ–°çš„ Session

3. åŸ·è¡ŒæŸ¥è©¢
   spark.sql("SELECT 1+1").show()
   â”‚
   â”œâ”€ PySpark å°‡ SQL é€é gRPC ExecutePlanRequest ç™¼é€
   â”œâ”€ SparkConnectServer æ¥æ”¶è«‹æ±‚
   â”œâ”€ sail-sql-parser è§£æ SQL "SELECT 1+1"
   â”œâ”€ sail-plan è½‰æ›ç‚º DataFusion é‚è¼¯è¨ˆåŠƒ
   â”œâ”€ DataFusion åŸ·è¡ŒæŸ¥è©¢ï¼ˆlocal modeï¼‰
   â”œâ”€ çµæœä»¥ Arrow RecordBatch æ ¼å¼ç”¢ç”Ÿ
   â””â”€ é€é gRPC ExecutePlanResponse å›å‚³çµ¦ PySpark
      â””â”€ PySpark é¡¯ç¤ºçµæœï¼š
          +-------+
          |(1 + 1)|
          +-------+
          |      2|
          +-------+
```

---
